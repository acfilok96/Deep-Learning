{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "QpgYXhaPZZr0",
        "outputId": "d2b9f3fe-584b-4685-e712-2a1dc74a2f16"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/device:GPU:0\n"
          ]
        }
      ],
      "source": [
        "import tensorflow as tf\n",
        "device_name = tf.test.gpu_device_name()\n",
        "with tf.device(device_name):\n",
        "  print(device_name)"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## **Normal MLP Model**"
      ],
      "metadata": {
        "id": "q3m2XvSZaraf"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# generate two moons dataset\n",
        "from sklearn.datasets import make_moons\n",
        "from matplotlib import pyplot\n",
        "from pandas import DataFrame\n",
        "\n",
        "# generate 2d classification dataset\n",
        "X, y = make_moons(n_samples=100, noise=0.2, random_state=1)\n",
        "\n",
        "# scatter plot, dots colored by class value\n",
        "df = DataFrame(dict(x=X[:,0], y=X[:,1], label=y))\n",
        "colors = {0:'red', 1:'blue'}\n",
        "fig, ax = pyplot.subplots()\n",
        "grouped = df.groupby('label')\n",
        "\n",
        "for key, group in grouped:\n",
        "    group.plot(ax=ax, kind='scatter', x='x', y='y', label=key, color=colors[key])\n",
        "pyplot.show()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 279
        },
        "id": "C4oZ68TAZj7G",
        "outputId": "6160a12c-3979-4dfe-8f42-305dc5c06d6d"
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# generate 2d classification dataset\n",
        "X, y = make_moons(n_samples=100, noise=0.2, random_state=1)\n",
        "# split into train and test\n",
        "n_train = 30\n",
        "trainX, testX = X[:n_train, :], X[n_train:, :]\n",
        "trainy, testy = y[:n_train], y[n_train:]\n",
        "\n",
        "print(X.shape, y.shape)\n",
        "print(trainX.shape, testX.shape)\n",
        "print(trainy.shape, testy.shape)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "QNy_b9DJcGO6",
        "outputId": "52423138-a523-4d4b-fd3f-f8f64e670043"
      },
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "(100, 2) (100,)\n",
            "(30, 2) (70, 2)\n",
            "(30,) (70,)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# mlp overfit on the moons dataset\n",
        "from sklearn.datasets import make_moons\n",
        "from keras.layers import Dense\n",
        "from keras.models import Sequential\n",
        "from matplotlib import pyplot"
      ],
      "metadata": {
        "id": "V5U2pKgKZ2yR"
      },
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# define model\n",
        "model = Sequential()\n",
        "model.add(Dense(500, input_dim=2, activation='relu'))\n",
        "model.add(Dense(1, activation='sigmoid'))\n",
        "model.compile(loss='binary_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
        "print(model.summary())"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "yxavBlt9aE7p",
        "outputId": "ea45ab4e-299c-42dd-9bed-753809475d06"
      },
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"sequential_2\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " dense_4 (Dense)             (None, 500)               1500      \n",
            "                                                                 \n",
            " dense_5 (Dense)             (None, 1)                 501       \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 2,001\n",
            "Trainable params: 2,001\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n",
            "None\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# fit model\n",
        "with tf.device(device_name):\n",
        "  history = model.fit(trainX, trainy, validation_data=(testX, testy), epochs=4000, verbose=1)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_9xhic8CaTJu",
        "outputId": "54e854c4-dbe1-4d8a-eca7-64dca2ad0608"
      },
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[1;30;43mStreaming output truncated to the last 5000 lines.\u001b[0m\n",
            "1/1 [==============================] - 0s 49ms/step - loss: 0.0036 - accuracy: 1.0000 - val_loss: 0.3307 - val_accuracy: 0.9286\n",
            "Epoch 1502/4000\n",
            "1/1 [==============================] - 0s 36ms/step - loss: 0.0036 - accuracy: 1.0000 - val_loss: 0.3308 - val_accuracy: 0.9286\n",
            "Epoch 1503/4000\n",
            "1/1 [==============================] - 0s 54ms/step - loss: 0.0036 - accuracy: 1.0000 - val_loss: 0.3310 - val_accuracy: 0.9286\n",
            "Epoch 1504/4000\n",
            "1/1 [==============================] - 0s 48ms/step - loss: 0.0036 - accuracy: 1.0000 - val_loss: 0.3311 - val_accuracy: 0.9286\n",
            "Epoch 1505/4000\n",
            "1/1 [==============================] - 0s 40ms/step - loss: 0.0036 - accuracy: 1.0000 - val_loss: 0.3312 - val_accuracy: 0.9286\n",
            "Epoch 1506/4000\n",
            "1/1 [==============================] - 0s 50ms/step - loss: 0.0036 - accuracy: 1.0000 - val_loss: 0.3313 - val_accuracy: 0.9286\n",
            "Epoch 1507/4000\n",
            "1/1 [==============================] - 0s 35ms/step - loss: 0.0036 - accuracy: 1.0000 - val_loss: 0.3314 - val_accuracy: 0.9286\n",
            "Epoch 1508/4000\n",
            "1/1 [==============================] - 0s 36ms/step - loss: 0.0036 - accuracy: 1.0000 - val_loss: 0.3316 - val_accuracy: 0.9286\n",
            "Epoch 1509/4000\n",
            "1/1 [==============================] - 0s 40ms/step - loss: 0.0036 - accuracy: 1.0000 - val_loss: 0.3317 - val_accuracy: 0.9286\n",
            "Epoch 1510/4000\n",
            "1/1 [==============================] - 0s 48ms/step - loss: 0.0036 - accuracy: 1.0000 - val_loss: 0.3319 - val_accuracy: 0.9286\n",
            "Epoch 1511/4000\n",
            "1/1 [==============================] - 0s 40ms/step - loss: 0.0035 - accuracy: 1.0000 - val_loss: 0.3320 - val_accuracy: 0.9286\n",
            "Epoch 1512/4000\n",
            "1/1 [==============================] - 0s 51ms/step - loss: 0.0035 - accuracy: 1.0000 - val_loss: 0.3321 - val_accuracy: 0.9286\n",
            "Epoch 1513/4000\n",
            "1/1 [==============================] - 0s 52ms/step - loss: 0.0035 - accuracy: 1.0000 - val_loss: 0.3322 - val_accuracy: 0.9286\n",
            "Epoch 1514/4000\n",
            "1/1 [==============================] - 0s 50ms/step - loss: 0.0035 - accuracy: 1.0000 - val_loss: 0.3323 - val_accuracy: 0.9286\n",
            "Epoch 1515/4000\n",
            "1/1 [==============================] - 0s 50ms/step - loss: 0.0035 - accuracy: 1.0000 - val_loss: 0.3324 - val_accuracy: 0.9286\n",
            "Epoch 1516/4000\n",
            "1/1 [==============================] - 0s 53ms/step - loss: 0.0035 - accuracy: 1.0000 - val_loss: 0.3325 - val_accuracy: 0.9286\n",
            "Epoch 1517/4000\n",
            "1/1 [==============================] - 0s 49ms/step - loss: 0.0035 - accuracy: 1.0000 - val_loss: 0.3327 - val_accuracy: 0.9286\n",
            "Epoch 1518/4000\n",
            "1/1 [==============================] - 0s 35ms/step - loss: 0.0035 - accuracy: 1.0000 - val_loss: 0.3328 - val_accuracy: 0.9286\n",
            "Epoch 1519/4000\n",
            "1/1 [==============================] - 0s 33ms/step - loss: 0.0035 - accuracy: 1.0000 - val_loss: 0.3329 - val_accuracy: 0.9286\n",
            "Epoch 1520/4000\n",
            "1/1 [==============================] - 0s 51ms/step - loss: 0.0035 - accuracy: 1.0000 - val_loss: 0.3330 - val_accuracy: 0.9286\n",
            "Epoch 1521/4000\n",
            "1/1 [==============================] - 0s 52ms/step - loss: 0.0035 - accuracy: 1.0000 - val_loss: 0.3331 - val_accuracy: 0.9286\n",
            "Epoch 1522/4000\n",
            "1/1 [==============================] - 0s 50ms/step - loss: 0.0035 - accuracy: 1.0000 - val_loss: 0.3332 - val_accuracy: 0.9286\n",
            "Epoch 1523/4000\n",
            "1/1 [==============================] - 0s 53ms/step - loss: 0.0035 - accuracy: 1.0000 - val_loss: 0.3333 - val_accuracy: 0.9286\n",
            "Epoch 1524/4000\n",
            "1/1 [==============================] - 0s 41ms/step - loss: 0.0035 - accuracy: 1.0000 - val_loss: 0.3334 - val_accuracy: 0.9286\n",
            "Epoch 1525/4000\n",
            "1/1 [==============================] - 0s 33ms/step - loss: 0.0034 - accuracy: 1.0000 - val_loss: 0.3335 - val_accuracy: 0.9286\n",
            "Epoch 1526/4000\n",
            "1/1 [==============================] - 0s 34ms/step - loss: 0.0034 - accuracy: 1.0000 - val_loss: 0.3336 - val_accuracy: 0.9286\n",
            "Epoch 1527/4000\n",
            "1/1 [==============================] - 0s 50ms/step - loss: 0.0034 - accuracy: 1.0000 - val_loss: 0.3338 - val_accuracy: 0.9286\n",
            "Epoch 1528/4000\n",
            "1/1 [==============================] - 0s 50ms/step - loss: 0.0034 - accuracy: 1.0000 - val_loss: 0.3339 - val_accuracy: 0.9286\n",
            "Epoch 1529/4000\n",
            "1/1 [==============================] - 0s 49ms/step - loss: 0.0034 - accuracy: 1.0000 - val_loss: 0.3340 - val_accuracy: 0.9286\n",
            "Epoch 1530/4000\n",
            "1/1 [==============================] - 0s 35ms/step - loss: 0.0034 - accuracy: 1.0000 - val_loss: 0.3341 - val_accuracy: 0.9286\n",
            "Epoch 1531/4000\n",
            "1/1 [==============================] - 0s 48ms/step - loss: 0.0034 - accuracy: 1.0000 - val_loss: 0.3342 - val_accuracy: 0.9286\n",
            "Epoch 1532/4000\n",
            "1/1 [==============================] - 0s 40ms/step - loss: 0.0034 - accuracy: 1.0000 - val_loss: 0.3343 - val_accuracy: 0.9286\n",
            "Epoch 1533/4000\n",
            "1/1 [==============================] - 0s 39ms/step - loss: 0.0034 - accuracy: 1.0000 - val_loss: 0.3344 - val_accuracy: 0.9286\n",
            "Epoch 1534/4000\n",
            "1/1 [==============================] - 0s 52ms/step - loss: 0.0034 - accuracy: 1.0000 - val_loss: 0.3345 - val_accuracy: 0.9286\n",
            "Epoch 1535/4000\n",
            "1/1 [==============================] - 0s 51ms/step - loss: 0.0034 - accuracy: 1.0000 - val_loss: 0.3347 - val_accuracy: 0.9286\n",
            "Epoch 1536/4000\n",
            "1/1 [==============================] - 0s 40ms/step - loss: 0.0034 - accuracy: 1.0000 - val_loss: 0.3348 - val_accuracy: 0.9286\n",
            "Epoch 1537/4000\n",
            "1/1 [==============================] - 0s 52ms/step - loss: 0.0034 - accuracy: 1.0000 - val_loss: 0.3349 - val_accuracy: 0.9286\n",
            "Epoch 1538/4000\n",
            "1/1 [==============================] - 0s 52ms/step - loss: 0.0034 - accuracy: 1.0000 - val_loss: 0.3351 - val_accuracy: 0.9286\n",
            "Epoch 1539/4000\n",
            "1/1 [==============================] - 0s 33ms/step - loss: 0.0034 - accuracy: 1.0000 - val_loss: 0.3352 - val_accuracy: 0.9286\n",
            "Epoch 1540/4000\n",
            "1/1 [==============================] - 0s 55ms/step - loss: 0.0033 - accuracy: 1.0000 - val_loss: 0.3353 - val_accuracy: 0.9286\n",
            "Epoch 1541/4000\n",
            "1/1 [==============================] - 0s 52ms/step - loss: 0.0033 - accuracy: 1.0000 - val_loss: 0.3354 - val_accuracy: 0.9286\n",
            "Epoch 1542/4000\n",
            "1/1 [==============================] - 0s 50ms/step - loss: 0.0033 - accuracy: 1.0000 - val_loss: 0.3355 - val_accuracy: 0.9286\n",
            "Epoch 1543/4000\n",
            "1/1 [==============================] - 0s 54ms/step - loss: 0.0033 - accuracy: 1.0000 - val_loss: 0.3356 - val_accuracy: 0.9286\n",
            "Epoch 1544/4000\n",
            "1/1 [==============================] - 0s 39ms/step - loss: 0.0033 - accuracy: 1.0000 - val_loss: 0.3357 - val_accuracy: 0.9286\n",
            "Epoch 1545/4000\n",
            "1/1 [==============================] - 0s 33ms/step - loss: 0.0033 - accuracy: 1.0000 - val_loss: 0.3358 - val_accuracy: 0.9286\n",
            "Epoch 1546/4000\n",
            "1/1 [==============================] - 0s 51ms/step - loss: 0.0033 - accuracy: 1.0000 - val_loss: 0.3360 - val_accuracy: 0.9286\n",
            "Epoch 1547/4000\n",
            "1/1 [==============================] - 0s 54ms/step - loss: 0.0033 - accuracy: 1.0000 - val_loss: 0.3361 - val_accuracy: 0.9286\n",
            "Epoch 1548/4000\n",
            "1/1 [==============================] - 0s 40ms/step - loss: 0.0033 - accuracy: 1.0000 - val_loss: 0.3362 - val_accuracy: 0.9286\n",
            "Epoch 1549/4000\n",
            "1/1 [==============================] - 0s 50ms/step - loss: 0.0033 - accuracy: 1.0000 - val_loss: 0.3363 - val_accuracy: 0.9286\n",
            "Epoch 1550/4000\n",
            "1/1 [==============================] - 0s 38ms/step - loss: 0.0033 - accuracy: 1.0000 - val_loss: 0.3364 - val_accuracy: 0.9286\n",
            "Epoch 1551/4000\n",
            "1/1 [==============================] - 0s 50ms/step - loss: 0.0033 - accuracy: 1.0000 - val_loss: 0.3365 - val_accuracy: 0.9286\n",
            "Epoch 1552/4000\n",
            "1/1 [==============================] - 0s 52ms/step - loss: 0.0033 - accuracy: 1.0000 - val_loss: 0.3366 - val_accuracy: 0.9286\n",
            "Epoch 1553/4000\n",
            "1/1 [==============================] - 0s 37ms/step - loss: 0.0033 - accuracy: 1.0000 - val_loss: 0.3368 - val_accuracy: 0.9286\n",
            "Epoch 1554/4000\n",
            "1/1 [==============================] - 0s 38ms/step - loss: 0.0033 - accuracy: 1.0000 - val_loss: 0.3369 - val_accuracy: 0.9286\n",
            "Epoch 1555/4000\n",
            "1/1 [==============================] - 0s 49ms/step - loss: 0.0032 - accuracy: 1.0000 - val_loss: 0.3370 - val_accuracy: 0.9286\n",
            "Epoch 1556/4000\n",
            "1/1 [==============================] - 0s 50ms/step - loss: 0.0032 - accuracy: 1.0000 - val_loss: 0.3371 - val_accuracy: 0.9286\n",
            "Epoch 1557/4000\n",
            "1/1 [==============================] - 0s 58ms/step - loss: 0.0032 - accuracy: 1.0000 - val_loss: 0.3372 - val_accuracy: 0.9286\n",
            "Epoch 1558/4000\n",
            "1/1 [==============================] - 0s 49ms/step - loss: 0.0032 - accuracy: 1.0000 - val_loss: 0.3373 - val_accuracy: 0.9286\n",
            "Epoch 1559/4000\n",
            "1/1 [==============================] - 0s 47ms/step - loss: 0.0032 - accuracy: 1.0000 - val_loss: 0.3373 - val_accuracy: 0.9286\n",
            "Epoch 1560/4000\n",
            "1/1 [==============================] - 0s 48ms/step - loss: 0.0032 - accuracy: 1.0000 - val_loss: 0.3374 - val_accuracy: 0.9286\n",
            "Epoch 1561/4000\n",
            "1/1 [==============================] - 0s 47ms/step - loss: 0.0032 - accuracy: 1.0000 - val_loss: 0.3375 - val_accuracy: 0.9286\n",
            "Epoch 1562/4000\n",
            "1/1 [==============================] - 0s 52ms/step - loss: 0.0032 - accuracy: 1.0000 - val_loss: 0.3376 - val_accuracy: 0.9286\n",
            "Epoch 1563/4000\n",
            "1/1 [==============================] - 0s 49ms/step - loss: 0.0032 - accuracy: 1.0000 - val_loss: 0.3377 - val_accuracy: 0.9286\n",
            "Epoch 1564/4000\n",
            "1/1 [==============================] - 0s 36ms/step - loss: 0.0032 - accuracy: 1.0000 - val_loss: 0.3378 - val_accuracy: 0.9286\n",
            "Epoch 1565/4000\n",
            "1/1 [==============================] - 0s 52ms/step - loss: 0.0032 - accuracy: 1.0000 - val_loss: 0.3379 - val_accuracy: 0.9286\n",
            "Epoch 1566/4000\n",
            "1/1 [==============================] - 0s 48ms/step - loss: 0.0032 - accuracy: 1.0000 - val_loss: 0.3380 - val_accuracy: 0.9286\n",
            "Epoch 1567/4000\n",
            "1/1 [==============================] - 0s 53ms/step - loss: 0.0032 - accuracy: 1.0000 - val_loss: 0.3381 - val_accuracy: 0.9286\n",
            "Epoch 1568/4000\n",
            "1/1 [==============================] - 0s 52ms/step - loss: 0.0032 - accuracy: 1.0000 - val_loss: 0.3382 - val_accuracy: 0.9286\n",
            "Epoch 1569/4000\n",
            "1/1 [==============================] - 0s 51ms/step - loss: 0.0032 - accuracy: 1.0000 - val_loss: 0.3383 - val_accuracy: 0.9286\n",
            "Epoch 1570/4000\n",
            "1/1 [==============================] - 0s 52ms/step - loss: 0.0031 - accuracy: 1.0000 - val_loss: 0.3384 - val_accuracy: 0.9286\n",
            "Epoch 1571/4000\n",
            "1/1 [==============================] - 0s 49ms/step - loss: 0.0031 - accuracy: 1.0000 - val_loss: 0.3385 - val_accuracy: 0.9286\n",
            "Epoch 1572/4000\n",
            "1/1 [==============================] - 0s 50ms/step - loss: 0.0031 - accuracy: 1.0000 - val_loss: 0.3386 - val_accuracy: 0.9286\n",
            "Epoch 1573/4000\n",
            "1/1 [==============================] - 0s 37ms/step - loss: 0.0031 - accuracy: 1.0000 - val_loss: 0.3387 - val_accuracy: 0.9286\n",
            "Epoch 1574/4000\n",
            "1/1 [==============================] - 0s 47ms/step - loss: 0.0031 - accuracy: 1.0000 - val_loss: 0.3388 - val_accuracy: 0.9286\n",
            "Epoch 1575/4000\n",
            "1/1 [==============================] - 0s 35ms/step - loss: 0.0031 - accuracy: 1.0000 - val_loss: 0.3389 - val_accuracy: 0.9286\n",
            "Epoch 1576/4000\n",
            "1/1 [==============================] - 0s 48ms/step - loss: 0.0031 - accuracy: 1.0000 - val_loss: 0.3390 - val_accuracy: 0.9286\n",
            "Epoch 1577/4000\n",
            "1/1 [==============================] - 0s 62ms/step - loss: 0.0031 - accuracy: 1.0000 - val_loss: 0.3391 - val_accuracy: 0.9286\n",
            "Epoch 1578/4000\n",
            "1/1 [==============================] - 0s 37ms/step - loss: 0.0031 - accuracy: 1.0000 - val_loss: 0.3392 - val_accuracy: 0.9286\n",
            "Epoch 1579/4000\n",
            "1/1 [==============================] - 0s 35ms/step - loss: 0.0031 - accuracy: 1.0000 - val_loss: 0.3394 - val_accuracy: 0.9286\n",
            "Epoch 1580/4000\n",
            "1/1 [==============================] - 0s 36ms/step - loss: 0.0031 - accuracy: 1.0000 - val_loss: 0.3395 - val_accuracy: 0.9286\n",
            "Epoch 1581/4000\n",
            "1/1 [==============================] - 0s 38ms/step - loss: 0.0031 - accuracy: 1.0000 - val_loss: 0.3396 - val_accuracy: 0.9286\n",
            "Epoch 1582/4000\n",
            "1/1 [==============================] - 0s 35ms/step - loss: 0.0031 - accuracy: 1.0000 - val_loss: 0.3397 - val_accuracy: 0.9286\n",
            "Epoch 1583/4000\n",
            "1/1 [==============================] - 0s 49ms/step - loss: 0.0031 - accuracy: 1.0000 - val_loss: 0.3398 - val_accuracy: 0.9286\n",
            "Epoch 1584/4000\n",
            "1/1 [==============================] - 0s 38ms/step - loss: 0.0031 - accuracy: 1.0000 - val_loss: 0.3398 - val_accuracy: 0.9286\n",
            "Epoch 1585/4000\n",
            "1/1 [==============================] - 0s 35ms/step - loss: 0.0031 - accuracy: 1.0000 - val_loss: 0.3399 - val_accuracy: 0.9286\n",
            "Epoch 1586/4000\n",
            "1/1 [==============================] - 0s 38ms/step - loss: 0.0031 - accuracy: 1.0000 - val_loss: 0.3400 - val_accuracy: 0.9286\n",
            "Epoch 1587/4000\n",
            "1/1 [==============================] - 0s 55ms/step - loss: 0.0030 - accuracy: 1.0000 - val_loss: 0.3401 - val_accuracy: 0.9286\n",
            "Epoch 1588/4000\n",
            "1/1 [==============================] - 0s 52ms/step - loss: 0.0030 - accuracy: 1.0000 - val_loss: 0.3403 - val_accuracy: 0.9286\n",
            "Epoch 1589/4000\n",
            "1/1 [==============================] - 0s 51ms/step - loss: 0.0030 - accuracy: 1.0000 - val_loss: 0.3404 - val_accuracy: 0.9286\n",
            "Epoch 1590/4000\n",
            "1/1 [==============================] - 0s 33ms/step - loss: 0.0030 - accuracy: 1.0000 - val_loss: 0.3405 - val_accuracy: 0.9286\n",
            "Epoch 1591/4000\n",
            "1/1 [==============================] - 0s 48ms/step - loss: 0.0030 - accuracy: 1.0000 - val_loss: 0.3406 - val_accuracy: 0.9286\n",
            "Epoch 1592/4000\n",
            "1/1 [==============================] - 0s 47ms/step - loss: 0.0030 - accuracy: 1.0000 - val_loss: 0.3407 - val_accuracy: 0.9286\n",
            "Epoch 1593/4000\n",
            "1/1 [==============================] - 0s 47ms/step - loss: 0.0030 - accuracy: 1.0000 - val_loss: 0.3408 - val_accuracy: 0.9286\n",
            "Epoch 1594/4000\n",
            "1/1 [==============================] - 0s 37ms/step - loss: 0.0030 - accuracy: 1.0000 - val_loss: 0.3409 - val_accuracy: 0.9286\n",
            "Epoch 1595/4000\n",
            "1/1 [==============================] - 0s 44ms/step - loss: 0.0030 - accuracy: 1.0000 - val_loss: 0.3410 - val_accuracy: 0.9286\n",
            "Epoch 1596/4000\n",
            "1/1 [==============================] - 0s 39ms/step - loss: 0.0030 - accuracy: 1.0000 - val_loss: 0.3411 - val_accuracy: 0.9286\n",
            "Epoch 1597/4000\n",
            "1/1 [==============================] - 0s 52ms/step - loss: 0.0030 - accuracy: 1.0000 - val_loss: 0.3412 - val_accuracy: 0.9286\n",
            "Epoch 1598/4000\n",
            "1/1 [==============================] - 0s 63ms/step - loss: 0.0030 - accuracy: 1.0000 - val_loss: 0.3413 - val_accuracy: 0.9286\n",
            "Epoch 1599/4000\n",
            "1/1 [==============================] - 0s 38ms/step - loss: 0.0030 - accuracy: 1.0000 - val_loss: 0.3414 - val_accuracy: 0.9286\n",
            "Epoch 1600/4000\n",
            "1/1 [==============================] - 0s 46ms/step - loss: 0.0030 - accuracy: 1.0000 - val_loss: 0.3415 - val_accuracy: 0.9286\n",
            "Epoch 1601/4000\n",
            "1/1 [==============================] - 0s 50ms/step - loss: 0.0030 - accuracy: 1.0000 - val_loss: 0.3416 - val_accuracy: 0.9286\n",
            "Epoch 1602/4000\n",
            "1/1 [==============================] - 0s 48ms/step - loss: 0.0030 - accuracy: 1.0000 - val_loss: 0.3417 - val_accuracy: 0.9286\n",
            "Epoch 1603/4000\n",
            "1/1 [==============================] - 0s 39ms/step - loss: 0.0030 - accuracy: 1.0000 - val_loss: 0.3418 - val_accuracy: 0.9286\n",
            "Epoch 1604/4000\n",
            "1/1 [==============================] - 0s 35ms/step - loss: 0.0029 - accuracy: 1.0000 - val_loss: 0.3419 - val_accuracy: 0.9286\n",
            "Epoch 1605/4000\n",
            "1/1 [==============================] - 0s 44ms/step - loss: 0.0029 - accuracy: 1.0000 - val_loss: 0.3421 - val_accuracy: 0.9286\n",
            "Epoch 1606/4000\n",
            "1/1 [==============================] - 0s 53ms/step - loss: 0.0029 - accuracy: 1.0000 - val_loss: 0.3422 - val_accuracy: 0.9286\n",
            "Epoch 1607/4000\n",
            "1/1 [==============================] - 0s 50ms/step - loss: 0.0029 - accuracy: 1.0000 - val_loss: 0.3423 - val_accuracy: 0.9286\n",
            "Epoch 1608/4000\n",
            "1/1 [==============================] - 0s 53ms/step - loss: 0.0029 - accuracy: 1.0000 - val_loss: 0.3424 - val_accuracy: 0.9286\n",
            "Epoch 1609/4000\n",
            "1/1 [==============================] - 0s 54ms/step - loss: 0.0029 - accuracy: 1.0000 - val_loss: 0.3425 - val_accuracy: 0.9286\n",
            "Epoch 1610/4000\n",
            "1/1 [==============================] - 0s 52ms/step - loss: 0.0029 - accuracy: 1.0000 - val_loss: 0.3425 - val_accuracy: 0.9286\n",
            "Epoch 1611/4000\n",
            "1/1 [==============================] - 0s 38ms/step - loss: 0.0029 - accuracy: 1.0000 - val_loss: 0.3426 - val_accuracy: 0.9286\n",
            "Epoch 1612/4000\n",
            "1/1 [==============================] - 0s 50ms/step - loss: 0.0029 - accuracy: 1.0000 - val_loss: 0.3428 - val_accuracy: 0.9286\n",
            "Epoch 1613/4000\n",
            "1/1 [==============================] - 0s 52ms/step - loss: 0.0029 - accuracy: 1.0000 - val_loss: 0.3429 - val_accuracy: 0.9286\n",
            "Epoch 1614/4000\n",
            "1/1 [==============================] - 0s 35ms/step - loss: 0.0029 - accuracy: 1.0000 - val_loss: 0.3430 - val_accuracy: 0.9286\n",
            "Epoch 1615/4000\n",
            "1/1 [==============================] - 0s 49ms/step - loss: 0.0029 - accuracy: 1.0000 - val_loss: 0.3431 - val_accuracy: 0.9286\n",
            "Epoch 1616/4000\n",
            "1/1 [==============================] - 0s 46ms/step - loss: 0.0029 - accuracy: 1.0000 - val_loss: 0.3432 - val_accuracy: 0.9286\n",
            "Epoch 1617/4000\n",
            "1/1 [==============================] - 0s 45ms/step - loss: 0.0029 - accuracy: 1.0000 - val_loss: 0.3433 - val_accuracy: 0.9286\n",
            "Epoch 1618/4000\n",
            "1/1 [==============================] - 0s 43ms/step - loss: 0.0029 - accuracy: 1.0000 - val_loss: 0.3434 - val_accuracy: 0.9286\n",
            "Epoch 1619/4000\n",
            "1/1 [==============================] - 0s 51ms/step - loss: 0.0029 - accuracy: 1.0000 - val_loss: 0.3435 - val_accuracy: 0.9286\n",
            "Epoch 1620/4000\n",
            "1/1 [==============================] - 0s 52ms/step - loss: 0.0029 - accuracy: 1.0000 - val_loss: 0.3436 - val_accuracy: 0.9286\n",
            "Epoch 1621/4000\n",
            "1/1 [==============================] - 0s 54ms/step - loss: 0.0029 - accuracy: 1.0000 - val_loss: 0.3437 - val_accuracy: 0.9286\n",
            "Epoch 1622/4000\n",
            "1/1 [==============================] - 0s 51ms/step - loss: 0.0028 - accuracy: 1.0000 - val_loss: 0.3438 - val_accuracy: 0.9286\n",
            "Epoch 1623/4000\n",
            "1/1 [==============================] - 0s 53ms/step - loss: 0.0028 - accuracy: 1.0000 - val_loss: 0.3439 - val_accuracy: 0.9286\n",
            "Epoch 1624/4000\n",
            "1/1 [==============================] - 0s 34ms/step - loss: 0.0028 - accuracy: 1.0000 - val_loss: 0.3440 - val_accuracy: 0.9286\n",
            "Epoch 1625/4000\n",
            "1/1 [==============================] - 0s 47ms/step - loss: 0.0028 - accuracy: 1.0000 - val_loss: 0.3441 - val_accuracy: 0.9286\n",
            "Epoch 1626/4000\n",
            "1/1 [==============================] - 0s 47ms/step - loss: 0.0028 - accuracy: 1.0000 - val_loss: 0.3442 - val_accuracy: 0.9286\n",
            "Epoch 1627/4000\n",
            "1/1 [==============================] - 0s 44ms/step - loss: 0.0028 - accuracy: 1.0000 - val_loss: 0.3443 - val_accuracy: 0.9286\n",
            "Epoch 1628/4000\n",
            "1/1 [==============================] - 0s 55ms/step - loss: 0.0028 - accuracy: 1.0000 - val_loss: 0.3444 - val_accuracy: 0.9286\n",
            "Epoch 1629/4000\n",
            "1/1 [==============================] - 0s 47ms/step - loss: 0.0028 - accuracy: 1.0000 - val_loss: 0.3445 - val_accuracy: 0.9286\n",
            "Epoch 1630/4000\n",
            "1/1 [==============================] - 0s 53ms/step - loss: 0.0028 - accuracy: 1.0000 - val_loss: 0.3446 - val_accuracy: 0.9286\n",
            "Epoch 1631/4000\n",
            "1/1 [==============================] - 0s 52ms/step - loss: 0.0028 - accuracy: 1.0000 - val_loss: 0.3447 - val_accuracy: 0.9286\n",
            "Epoch 1632/4000\n",
            "1/1 [==============================] - 0s 50ms/step - loss: 0.0028 - accuracy: 1.0000 - val_loss: 0.3448 - val_accuracy: 0.9286\n",
            "Epoch 1633/4000\n",
            "1/1 [==============================] - 0s 37ms/step - loss: 0.0028 - accuracy: 1.0000 - val_loss: 0.3449 - val_accuracy: 0.9286\n",
            "Epoch 1634/4000\n",
            "1/1 [==============================] - 0s 48ms/step - loss: 0.0028 - accuracy: 1.0000 - val_loss: 0.3450 - val_accuracy: 0.9286\n",
            "Epoch 1635/4000\n",
            "1/1 [==============================] - 0s 51ms/step - loss: 0.0028 - accuracy: 1.0000 - val_loss: 0.3452 - val_accuracy: 0.9286\n",
            "Epoch 1636/4000\n",
            "1/1 [==============================] - 0s 34ms/step - loss: 0.0028 - accuracy: 1.0000 - val_loss: 0.3453 - val_accuracy: 0.9286\n",
            "Epoch 1637/4000\n",
            "1/1 [==============================] - 0s 47ms/step - loss: 0.0028 - accuracy: 1.0000 - val_loss: 0.3454 - val_accuracy: 0.9286\n",
            "Epoch 1638/4000\n",
            "1/1 [==============================] - 0s 49ms/step - loss: 0.0028 - accuracy: 1.0000 - val_loss: 0.3455 - val_accuracy: 0.9286\n",
            "Epoch 1639/4000\n",
            "1/1 [==============================] - 0s 32ms/step - loss: 0.0028 - accuracy: 1.0000 - val_loss: 0.3456 - val_accuracy: 0.9286\n",
            "Epoch 1640/4000\n",
            "1/1 [==============================] - 0s 46ms/step - loss: 0.0028 - accuracy: 1.0000 - val_loss: 0.3457 - val_accuracy: 0.9286\n",
            "Epoch 1641/4000\n",
            "1/1 [==============================] - 0s 48ms/step - loss: 0.0027 - accuracy: 1.0000 - val_loss: 0.3458 - val_accuracy: 0.9286\n",
            "Epoch 1642/4000\n",
            "1/1 [==============================] - 0s 50ms/step - loss: 0.0027 - accuracy: 1.0000 - val_loss: 0.3459 - val_accuracy: 0.9286\n",
            "Epoch 1643/4000\n",
            "1/1 [==============================] - 0s 48ms/step - loss: 0.0027 - accuracy: 1.0000 - val_loss: 0.3460 - val_accuracy: 0.9286\n",
            "Epoch 1644/4000\n",
            "1/1 [==============================] - 0s 48ms/step - loss: 0.0027 - accuracy: 1.0000 - val_loss: 0.3461 - val_accuracy: 0.9286\n",
            "Epoch 1645/4000\n",
            "1/1 [==============================] - 0s 33ms/step - loss: 0.0027 - accuracy: 1.0000 - val_loss: 0.3462 - val_accuracy: 0.9286\n",
            "Epoch 1646/4000\n",
            "1/1 [==============================] - 0s 50ms/step - loss: 0.0027 - accuracy: 1.0000 - val_loss: 0.3463 - val_accuracy: 0.9286\n",
            "Epoch 1647/4000\n",
            "1/1 [==============================] - 0s 35ms/step - loss: 0.0027 - accuracy: 1.0000 - val_loss: 0.3464 - val_accuracy: 0.9286\n",
            "Epoch 1648/4000\n",
            "1/1 [==============================] - 0s 48ms/step - loss: 0.0027 - accuracy: 1.0000 - val_loss: 0.3465 - val_accuracy: 0.9286\n",
            "Epoch 1649/4000\n",
            "1/1 [==============================] - 0s 34ms/step - loss: 0.0027 - accuracy: 1.0000 - val_loss: 0.3466 - val_accuracy: 0.9286\n",
            "Epoch 1650/4000\n",
            "1/1 [==============================] - 0s 34ms/step - loss: 0.0027 - accuracy: 1.0000 - val_loss: 0.3467 - val_accuracy: 0.9286\n",
            "Epoch 1651/4000\n",
            "1/1 [==============================] - 0s 33ms/step - loss: 0.0027 - accuracy: 1.0000 - val_loss: 0.3469 - val_accuracy: 0.9286\n",
            "Epoch 1652/4000\n",
            "1/1 [==============================] - 0s 40ms/step - loss: 0.0027 - accuracy: 1.0000 - val_loss: 0.3470 - val_accuracy: 0.9286\n",
            "Epoch 1653/4000\n",
            "1/1 [==============================] - 0s 48ms/step - loss: 0.0027 - accuracy: 1.0000 - val_loss: 0.3471 - val_accuracy: 0.9286\n",
            "Epoch 1654/4000\n",
            "1/1 [==============================] - 0s 48ms/step - loss: 0.0027 - accuracy: 1.0000 - val_loss: 0.3472 - val_accuracy: 0.9286\n",
            "Epoch 1655/4000\n",
            "1/1 [==============================] - 0s 37ms/step - loss: 0.0027 - accuracy: 1.0000 - val_loss: 0.3473 - val_accuracy: 0.9286\n",
            "Epoch 1656/4000\n",
            "1/1 [==============================] - 0s 50ms/step - loss: 0.0027 - accuracy: 1.0000 - val_loss: 0.3474 - val_accuracy: 0.9286\n",
            "Epoch 1657/4000\n",
            "1/1 [==============================] - 0s 32ms/step - loss: 0.0027 - accuracy: 1.0000 - val_loss: 0.3475 - val_accuracy: 0.9286\n",
            "Epoch 1658/4000\n",
            "1/1 [==============================] - 0s 46ms/step - loss: 0.0027 - accuracy: 1.0000 - val_loss: 0.3476 - val_accuracy: 0.9286\n",
            "Epoch 1659/4000\n",
            "1/1 [==============================] - 0s 48ms/step - loss: 0.0027 - accuracy: 1.0000 - val_loss: 0.3477 - val_accuracy: 0.9286\n",
            "Epoch 1660/4000\n",
            "1/1 [==============================] - 0s 53ms/step - loss: 0.0027 - accuracy: 1.0000 - val_loss: 0.3478 - val_accuracy: 0.9286\n",
            "Epoch 1661/4000\n",
            "1/1 [==============================] - 0s 50ms/step - loss: 0.0026 - accuracy: 1.0000 - val_loss: 0.3479 - val_accuracy: 0.9286\n",
            "Epoch 1662/4000\n",
            "1/1 [==============================] - 0s 49ms/step - loss: 0.0026 - accuracy: 1.0000 - val_loss: 0.3480 - val_accuracy: 0.9286\n",
            "Epoch 1663/4000\n",
            "1/1 [==============================] - 0s 34ms/step - loss: 0.0026 - accuracy: 1.0000 - val_loss: 0.3482 - val_accuracy: 0.9286\n",
            "Epoch 1664/4000\n",
            "1/1 [==============================] - 0s 41ms/step - loss: 0.0026 - accuracy: 1.0000 - val_loss: 0.3483 - val_accuracy: 0.9286\n",
            "Epoch 1665/4000\n",
            "1/1 [==============================] - 0s 32ms/step - loss: 0.0026 - accuracy: 1.0000 - val_loss: 0.3484 - val_accuracy: 0.9286\n",
            "Epoch 1666/4000\n",
            "1/1 [==============================] - 0s 49ms/step - loss: 0.0026 - accuracy: 1.0000 - val_loss: 0.3485 - val_accuracy: 0.9286\n",
            "Epoch 1667/4000\n",
            "1/1 [==============================] - 0s 47ms/step - loss: 0.0026 - accuracy: 1.0000 - val_loss: 0.3486 - val_accuracy: 0.9286\n",
            "Epoch 1668/4000\n",
            "1/1 [==============================] - 0s 47ms/step - loss: 0.0026 - accuracy: 1.0000 - val_loss: 0.3486 - val_accuracy: 0.9286\n",
            "Epoch 1669/4000\n",
            "1/1 [==============================] - 0s 49ms/step - loss: 0.0026 - accuracy: 1.0000 - val_loss: 0.3487 - val_accuracy: 0.9286\n",
            "Epoch 1670/4000\n",
            "1/1 [==============================] - 0s 49ms/step - loss: 0.0026 - accuracy: 1.0000 - val_loss: 0.3488 - val_accuracy: 0.9286\n",
            "Epoch 1671/4000\n",
            "1/1 [==============================] - 0s 48ms/step - loss: 0.0026 - accuracy: 1.0000 - val_loss: 0.3489 - val_accuracy: 0.9286\n",
            "Epoch 1672/4000\n",
            "1/1 [==============================] - 0s 50ms/step - loss: 0.0026 - accuracy: 1.0000 - val_loss: 0.3490 - val_accuracy: 0.9286\n",
            "Epoch 1673/4000\n",
            "1/1 [==============================] - 0s 58ms/step - loss: 0.0026 - accuracy: 1.0000 - val_loss: 0.3491 - val_accuracy: 0.9286\n",
            "Epoch 1674/4000\n",
            "1/1 [==============================] - 0s 41ms/step - loss: 0.0026 - accuracy: 1.0000 - val_loss: 0.3492 - val_accuracy: 0.9286\n",
            "Epoch 1675/4000\n",
            "1/1 [==============================] - 0s 37ms/step - loss: 0.0026 - accuracy: 1.0000 - val_loss: 0.3493 - val_accuracy: 0.9286\n",
            "Epoch 1676/4000\n",
            "1/1 [==============================] - 0s 47ms/step - loss: 0.0026 - accuracy: 1.0000 - val_loss: 0.3494 - val_accuracy: 0.9286\n",
            "Epoch 1677/4000\n",
            "1/1 [==============================] - 0s 37ms/step - loss: 0.0026 - accuracy: 1.0000 - val_loss: 0.3495 - val_accuracy: 0.9286\n",
            "Epoch 1678/4000\n",
            "1/1 [==============================] - 0s 55ms/step - loss: 0.0026 - accuracy: 1.0000 - val_loss: 0.3496 - val_accuracy: 0.9286\n",
            "Epoch 1679/4000\n",
            "1/1 [==============================] - 0s 47ms/step - loss: 0.0026 - accuracy: 1.0000 - val_loss: 0.3497 - val_accuracy: 0.9286\n",
            "Epoch 1680/4000\n",
            "1/1 [==============================] - 0s 42ms/step - loss: 0.0026 - accuracy: 1.0000 - val_loss: 0.3498 - val_accuracy: 0.9286\n",
            "Epoch 1681/4000\n",
            "1/1 [==============================] - 0s 46ms/step - loss: 0.0026 - accuracy: 1.0000 - val_loss: 0.3499 - val_accuracy: 0.9286\n",
            "Epoch 1682/4000\n",
            "1/1 [==============================] - 0s 48ms/step - loss: 0.0025 - accuracy: 1.0000 - val_loss: 0.3500 - val_accuracy: 0.9286\n",
            "Epoch 1683/4000\n",
            "1/1 [==============================] - 0s 36ms/step - loss: 0.0025 - accuracy: 1.0000 - val_loss: 0.3501 - val_accuracy: 0.9286\n",
            "Epoch 1684/4000\n",
            "1/1 [==============================] - 0s 47ms/step - loss: 0.0025 - accuracy: 1.0000 - val_loss: 0.3502 - val_accuracy: 0.9286\n",
            "Epoch 1685/4000\n",
            "1/1 [==============================] - 0s 38ms/step - loss: 0.0025 - accuracy: 1.0000 - val_loss: 0.3503 - val_accuracy: 0.9286\n",
            "Epoch 1686/4000\n",
            "1/1 [==============================] - 0s 40ms/step - loss: 0.0025 - accuracy: 1.0000 - val_loss: 0.3504 - val_accuracy: 0.9286\n",
            "Epoch 1687/4000\n",
            "1/1 [==============================] - 0s 48ms/step - loss: 0.0025 - accuracy: 1.0000 - val_loss: 0.3505 - val_accuracy: 0.9286\n",
            "Epoch 1688/4000\n",
            "1/1 [==============================] - 0s 33ms/step - loss: 0.0025 - accuracy: 1.0000 - val_loss: 0.3506 - val_accuracy: 0.9286\n",
            "Epoch 1689/4000\n",
            "1/1 [==============================] - 0s 47ms/step - loss: 0.0025 - accuracy: 1.0000 - val_loss: 0.3507 - val_accuracy: 0.9286\n",
            "Epoch 1690/4000\n",
            "1/1 [==============================] - 0s 36ms/step - loss: 0.0025 - accuracy: 1.0000 - val_loss: 0.3508 - val_accuracy: 0.9286\n",
            "Epoch 1691/4000\n",
            "1/1 [==============================] - 0s 46ms/step - loss: 0.0025 - accuracy: 1.0000 - val_loss: 0.3509 - val_accuracy: 0.9286\n",
            "Epoch 1692/4000\n",
            "1/1 [==============================] - 0s 34ms/step - loss: 0.0025 - accuracy: 1.0000 - val_loss: 0.3510 - val_accuracy: 0.9286\n",
            "Epoch 1693/4000\n",
            "1/1 [==============================] - 0s 47ms/step - loss: 0.0025 - accuracy: 1.0000 - val_loss: 0.3511 - val_accuracy: 0.9286\n",
            "Epoch 1694/4000\n",
            "1/1 [==============================] - 0s 52ms/step - loss: 0.0025 - accuracy: 1.0000 - val_loss: 0.3512 - val_accuracy: 0.9286\n",
            "Epoch 1695/4000\n",
            "1/1 [==============================] - 0s 54ms/step - loss: 0.0025 - accuracy: 1.0000 - val_loss: 0.3513 - val_accuracy: 0.9286\n",
            "Epoch 1696/4000\n",
            "1/1 [==============================] - 0s 37ms/step - loss: 0.0025 - accuracy: 1.0000 - val_loss: 0.3514 - val_accuracy: 0.9286\n",
            "Epoch 1697/4000\n",
            "1/1 [==============================] - 0s 35ms/step - loss: 0.0025 - accuracy: 1.0000 - val_loss: 0.3515 - val_accuracy: 0.9286\n",
            "Epoch 1698/4000\n",
            "1/1 [==============================] - 0s 34ms/step - loss: 0.0025 - accuracy: 1.0000 - val_loss: 0.3516 - val_accuracy: 0.9286\n",
            "Epoch 1699/4000\n",
            "1/1 [==============================] - 0s 32ms/step - loss: 0.0025 - accuracy: 1.0000 - val_loss: 0.3517 - val_accuracy: 0.9286\n",
            "Epoch 1700/4000\n",
            "1/1 [==============================] - 0s 51ms/step - loss: 0.0025 - accuracy: 1.0000 - val_loss: 0.3518 - val_accuracy: 0.9286\n",
            "Epoch 1701/4000\n",
            "1/1 [==============================] - 0s 52ms/step - loss: 0.0025 - accuracy: 1.0000 - val_loss: 0.3519 - val_accuracy: 0.9286\n",
            "Epoch 1702/4000\n",
            "1/1 [==============================] - 0s 44ms/step - loss: 0.0025 - accuracy: 1.0000 - val_loss: 0.3520 - val_accuracy: 0.9286\n",
            "Epoch 1703/4000\n",
            "1/1 [==============================] - 0s 51ms/step - loss: 0.0025 - accuracy: 1.0000 - val_loss: 0.3521 - val_accuracy: 0.9286\n",
            "Epoch 1704/4000\n",
            "1/1 [==============================] - 0s 32ms/step - loss: 0.0025 - accuracy: 1.0000 - val_loss: 0.3522 - val_accuracy: 0.9286\n",
            "Epoch 1705/4000\n",
            "1/1 [==============================] - 0s 49ms/step - loss: 0.0024 - accuracy: 1.0000 - val_loss: 0.3523 - val_accuracy: 0.9286\n",
            "Epoch 1706/4000\n",
            "1/1 [==============================] - 0s 37ms/step - loss: 0.0024 - accuracy: 1.0000 - val_loss: 0.3524 - val_accuracy: 0.9286\n",
            "Epoch 1707/4000\n",
            "1/1 [==============================] - 0s 50ms/step - loss: 0.0024 - accuracy: 1.0000 - val_loss: 0.3525 - val_accuracy: 0.9286\n",
            "Epoch 1708/4000\n",
            "1/1 [==============================] - 0s 46ms/step - loss: 0.0024 - accuracy: 1.0000 - val_loss: 0.3526 - val_accuracy: 0.9286\n",
            "Epoch 1709/4000\n",
            "1/1 [==============================] - 0s 48ms/step - loss: 0.0024 - accuracy: 1.0000 - val_loss: 0.3527 - val_accuracy: 0.9286\n",
            "Epoch 1710/4000\n",
            "1/1 [==============================] - 0s 48ms/step - loss: 0.0024 - accuracy: 1.0000 - val_loss: 0.3527 - val_accuracy: 0.9286\n",
            "Epoch 1711/4000\n",
            "1/1 [==============================] - 0s 37ms/step - loss: 0.0024 - accuracy: 1.0000 - val_loss: 0.3528 - val_accuracy: 0.9286\n",
            "Epoch 1712/4000\n",
            "1/1 [==============================] - 0s 53ms/step - loss: 0.0024 - accuracy: 1.0000 - val_loss: 0.3530 - val_accuracy: 0.9286\n",
            "Epoch 1713/4000\n",
            "1/1 [==============================] - 0s 34ms/step - loss: 0.0024 - accuracy: 1.0000 - val_loss: 0.3531 - val_accuracy: 0.9286\n",
            "Epoch 1714/4000\n",
            "1/1 [==============================] - 0s 47ms/step - loss: 0.0024 - accuracy: 1.0000 - val_loss: 0.3532 - val_accuracy: 0.9286\n",
            "Epoch 1715/4000\n",
            "1/1 [==============================] - 0s 33ms/step - loss: 0.0024 - accuracy: 1.0000 - val_loss: 0.3533 - val_accuracy: 0.9286\n",
            "Epoch 1716/4000\n",
            "1/1 [==============================] - 0s 51ms/step - loss: 0.0024 - accuracy: 1.0000 - val_loss: 0.3534 - val_accuracy: 0.9286\n",
            "Epoch 1717/4000\n",
            "1/1 [==============================] - 0s 34ms/step - loss: 0.0024 - accuracy: 1.0000 - val_loss: 0.3535 - val_accuracy: 0.9286\n",
            "Epoch 1718/4000\n",
            "1/1 [==============================] - 0s 47ms/step - loss: 0.0024 - accuracy: 1.0000 - val_loss: 0.3536 - val_accuracy: 0.9286\n",
            "Epoch 1719/4000\n",
            "1/1 [==============================] - 0s 35ms/step - loss: 0.0024 - accuracy: 1.0000 - val_loss: 0.3536 - val_accuracy: 0.9286\n",
            "Epoch 1720/4000\n",
            "1/1 [==============================] - 0s 48ms/step - loss: 0.0024 - accuracy: 1.0000 - val_loss: 0.3537 - val_accuracy: 0.9286\n",
            "Epoch 1721/4000\n",
            "1/1 [==============================] - 0s 51ms/step - loss: 0.0024 - accuracy: 1.0000 - val_loss: 0.3538 - val_accuracy: 0.9286\n",
            "Epoch 1722/4000\n",
            "1/1 [==============================] - 0s 46ms/step - loss: 0.0024 - accuracy: 1.0000 - val_loss: 0.3539 - val_accuracy: 0.9286\n",
            "Epoch 1723/4000\n",
            "1/1 [==============================] - 0s 34ms/step - loss: 0.0024 - accuracy: 1.0000 - val_loss: 0.3540 - val_accuracy: 0.9286\n",
            "Epoch 1724/4000\n",
            "1/1 [==============================] - 0s 37ms/step - loss: 0.0024 - accuracy: 1.0000 - val_loss: 0.3541 - val_accuracy: 0.9286\n",
            "Epoch 1725/4000\n",
            "1/1 [==============================] - 0s 42ms/step - loss: 0.0024 - accuracy: 1.0000 - val_loss: 0.3542 - val_accuracy: 0.9286\n",
            "Epoch 1726/4000\n",
            "1/1 [==============================] - 0s 52ms/step - loss: 0.0024 - accuracy: 1.0000 - val_loss: 0.3543 - val_accuracy: 0.9286\n",
            "Epoch 1727/4000\n",
            "1/1 [==============================] - 0s 54ms/step - loss: 0.0024 - accuracy: 1.0000 - val_loss: 0.3544 - val_accuracy: 0.9286\n",
            "Epoch 1728/4000\n",
            "1/1 [==============================] - 0s 52ms/step - loss: 0.0024 - accuracy: 1.0000 - val_loss: 0.3545 - val_accuracy: 0.9286\n",
            "Epoch 1729/4000\n",
            "1/1 [==============================] - 0s 52ms/step - loss: 0.0023 - accuracy: 1.0000 - val_loss: 0.3546 - val_accuracy: 0.9286\n",
            "Epoch 1730/4000\n",
            "1/1 [==============================] - 0s 45ms/step - loss: 0.0023 - accuracy: 1.0000 - val_loss: 0.3547 - val_accuracy: 0.9286\n",
            "Epoch 1731/4000\n",
            "1/1 [==============================] - 0s 46ms/step - loss: 0.0023 - accuracy: 1.0000 - val_loss: 0.3548 - val_accuracy: 0.9286\n",
            "Epoch 1732/4000\n",
            "1/1 [==============================] - 0s 36ms/step - loss: 0.0023 - accuracy: 1.0000 - val_loss: 0.3549 - val_accuracy: 0.9286\n",
            "Epoch 1733/4000\n",
            "1/1 [==============================] - 0s 36ms/step - loss: 0.0023 - accuracy: 1.0000 - val_loss: 0.3550 - val_accuracy: 0.9286\n",
            "Epoch 1734/4000\n",
            "1/1 [==============================] - 0s 47ms/step - loss: 0.0023 - accuracy: 1.0000 - val_loss: 0.3551 - val_accuracy: 0.9286\n",
            "Epoch 1735/4000\n",
            "1/1 [==============================] - 0s 34ms/step - loss: 0.0023 - accuracy: 1.0000 - val_loss: 0.3552 - val_accuracy: 0.9286\n",
            "Epoch 1736/4000\n",
            "1/1 [==============================] - 0s 46ms/step - loss: 0.0023 - accuracy: 1.0000 - val_loss: 0.3553 - val_accuracy: 0.9286\n",
            "Epoch 1737/4000\n",
            "1/1 [==============================] - 0s 48ms/step - loss: 0.0023 - accuracy: 1.0000 - val_loss: 0.3554 - val_accuracy: 0.9286\n",
            "Epoch 1738/4000\n",
            "1/1 [==============================] - 0s 48ms/step - loss: 0.0023 - accuracy: 1.0000 - val_loss: 0.3555 - val_accuracy: 0.9286\n",
            "Epoch 1739/4000\n",
            "1/1 [==============================] - 0s 47ms/step - loss: 0.0023 - accuracy: 1.0000 - val_loss: 0.3556 - val_accuracy: 0.9286\n",
            "Epoch 1740/4000\n",
            "1/1 [==============================] - 0s 50ms/step - loss: 0.0023 - accuracy: 1.0000 - val_loss: 0.3557 - val_accuracy: 0.9286\n",
            "Epoch 1741/4000\n",
            "1/1 [==============================] - 0s 35ms/step - loss: 0.0023 - accuracy: 1.0000 - val_loss: 0.3558 - val_accuracy: 0.9286\n",
            "Epoch 1742/4000\n",
            "1/1 [==============================] - 0s 37ms/step - loss: 0.0023 - accuracy: 1.0000 - val_loss: 0.3559 - val_accuracy: 0.9286\n",
            "Epoch 1743/4000\n",
            "1/1 [==============================] - 0s 47ms/step - loss: 0.0023 - accuracy: 1.0000 - val_loss: 0.3560 - val_accuracy: 0.9286\n",
            "Epoch 1744/4000\n",
            "1/1 [==============================] - 0s 50ms/step - loss: 0.0023 - accuracy: 1.0000 - val_loss: 0.3561 - val_accuracy: 0.9286\n",
            "Epoch 1745/4000\n",
            "1/1 [==============================] - 0s 52ms/step - loss: 0.0023 - accuracy: 1.0000 - val_loss: 0.3562 - val_accuracy: 0.9286\n",
            "Epoch 1746/4000\n",
            "1/1 [==============================] - 0s 50ms/step - loss: 0.0023 - accuracy: 1.0000 - val_loss: 0.3563 - val_accuracy: 0.9286\n",
            "Epoch 1747/4000\n",
            "1/1 [==============================] - 0s 32ms/step - loss: 0.0023 - accuracy: 1.0000 - val_loss: 0.3564 - val_accuracy: 0.9286\n",
            "Epoch 1748/4000\n",
            "1/1 [==============================] - 0s 46ms/step - loss: 0.0023 - accuracy: 1.0000 - val_loss: 0.3565 - val_accuracy: 0.9286\n",
            "Epoch 1749/4000\n",
            "1/1 [==============================] - 0s 48ms/step - loss: 0.0023 - accuracy: 1.0000 - val_loss: 0.3566 - val_accuracy: 0.9286\n",
            "Epoch 1750/4000\n",
            "1/1 [==============================] - 0s 35ms/step - loss: 0.0023 - accuracy: 1.0000 - val_loss: 0.3567 - val_accuracy: 0.9286\n",
            "Epoch 1751/4000\n",
            "1/1 [==============================] - 0s 47ms/step - loss: 0.0023 - accuracy: 1.0000 - val_loss: 0.3568 - val_accuracy: 0.9286\n",
            "Epoch 1752/4000\n",
            "1/1 [==============================] - 0s 47ms/step - loss: 0.0023 - accuracy: 1.0000 - val_loss: 0.3569 - val_accuracy: 0.9286\n",
            "Epoch 1753/4000\n",
            "1/1 [==============================] - 0s 47ms/step - loss: 0.0023 - accuracy: 1.0000 - val_loss: 0.3570 - val_accuracy: 0.9286\n",
            "Epoch 1754/4000\n",
            "1/1 [==============================] - 0s 51ms/step - loss: 0.0022 - accuracy: 1.0000 - val_loss: 0.3571 - val_accuracy: 0.9286\n",
            "Epoch 1755/4000\n",
            "1/1 [==============================] - 0s 51ms/step - loss: 0.0022 - accuracy: 1.0000 - val_loss: 0.3572 - val_accuracy: 0.9286\n",
            "Epoch 1756/4000\n",
            "1/1 [==============================] - 0s 49ms/step - loss: 0.0022 - accuracy: 1.0000 - val_loss: 0.3573 - val_accuracy: 0.9286\n",
            "Epoch 1757/4000\n",
            "1/1 [==============================] - 0s 39ms/step - loss: 0.0022 - accuracy: 1.0000 - val_loss: 0.3574 - val_accuracy: 0.9286\n",
            "Epoch 1758/4000\n",
            "1/1 [==============================] - 0s 46ms/step - loss: 0.0022 - accuracy: 1.0000 - val_loss: 0.3575 - val_accuracy: 0.9286\n",
            "Epoch 1759/4000\n",
            "1/1 [==============================] - 0s 36ms/step - loss: 0.0022 - accuracy: 1.0000 - val_loss: 0.3576 - val_accuracy: 0.9286\n",
            "Epoch 1760/4000\n",
            "1/1 [==============================] - 0s 52ms/step - loss: 0.0022 - accuracy: 1.0000 - val_loss: 0.3577 - val_accuracy: 0.9286\n",
            "Epoch 1761/4000\n",
            "1/1 [==============================] - 0s 46ms/step - loss: 0.0022 - accuracy: 1.0000 - val_loss: 0.3578 - val_accuracy: 0.9286\n",
            "Epoch 1762/4000\n",
            "1/1 [==============================] - 0s 47ms/step - loss: 0.0022 - accuracy: 1.0000 - val_loss: 0.3579 - val_accuracy: 0.9286\n",
            "Epoch 1763/4000\n",
            "1/1 [==============================] - 0s 32ms/step - loss: 0.0022 - accuracy: 1.0000 - val_loss: 0.3580 - val_accuracy: 0.9286\n",
            "Epoch 1764/4000\n",
            "1/1 [==============================] - 0s 32ms/step - loss: 0.0022 - accuracy: 1.0000 - val_loss: 0.3581 - val_accuracy: 0.9286\n",
            "Epoch 1765/4000\n",
            "1/1 [==============================] - 0s 31ms/step - loss: 0.0022 - accuracy: 1.0000 - val_loss: 0.3582 - val_accuracy: 0.9286\n",
            "Epoch 1766/4000\n",
            "1/1 [==============================] - 0s 47ms/step - loss: 0.0022 - accuracy: 1.0000 - val_loss: 0.3583 - val_accuracy: 0.9286\n",
            "Epoch 1767/4000\n",
            "1/1 [==============================] - 0s 46ms/step - loss: 0.0022 - accuracy: 1.0000 - val_loss: 0.3584 - val_accuracy: 0.9286\n",
            "Epoch 1768/4000\n",
            "1/1 [==============================] - 0s 38ms/step - loss: 0.0022 - accuracy: 1.0000 - val_loss: 0.3585 - val_accuracy: 0.9286\n",
            "Epoch 1769/4000\n",
            "1/1 [==============================] - 0s 32ms/step - loss: 0.0022 - accuracy: 1.0000 - val_loss: 0.3586 - val_accuracy: 0.9286\n",
            "Epoch 1770/4000\n",
            "1/1 [==============================] - 0s 31ms/step - loss: 0.0022 - accuracy: 1.0000 - val_loss: 0.3587 - val_accuracy: 0.9286\n",
            "Epoch 1771/4000\n",
            "1/1 [==============================] - 0s 46ms/step - loss: 0.0022 - accuracy: 1.0000 - val_loss: 0.3588 - val_accuracy: 0.9286\n",
            "Epoch 1772/4000\n",
            "1/1 [==============================] - 0s 35ms/step - loss: 0.0022 - accuracy: 1.0000 - val_loss: 0.3589 - val_accuracy: 0.9286\n",
            "Epoch 1773/4000\n",
            "1/1 [==============================] - 0s 48ms/step - loss: 0.0022 - accuracy: 1.0000 - val_loss: 0.3590 - val_accuracy: 0.9286\n",
            "Epoch 1774/4000\n",
            "1/1 [==============================] - 0s 48ms/step - loss: 0.0022 - accuracy: 1.0000 - val_loss: 0.3592 - val_accuracy: 0.9286\n",
            "Epoch 1775/4000\n",
            "1/1 [==============================] - 0s 37ms/step - loss: 0.0022 - accuracy: 1.0000 - val_loss: 0.3593 - val_accuracy: 0.9286\n",
            "Epoch 1776/4000\n",
            "1/1 [==============================] - 0s 47ms/step - loss: 0.0022 - accuracy: 1.0000 - val_loss: 0.3594 - val_accuracy: 0.9286\n",
            "Epoch 1777/4000\n",
            "1/1 [==============================] - 0s 32ms/step - loss: 0.0022 - accuracy: 1.0000 - val_loss: 0.3595 - val_accuracy: 0.9286\n",
            "Epoch 1778/4000\n",
            "1/1 [==============================] - 0s 34ms/step - loss: 0.0022 - accuracy: 1.0000 - val_loss: 0.3596 - val_accuracy: 0.9286\n",
            "Epoch 1779/4000\n",
            "1/1 [==============================] - 0s 55ms/step - loss: 0.0022 - accuracy: 1.0000 - val_loss: 0.3597 - val_accuracy: 0.9286\n",
            "Epoch 1780/4000\n",
            "1/1 [==============================] - 0s 52ms/step - loss: 0.0022 - accuracy: 1.0000 - val_loss: 0.3598 - val_accuracy: 0.9286\n",
            "Epoch 1781/4000\n",
            "1/1 [==============================] - 0s 36ms/step - loss: 0.0021 - accuracy: 1.0000 - val_loss: 0.3599 - val_accuracy: 0.9286\n",
            "Epoch 1782/4000\n",
            "1/1 [==============================] - 0s 48ms/step - loss: 0.0021 - accuracy: 1.0000 - val_loss: 0.3600 - val_accuracy: 0.9286\n",
            "Epoch 1783/4000\n",
            "1/1 [==============================] - 0s 50ms/step - loss: 0.0021 - accuracy: 1.0000 - val_loss: 0.3601 - val_accuracy: 0.9286\n",
            "Epoch 1784/4000\n",
            "1/1 [==============================] - 0s 37ms/step - loss: 0.0021 - accuracy: 1.0000 - val_loss: 0.3602 - val_accuracy: 0.9286\n",
            "Epoch 1785/4000\n",
            "1/1 [==============================] - 0s 48ms/step - loss: 0.0021 - accuracy: 1.0000 - val_loss: 0.3603 - val_accuracy: 0.9286\n",
            "Epoch 1786/4000\n",
            "1/1 [==============================] - 0s 49ms/step - loss: 0.0021 - accuracy: 1.0000 - val_loss: 0.3604 - val_accuracy: 0.9286\n",
            "Epoch 1787/4000\n",
            "1/1 [==============================] - 0s 56ms/step - loss: 0.0021 - accuracy: 1.0000 - val_loss: 0.3605 - val_accuracy: 0.9286\n",
            "Epoch 1788/4000\n",
            "1/1 [==============================] - 0s 50ms/step - loss: 0.0021 - accuracy: 1.0000 - val_loss: 0.3606 - val_accuracy: 0.9286\n",
            "Epoch 1789/4000\n",
            "1/1 [==============================] - 0s 62ms/step - loss: 0.0021 - accuracy: 1.0000 - val_loss: 0.3607 - val_accuracy: 0.9286\n",
            "Epoch 1790/4000\n",
            "1/1 [==============================] - 0s 51ms/step - loss: 0.0021 - accuracy: 1.0000 - val_loss: 0.3608 - val_accuracy: 0.9286\n",
            "Epoch 1791/4000\n",
            "1/1 [==============================] - 0s 38ms/step - loss: 0.0021 - accuracy: 1.0000 - val_loss: 0.3609 - val_accuracy: 0.9286\n",
            "Epoch 1792/4000\n",
            "1/1 [==============================] - 0s 50ms/step - loss: 0.0021 - accuracy: 1.0000 - val_loss: 0.3610 - val_accuracy: 0.9286\n",
            "Epoch 1793/4000\n",
            "1/1 [==============================] - 0s 46ms/step - loss: 0.0021 - accuracy: 1.0000 - val_loss: 0.3611 - val_accuracy: 0.9286\n",
            "Epoch 1794/4000\n",
            "1/1 [==============================] - 0s 47ms/step - loss: 0.0021 - accuracy: 1.0000 - val_loss: 0.3612 - val_accuracy: 0.9286\n",
            "Epoch 1795/4000\n",
            "1/1 [==============================] - 0s 36ms/step - loss: 0.0021 - accuracy: 1.0000 - val_loss: 0.3613 - val_accuracy: 0.9286\n",
            "Epoch 1796/4000\n",
            "1/1 [==============================] - 0s 33ms/step - loss: 0.0021 - accuracy: 1.0000 - val_loss: 0.3614 - val_accuracy: 0.9286\n",
            "Epoch 1797/4000\n",
            "1/1 [==============================] - 0s 46ms/step - loss: 0.0021 - accuracy: 1.0000 - val_loss: 0.3615 - val_accuracy: 0.9286\n",
            "Epoch 1798/4000\n",
            "1/1 [==============================] - 0s 37ms/step - loss: 0.0021 - accuracy: 1.0000 - val_loss: 0.3616 - val_accuracy: 0.9286\n",
            "Epoch 1799/4000\n",
            "1/1 [==============================] - 0s 36ms/step - loss: 0.0021 - accuracy: 1.0000 - val_loss: 0.3617 - val_accuracy: 0.9286\n",
            "Epoch 1800/4000\n",
            "1/1 [==============================] - 0s 48ms/step - loss: 0.0021 - accuracy: 1.0000 - val_loss: 0.3619 - val_accuracy: 0.9286\n",
            "Epoch 1801/4000\n",
            "1/1 [==============================] - 0s 47ms/step - loss: 0.0021 - accuracy: 1.0000 - val_loss: 0.3619 - val_accuracy: 0.9286\n",
            "Epoch 1802/4000\n",
            "1/1 [==============================] - 0s 48ms/step - loss: 0.0021 - accuracy: 1.0000 - val_loss: 0.3620 - val_accuracy: 0.9286\n",
            "Epoch 1803/4000\n",
            "1/1 [==============================] - 0s 40ms/step - loss: 0.0021 - accuracy: 1.0000 - val_loss: 0.3621 - val_accuracy: 0.9286\n",
            "Epoch 1804/4000\n",
            "1/1 [==============================] - 0s 40ms/step - loss: 0.0021 - accuracy: 1.0000 - val_loss: 0.3622 - val_accuracy: 0.9286\n",
            "Epoch 1805/4000\n",
            "1/1 [==============================] - 0s 35ms/step - loss: 0.0021 - accuracy: 1.0000 - val_loss: 0.3624 - val_accuracy: 0.9286\n",
            "Epoch 1806/4000\n",
            "1/1 [==============================] - 0s 54ms/step - loss: 0.0021 - accuracy: 1.0000 - val_loss: 0.3625 - val_accuracy: 0.9286\n",
            "Epoch 1807/4000\n",
            "1/1 [==============================] - 0s 57ms/step - loss: 0.0021 - accuracy: 1.0000 - val_loss: 0.3625 - val_accuracy: 0.9286\n",
            "Epoch 1808/4000\n",
            "1/1 [==============================] - 0s 51ms/step - loss: 0.0021 - accuracy: 1.0000 - val_loss: 0.3626 - val_accuracy: 0.9286\n",
            "Epoch 1809/4000\n",
            "1/1 [==============================] - 0s 45ms/step - loss: 0.0020 - accuracy: 1.0000 - val_loss: 0.3627 - val_accuracy: 0.9286\n",
            "Epoch 1810/4000\n",
            "1/1 [==============================] - 0s 49ms/step - loss: 0.0020 - accuracy: 1.0000 - val_loss: 0.3628 - val_accuracy: 0.9286\n",
            "Epoch 1811/4000\n",
            "1/1 [==============================] - 0s 36ms/step - loss: 0.0020 - accuracy: 1.0000 - val_loss: 0.3629 - val_accuracy: 0.9286\n",
            "Epoch 1812/4000\n",
            "1/1 [==============================] - 0s 38ms/step - loss: 0.0020 - accuracy: 1.0000 - val_loss: 0.3631 - val_accuracy: 0.9286\n",
            "Epoch 1813/4000\n",
            "1/1 [==============================] - 0s 37ms/step - loss: 0.0020 - accuracy: 1.0000 - val_loss: 0.3632 - val_accuracy: 0.9286\n",
            "Epoch 1814/4000\n",
            "1/1 [==============================] - 0s 46ms/step - loss: 0.0020 - accuracy: 1.0000 - val_loss: 0.3633 - val_accuracy: 0.9286\n",
            "Epoch 1815/4000\n",
            "1/1 [==============================] - 0s 48ms/step - loss: 0.0020 - accuracy: 1.0000 - val_loss: 0.3634 - val_accuracy: 0.9286\n",
            "Epoch 1816/4000\n",
            "1/1 [==============================] - 0s 52ms/step - loss: 0.0020 - accuracy: 1.0000 - val_loss: 0.3635 - val_accuracy: 0.9286\n",
            "Epoch 1817/4000\n",
            "1/1 [==============================] - 0s 38ms/step - loss: 0.0020 - accuracy: 1.0000 - val_loss: 0.3636 - val_accuracy: 0.9286\n",
            "Epoch 1818/4000\n",
            "1/1 [==============================] - 0s 49ms/step - loss: 0.0020 - accuracy: 1.0000 - val_loss: 0.3637 - val_accuracy: 0.9286\n",
            "Epoch 1819/4000\n",
            "1/1 [==============================] - 0s 33ms/step - loss: 0.0020 - accuracy: 1.0000 - val_loss: 0.3638 - val_accuracy: 0.9286\n",
            "Epoch 1820/4000\n",
            "1/1 [==============================] - 0s 47ms/step - loss: 0.0020 - accuracy: 1.0000 - val_loss: 0.3639 - val_accuracy: 0.9286\n",
            "Epoch 1821/4000\n",
            "1/1 [==============================] - 0s 51ms/step - loss: 0.0020 - accuracy: 1.0000 - val_loss: 0.3640 - val_accuracy: 0.9286\n",
            "Epoch 1822/4000\n",
            "1/1 [==============================] - 0s 39ms/step - loss: 0.0020 - accuracy: 1.0000 - val_loss: 0.3641 - val_accuracy: 0.9286\n",
            "Epoch 1823/4000\n",
            "1/1 [==============================] - 0s 53ms/step - loss: 0.0020 - accuracy: 1.0000 - val_loss: 0.3642 - val_accuracy: 0.9286\n",
            "Epoch 1824/4000\n",
            "1/1 [==============================] - 0s 35ms/step - loss: 0.0020 - accuracy: 1.0000 - val_loss: 0.3643 - val_accuracy: 0.9286\n",
            "Epoch 1825/4000\n",
            "1/1 [==============================] - 0s 35ms/step - loss: 0.0020 - accuracy: 1.0000 - val_loss: 0.3644 - val_accuracy: 0.9286\n",
            "Epoch 1826/4000\n",
            "1/1 [==============================] - 0s 51ms/step - loss: 0.0020 - accuracy: 1.0000 - val_loss: 0.3645 - val_accuracy: 0.9286\n",
            "Epoch 1827/4000\n",
            "1/1 [==============================] - 0s 48ms/step - loss: 0.0020 - accuracy: 1.0000 - val_loss: 0.3646 - val_accuracy: 0.9286\n",
            "Epoch 1828/4000\n",
            "1/1 [==============================] - 0s 44ms/step - loss: 0.0020 - accuracy: 1.0000 - val_loss: 0.3647 - val_accuracy: 0.9286\n",
            "Epoch 1829/4000\n",
            "1/1 [==============================] - 0s 53ms/step - loss: 0.0020 - accuracy: 1.0000 - val_loss: 0.3648 - val_accuracy: 0.9286\n",
            "Epoch 1830/4000\n",
            "1/1 [==============================] - 0s 34ms/step - loss: 0.0020 - accuracy: 1.0000 - val_loss: 0.3648 - val_accuracy: 0.9286\n",
            "Epoch 1831/4000\n",
            "1/1 [==============================] - 0s 49ms/step - loss: 0.0020 - accuracy: 1.0000 - val_loss: 0.3649 - val_accuracy: 0.9286\n",
            "Epoch 1832/4000\n",
            "1/1 [==============================] - 0s 49ms/step - loss: 0.0020 - accuracy: 1.0000 - val_loss: 0.3650 - val_accuracy: 0.9286\n",
            "Epoch 1833/4000\n",
            "1/1 [==============================] - 0s 50ms/step - loss: 0.0020 - accuracy: 1.0000 - val_loss: 0.3652 - val_accuracy: 0.9286\n",
            "Epoch 1834/4000\n",
            "1/1 [==============================] - 0s 47ms/step - loss: 0.0020 - accuracy: 1.0000 - val_loss: 0.3653 - val_accuracy: 0.9286\n",
            "Epoch 1835/4000\n",
            "1/1 [==============================] - 0s 37ms/step - loss: 0.0020 - accuracy: 1.0000 - val_loss: 0.3654 - val_accuracy: 0.9286\n",
            "Epoch 1836/4000\n",
            "1/1 [==============================] - 0s 48ms/step - loss: 0.0020 - accuracy: 1.0000 - val_loss: 0.3655 - val_accuracy: 0.9286\n",
            "Epoch 1837/4000\n",
            "1/1 [==============================] - 0s 46ms/step - loss: 0.0020 - accuracy: 1.0000 - val_loss: 0.3656 - val_accuracy: 0.9286\n",
            "Epoch 1838/4000\n",
            "1/1 [==============================] - 0s 39ms/step - loss: 0.0020 - accuracy: 1.0000 - val_loss: 0.3657 - val_accuracy: 0.9286\n",
            "Epoch 1839/4000\n",
            "1/1 [==============================] - 0s 47ms/step - loss: 0.0020 - accuracy: 1.0000 - val_loss: 0.3658 - val_accuracy: 0.9286\n",
            "Epoch 1840/4000\n",
            "1/1 [==============================] - 0s 47ms/step - loss: 0.0019 - accuracy: 1.0000 - val_loss: 0.3659 - val_accuracy: 0.9286\n",
            "Epoch 1841/4000\n",
            "1/1 [==============================] - 0s 35ms/step - loss: 0.0019 - accuracy: 1.0000 - val_loss: 0.3659 - val_accuracy: 0.9286\n",
            "Epoch 1842/4000\n",
            "1/1 [==============================] - 0s 48ms/step - loss: 0.0019 - accuracy: 1.0000 - val_loss: 0.3661 - val_accuracy: 0.9286\n",
            "Epoch 1843/4000\n",
            "1/1 [==============================] - 0s 49ms/step - loss: 0.0019 - accuracy: 1.0000 - val_loss: 0.3662 - val_accuracy: 0.9286\n",
            "Epoch 1844/4000\n",
            "1/1 [==============================] - 0s 31ms/step - loss: 0.0019 - accuracy: 1.0000 - val_loss: 0.3663 - val_accuracy: 0.9286\n",
            "Epoch 1845/4000\n",
            "1/1 [==============================] - 0s 51ms/step - loss: 0.0019 - accuracy: 1.0000 - val_loss: 0.3664 - val_accuracy: 0.9286\n",
            "Epoch 1846/4000\n",
            "1/1 [==============================] - 0s 49ms/step - loss: 0.0019 - accuracy: 1.0000 - val_loss: 0.3665 - val_accuracy: 0.9286\n",
            "Epoch 1847/4000\n",
            "1/1 [==============================] - 0s 49ms/step - loss: 0.0019 - accuracy: 1.0000 - val_loss: 0.3666 - val_accuracy: 0.9286\n",
            "Epoch 1848/4000\n",
            "1/1 [==============================] - 0s 50ms/step - loss: 0.0019 - accuracy: 1.0000 - val_loss: 0.3667 - val_accuracy: 0.9286\n",
            "Epoch 1849/4000\n",
            "1/1 [==============================] - 0s 53ms/step - loss: 0.0019 - accuracy: 1.0000 - val_loss: 0.3668 - val_accuracy: 0.9286\n",
            "Epoch 1850/4000\n",
            "1/1 [==============================] - 0s 39ms/step - loss: 0.0019 - accuracy: 1.0000 - val_loss: 0.3669 - val_accuracy: 0.9286\n",
            "Epoch 1851/4000\n",
            "1/1 [==============================] - 0s 51ms/step - loss: 0.0019 - accuracy: 1.0000 - val_loss: 0.3670 - val_accuracy: 0.9286\n",
            "Epoch 1852/4000\n",
            "1/1 [==============================] - 0s 58ms/step - loss: 0.0019 - accuracy: 1.0000 - val_loss: 0.3671 - val_accuracy: 0.9286\n",
            "Epoch 1853/4000\n",
            "1/1 [==============================] - 0s 34ms/step - loss: 0.0019 - accuracy: 1.0000 - val_loss: 0.3672 - val_accuracy: 0.9286\n",
            "Epoch 1854/4000\n",
            "1/1 [==============================] - 0s 48ms/step - loss: 0.0019 - accuracy: 1.0000 - val_loss: 0.3673 - val_accuracy: 0.9286\n",
            "Epoch 1855/4000\n",
            "1/1 [==============================] - 0s 49ms/step - loss: 0.0019 - accuracy: 1.0000 - val_loss: 0.3674 - val_accuracy: 0.9286\n",
            "Epoch 1856/4000\n",
            "1/1 [==============================] - 0s 36ms/step - loss: 0.0019 - accuracy: 1.0000 - val_loss: 0.3675 - val_accuracy: 0.9286\n",
            "Epoch 1857/4000\n",
            "1/1 [==============================] - 0s 38ms/step - loss: 0.0019 - accuracy: 1.0000 - val_loss: 0.3676 - val_accuracy: 0.9286\n",
            "Epoch 1858/4000\n",
            "1/1 [==============================] - 0s 47ms/step - loss: 0.0019 - accuracy: 1.0000 - val_loss: 0.3677 - val_accuracy: 0.9286\n",
            "Epoch 1859/4000\n",
            "1/1 [==============================] - 0s 50ms/step - loss: 0.0019 - accuracy: 1.0000 - val_loss: 0.3678 - val_accuracy: 0.9286\n",
            "Epoch 1860/4000\n",
            "1/1 [==============================] - 0s 51ms/step - loss: 0.0019 - accuracy: 1.0000 - val_loss: 0.3679 - val_accuracy: 0.9286\n",
            "Epoch 1861/4000\n",
            "1/1 [==============================] - 0s 44ms/step - loss: 0.0019 - accuracy: 1.0000 - val_loss: 0.3679 - val_accuracy: 0.9286\n",
            "Epoch 1862/4000\n",
            "1/1 [==============================] - 0s 47ms/step - loss: 0.0019 - accuracy: 1.0000 - val_loss: 0.3680 - val_accuracy: 0.9286\n",
            "Epoch 1863/4000\n",
            "1/1 [==============================] - 0s 32ms/step - loss: 0.0019 - accuracy: 1.0000 - val_loss: 0.3681 - val_accuracy: 0.9286\n",
            "Epoch 1864/4000\n",
            "1/1 [==============================] - 0s 49ms/step - loss: 0.0019 - accuracy: 1.0000 - val_loss: 0.3682 - val_accuracy: 0.9286\n",
            "Epoch 1865/4000\n",
            "1/1 [==============================] - 0s 38ms/step - loss: 0.0019 - accuracy: 1.0000 - val_loss: 0.3684 - val_accuracy: 0.9286\n",
            "Epoch 1866/4000\n",
            "1/1 [==============================] - 0s 36ms/step - loss: 0.0019 - accuracy: 1.0000 - val_loss: 0.3685 - val_accuracy: 0.9286\n",
            "Epoch 1867/4000\n",
            "1/1 [==============================] - 0s 45ms/step - loss: 0.0019 - accuracy: 1.0000 - val_loss: 0.3686 - val_accuracy: 0.9286\n",
            "Epoch 1868/4000\n",
            "1/1 [==============================] - 0s 51ms/step - loss: 0.0019 - accuracy: 1.0000 - val_loss: 0.3686 - val_accuracy: 0.9286\n",
            "Epoch 1869/4000\n",
            "1/1 [==============================] - 0s 38ms/step - loss: 0.0019 - accuracy: 1.0000 - val_loss: 0.3687 - val_accuracy: 0.9286\n",
            "Epoch 1870/4000\n",
            "1/1 [==============================] - 0s 45ms/step - loss: 0.0019 - accuracy: 1.0000 - val_loss: 0.3688 - val_accuracy: 0.9286\n",
            "Epoch 1871/4000\n",
            "1/1 [==============================] - 0s 39ms/step - loss: 0.0019 - accuracy: 1.0000 - val_loss: 0.3689 - val_accuracy: 0.9286\n",
            "Epoch 1872/4000\n",
            "1/1 [==============================] - 0s 49ms/step - loss: 0.0019 - accuracy: 1.0000 - val_loss: 0.3690 - val_accuracy: 0.9286\n",
            "Epoch 1873/4000\n",
            "1/1 [==============================] - 0s 50ms/step - loss: 0.0018 - accuracy: 1.0000 - val_loss: 0.3691 - val_accuracy: 0.9286\n",
            "Epoch 1874/4000\n",
            "1/1 [==============================] - 0s 33ms/step - loss: 0.0018 - accuracy: 1.0000 - val_loss: 0.3692 - val_accuracy: 0.9286\n",
            "Epoch 1875/4000\n",
            "1/1 [==============================] - 0s 58ms/step - loss: 0.0018 - accuracy: 1.0000 - val_loss: 0.3693 - val_accuracy: 0.9286\n",
            "Epoch 1876/4000\n",
            "1/1 [==============================] - 0s 54ms/step - loss: 0.0018 - accuracy: 1.0000 - val_loss: 0.3694 - val_accuracy: 0.9286\n",
            "Epoch 1877/4000\n",
            "1/1 [==============================] - 0s 51ms/step - loss: 0.0018 - accuracy: 1.0000 - val_loss: 0.3695 - val_accuracy: 0.9286\n",
            "Epoch 1878/4000\n",
            "1/1 [==============================] - 0s 53ms/step - loss: 0.0018 - accuracy: 1.0000 - val_loss: 0.3696 - val_accuracy: 0.9286\n",
            "Epoch 1879/4000\n",
            "1/1 [==============================] - 0s 38ms/step - loss: 0.0018 - accuracy: 1.0000 - val_loss: 0.3697 - val_accuracy: 0.9286\n",
            "Epoch 1880/4000\n",
            "1/1 [==============================] - 0s 46ms/step - loss: 0.0018 - accuracy: 1.0000 - val_loss: 0.3698 - val_accuracy: 0.9286\n",
            "Epoch 1881/4000\n",
            "1/1 [==============================] - 0s 51ms/step - loss: 0.0018 - accuracy: 1.0000 - val_loss: 0.3699 - val_accuracy: 0.9286\n",
            "Epoch 1882/4000\n",
            "1/1 [==============================] - 0s 54ms/step - loss: 0.0018 - accuracy: 1.0000 - val_loss: 0.3700 - val_accuracy: 0.9286\n",
            "Epoch 1883/4000\n",
            "1/1 [==============================] - 0s 54ms/step - loss: 0.0018 - accuracy: 1.0000 - val_loss: 0.3701 - val_accuracy: 0.9286\n",
            "Epoch 1884/4000\n",
            "1/1 [==============================] - 0s 48ms/step - loss: 0.0018 - accuracy: 1.0000 - val_loss: 0.3702 - val_accuracy: 0.9286\n",
            "Epoch 1885/4000\n",
            "1/1 [==============================] - 0s 41ms/step - loss: 0.0018 - accuracy: 1.0000 - val_loss: 0.3703 - val_accuracy: 0.9286\n",
            "Epoch 1886/4000\n",
            "1/1 [==============================] - 0s 49ms/step - loss: 0.0018 - accuracy: 1.0000 - val_loss: 0.3704 - val_accuracy: 0.9286\n",
            "Epoch 1887/4000\n",
            "1/1 [==============================] - 0s 37ms/step - loss: 0.0018 - accuracy: 1.0000 - val_loss: 0.3705 - val_accuracy: 0.9286\n",
            "Epoch 1888/4000\n",
            "1/1 [==============================] - 0s 42ms/step - loss: 0.0018 - accuracy: 1.0000 - val_loss: 0.3706 - val_accuracy: 0.9286\n",
            "Epoch 1889/4000\n",
            "1/1 [==============================] - 0s 58ms/step - loss: 0.0018 - accuracy: 1.0000 - val_loss: 0.3707 - val_accuracy: 0.9286\n",
            "Epoch 1890/4000\n",
            "1/1 [==============================] - 0s 54ms/step - loss: 0.0018 - accuracy: 1.0000 - val_loss: 0.3708 - val_accuracy: 0.9286\n",
            "Epoch 1891/4000\n",
            "1/1 [==============================] - 0s 45ms/step - loss: 0.0018 - accuracy: 1.0000 - val_loss: 0.3709 - val_accuracy: 0.9286\n",
            "Epoch 1892/4000\n",
            "1/1 [==============================] - 0s 46ms/step - loss: 0.0018 - accuracy: 1.0000 - val_loss: 0.3710 - val_accuracy: 0.9286\n",
            "Epoch 1893/4000\n",
            "1/1 [==============================] - 0s 56ms/step - loss: 0.0018 - accuracy: 1.0000 - val_loss: 0.3711 - val_accuracy: 0.9286\n",
            "Epoch 1894/4000\n",
            "1/1 [==============================] - 0s 37ms/step - loss: 0.0018 - accuracy: 1.0000 - val_loss: 0.3712 - val_accuracy: 0.9286\n",
            "Epoch 1895/4000\n",
            "1/1 [==============================] - 0s 49ms/step - loss: 0.0018 - accuracy: 1.0000 - val_loss: 0.3713 - val_accuracy: 0.9286\n",
            "Epoch 1896/4000\n",
            "1/1 [==============================] - 0s 50ms/step - loss: 0.0018 - accuracy: 1.0000 - val_loss: 0.3714 - val_accuracy: 0.9286\n",
            "Epoch 1897/4000\n",
            "1/1 [==============================] - 0s 48ms/step - loss: 0.0018 - accuracy: 1.0000 - val_loss: 0.3715 - val_accuracy: 0.9286\n",
            "Epoch 1898/4000\n",
            "1/1 [==============================] - 0s 46ms/step - loss: 0.0018 - accuracy: 1.0000 - val_loss: 0.3716 - val_accuracy: 0.9286\n",
            "Epoch 1899/4000\n",
            "1/1 [==============================] - 0s 32ms/step - loss: 0.0018 - accuracy: 1.0000 - val_loss: 0.3717 - val_accuracy: 0.9286\n",
            "Epoch 1900/4000\n",
            "1/1 [==============================] - 0s 42ms/step - loss: 0.0018 - accuracy: 1.0000 - val_loss: 0.3717 - val_accuracy: 0.9286\n",
            "Epoch 1901/4000\n",
            "1/1 [==============================] - 0s 50ms/step - loss: 0.0018 - accuracy: 1.0000 - val_loss: 0.3718 - val_accuracy: 0.9286\n",
            "Epoch 1902/4000\n",
            "1/1 [==============================] - 0s 45ms/step - loss: 0.0018 - accuracy: 1.0000 - val_loss: 0.3719 - val_accuracy: 0.9286\n",
            "Epoch 1903/4000\n",
            "1/1 [==============================] - 0s 53ms/step - loss: 0.0018 - accuracy: 1.0000 - val_loss: 0.3720 - val_accuracy: 0.9286\n",
            "Epoch 1904/4000\n",
            "1/1 [==============================] - 0s 56ms/step - loss: 0.0018 - accuracy: 1.0000 - val_loss: 0.3721 - val_accuracy: 0.9286\n",
            "Epoch 1905/4000\n",
            "1/1 [==============================] - 0s 53ms/step - loss: 0.0018 - accuracy: 1.0000 - val_loss: 0.3722 - val_accuracy: 0.9286\n",
            "Epoch 1906/4000\n",
            "1/1 [==============================] - 0s 73ms/step - loss: 0.0018 - accuracy: 1.0000 - val_loss: 0.3723 - val_accuracy: 0.9286\n",
            "Epoch 1907/4000\n",
            "1/1 [==============================] - 0s 65ms/step - loss: 0.0018 - accuracy: 1.0000 - val_loss: 0.3724 - val_accuracy: 0.9286\n",
            "Epoch 1908/4000\n",
            "1/1 [==============================] - 0s 123ms/step - loss: 0.0017 - accuracy: 1.0000 - val_loss: 0.3725 - val_accuracy: 0.9286\n",
            "Epoch 1909/4000\n",
            "1/1 [==============================] - 0s 76ms/step - loss: 0.0017 - accuracy: 1.0000 - val_loss: 0.3726 - val_accuracy: 0.9286\n",
            "Epoch 1910/4000\n",
            "1/1 [==============================] - 0s 85ms/step - loss: 0.0017 - accuracy: 1.0000 - val_loss: 0.3727 - val_accuracy: 0.9286\n",
            "Epoch 1911/4000\n",
            "1/1 [==============================] - 0s 123ms/step - loss: 0.0017 - accuracy: 1.0000 - val_loss: 0.3728 - val_accuracy: 0.9286\n",
            "Epoch 1912/4000\n",
            "1/1 [==============================] - 0s 145ms/step - loss: 0.0017 - accuracy: 1.0000 - val_loss: 0.3729 - val_accuracy: 0.9286\n",
            "Epoch 1913/4000\n",
            "1/1 [==============================] - 0s 96ms/step - loss: 0.0017 - accuracy: 1.0000 - val_loss: 0.3730 - val_accuracy: 0.9286\n",
            "Epoch 1914/4000\n",
            "1/1 [==============================] - 0s 123ms/step - loss: 0.0017 - accuracy: 1.0000 - val_loss: 0.3731 - val_accuracy: 0.9286\n",
            "Epoch 1915/4000\n",
            "1/1 [==============================] - 0s 71ms/step - loss: 0.0017 - accuracy: 1.0000 - val_loss: 0.3732 - val_accuracy: 0.9286\n",
            "Epoch 1916/4000\n",
            "1/1 [==============================] - 0s 68ms/step - loss: 0.0017 - accuracy: 1.0000 - val_loss: 0.3733 - val_accuracy: 0.9286\n",
            "Epoch 1917/4000\n",
            "1/1 [==============================] - 0s 90ms/step - loss: 0.0017 - accuracy: 1.0000 - val_loss: 0.3734 - val_accuracy: 0.9286\n",
            "Epoch 1918/4000\n",
            "1/1 [==============================] - 0s 75ms/step - loss: 0.0017 - accuracy: 1.0000 - val_loss: 0.3735 - val_accuracy: 0.9286\n",
            "Epoch 1919/4000\n",
            "1/1 [==============================] - 0s 80ms/step - loss: 0.0017 - accuracy: 1.0000 - val_loss: 0.3736 - val_accuracy: 0.9286\n",
            "Epoch 1920/4000\n",
            "1/1 [==============================] - 0s 102ms/step - loss: 0.0017 - accuracy: 1.0000 - val_loss: 0.3737 - val_accuracy: 0.9286\n",
            "Epoch 1921/4000\n",
            "1/1 [==============================] - 0s 128ms/step - loss: 0.0017 - accuracy: 1.0000 - val_loss: 0.3738 - val_accuracy: 0.9286\n",
            "Epoch 1922/4000\n",
            "1/1 [==============================] - 0s 104ms/step - loss: 0.0017 - accuracy: 1.0000 - val_loss: 0.3738 - val_accuracy: 0.9286\n",
            "Epoch 1923/4000\n",
            "1/1 [==============================] - 0s 123ms/step - loss: 0.0017 - accuracy: 1.0000 - val_loss: 0.3739 - val_accuracy: 0.9286\n",
            "Epoch 1924/4000\n",
            "1/1 [==============================] - 0s 61ms/step - loss: 0.0017 - accuracy: 1.0000 - val_loss: 0.3740 - val_accuracy: 0.9286\n",
            "Epoch 1925/4000\n",
            "1/1 [==============================] - 0s 107ms/step - loss: 0.0017 - accuracy: 1.0000 - val_loss: 0.3741 - val_accuracy: 0.9286\n",
            "Epoch 1926/4000\n",
            "1/1 [==============================] - 0s 135ms/step - loss: 0.0017 - accuracy: 1.0000 - val_loss: 0.3742 - val_accuracy: 0.9286\n",
            "Epoch 1927/4000\n",
            "1/1 [==============================] - 0s 133ms/step - loss: 0.0017 - accuracy: 1.0000 - val_loss: 0.3743 - val_accuracy: 0.9286\n",
            "Epoch 1928/4000\n",
            "1/1 [==============================] - 0s 75ms/step - loss: 0.0017 - accuracy: 1.0000 - val_loss: 0.3744 - val_accuracy: 0.9286\n",
            "Epoch 1929/4000\n",
            "1/1 [==============================] - 0s 78ms/step - loss: 0.0017 - accuracy: 1.0000 - val_loss: 0.3745 - val_accuracy: 0.9286\n",
            "Epoch 1930/4000\n",
            "1/1 [==============================] - 0s 92ms/step - loss: 0.0017 - accuracy: 1.0000 - val_loss: 0.3746 - val_accuracy: 0.9286\n",
            "Epoch 1931/4000\n",
            "1/1 [==============================] - 0s 78ms/step - loss: 0.0017 - accuracy: 1.0000 - val_loss: 0.3747 - val_accuracy: 0.9286\n",
            "Epoch 1932/4000\n",
            "1/1 [==============================] - 0s 92ms/step - loss: 0.0017 - accuracy: 1.0000 - val_loss: 0.3748 - val_accuracy: 0.9286\n",
            "Epoch 1933/4000\n",
            "1/1 [==============================] - 0s 102ms/step - loss: 0.0017 - accuracy: 1.0000 - val_loss: 0.3749 - val_accuracy: 0.9286\n",
            "Epoch 1934/4000\n",
            "1/1 [==============================] - 0s 111ms/step - loss: 0.0017 - accuracy: 1.0000 - val_loss: 0.3750 - val_accuracy: 0.9286\n",
            "Epoch 1935/4000\n",
            "1/1 [==============================] - 0s 172ms/step - loss: 0.0017 - accuracy: 1.0000 - val_loss: 0.3751 - val_accuracy: 0.9286\n",
            "Epoch 1936/4000\n",
            "1/1 [==============================] - 0s 97ms/step - loss: 0.0017 - accuracy: 1.0000 - val_loss: 0.3752 - val_accuracy: 0.9286\n",
            "Epoch 1937/4000\n",
            "1/1 [==============================] - 0s 108ms/step - loss: 0.0017 - accuracy: 1.0000 - val_loss: 0.3753 - val_accuracy: 0.9286\n",
            "Epoch 1938/4000\n",
            "1/1 [==============================] - 0s 114ms/step - loss: 0.0017 - accuracy: 1.0000 - val_loss: 0.3754 - val_accuracy: 0.9286\n",
            "Epoch 1939/4000\n",
            "1/1 [==============================] - 0s 66ms/step - loss: 0.0017 - accuracy: 1.0000 - val_loss: 0.3755 - val_accuracy: 0.9286\n",
            "Epoch 1940/4000\n",
            "1/1 [==============================] - 0s 116ms/step - loss: 0.0017 - accuracy: 1.0000 - val_loss: 0.3756 - val_accuracy: 0.9286\n",
            "Epoch 1941/4000\n",
            "1/1 [==============================] - 0s 104ms/step - loss: 0.0017 - accuracy: 1.0000 - val_loss: 0.3757 - val_accuracy: 0.9286\n",
            "Epoch 1942/4000\n",
            "1/1 [==============================] - 0s 67ms/step - loss: 0.0017 - accuracy: 1.0000 - val_loss: 0.3758 - val_accuracy: 0.9286\n",
            "Epoch 1943/4000\n",
            "1/1 [==============================] - 0s 36ms/step - loss: 0.0017 - accuracy: 1.0000 - val_loss: 0.3759 - val_accuracy: 0.9286\n",
            "Epoch 1944/4000\n",
            "1/1 [==============================] - 0s 34ms/step - loss: 0.0017 - accuracy: 1.0000 - val_loss: 0.3759 - val_accuracy: 0.9286\n",
            "Epoch 1945/4000\n",
            "1/1 [==============================] - 0s 33ms/step - loss: 0.0017 - accuracy: 1.0000 - val_loss: 0.3760 - val_accuracy: 0.9286\n",
            "Epoch 1946/4000\n",
            "1/1 [==============================] - 0s 50ms/step - loss: 0.0017 - accuracy: 1.0000 - val_loss: 0.3761 - val_accuracy: 0.9286\n",
            "Epoch 1947/4000\n",
            "1/1 [==============================] - 0s 50ms/step - loss: 0.0016 - accuracy: 1.0000 - val_loss: 0.3762 - val_accuracy: 0.9286\n",
            "Epoch 1948/4000\n",
            "1/1 [==============================] - 0s 48ms/step - loss: 0.0016 - accuracy: 1.0000 - val_loss: 0.3763 - val_accuracy: 0.9286\n",
            "Epoch 1949/4000\n",
            "1/1 [==============================] - 0s 56ms/step - loss: 0.0016 - accuracy: 1.0000 - val_loss: 0.3764 - val_accuracy: 0.9286\n",
            "Epoch 1950/4000\n",
            "1/1 [==============================] - 0s 52ms/step - loss: 0.0016 - accuracy: 1.0000 - val_loss: 0.3765 - val_accuracy: 0.9286\n",
            "Epoch 1951/4000\n",
            "1/1 [==============================] - 0s 50ms/step - loss: 0.0016 - accuracy: 1.0000 - val_loss: 0.3766 - val_accuracy: 0.9286\n",
            "Epoch 1952/4000\n",
            "1/1 [==============================] - 0s 38ms/step - loss: 0.0016 - accuracy: 1.0000 - val_loss: 0.3767 - val_accuracy: 0.9286\n",
            "Epoch 1953/4000\n",
            "1/1 [==============================] - 0s 48ms/step - loss: 0.0016 - accuracy: 1.0000 - val_loss: 0.3768 - val_accuracy: 0.9286\n",
            "Epoch 1954/4000\n",
            "1/1 [==============================] - 0s 48ms/step - loss: 0.0016 - accuracy: 1.0000 - val_loss: 0.3769 - val_accuracy: 0.9286\n",
            "Epoch 1955/4000\n",
            "1/1 [==============================] - 0s 34ms/step - loss: 0.0016 - accuracy: 1.0000 - val_loss: 0.3770 - val_accuracy: 0.9286\n",
            "Epoch 1956/4000\n",
            "1/1 [==============================] - 0s 51ms/step - loss: 0.0016 - accuracy: 1.0000 - val_loss: 0.3771 - val_accuracy: 0.9286\n",
            "Epoch 1957/4000\n",
            "1/1 [==============================] - 0s 53ms/step - loss: 0.0016 - accuracy: 1.0000 - val_loss: 0.3772 - val_accuracy: 0.9286\n",
            "Epoch 1958/4000\n",
            "1/1 [==============================] - 0s 32ms/step - loss: 0.0016 - accuracy: 1.0000 - val_loss: 0.3773 - val_accuracy: 0.9286\n",
            "Epoch 1959/4000\n",
            "1/1 [==============================] - 0s 56ms/step - loss: 0.0016 - accuracy: 1.0000 - val_loss: 0.3774 - val_accuracy: 0.9286\n",
            "Epoch 1960/4000\n",
            "1/1 [==============================] - 0s 36ms/step - loss: 0.0016 - accuracy: 1.0000 - val_loss: 0.3775 - val_accuracy: 0.9286\n",
            "Epoch 1961/4000\n",
            "1/1 [==============================] - 0s 32ms/step - loss: 0.0016 - accuracy: 1.0000 - val_loss: 0.3775 - val_accuracy: 0.9286\n",
            "Epoch 1962/4000\n",
            "1/1 [==============================] - 0s 38ms/step - loss: 0.0016 - accuracy: 1.0000 - val_loss: 0.3776 - val_accuracy: 0.9286\n",
            "Epoch 1963/4000\n",
            "1/1 [==============================] - 0s 54ms/step - loss: 0.0016 - accuracy: 1.0000 - val_loss: 0.3777 - val_accuracy: 0.9286\n",
            "Epoch 1964/4000\n",
            "1/1 [==============================] - 0s 36ms/step - loss: 0.0016 - accuracy: 1.0000 - val_loss: 0.3778 - val_accuracy: 0.9286\n",
            "Epoch 1965/4000\n",
            "1/1 [==============================] - 0s 51ms/step - loss: 0.0016 - accuracy: 1.0000 - val_loss: 0.3779 - val_accuracy: 0.9286\n",
            "Epoch 1966/4000\n",
            "1/1 [==============================] - 0s 50ms/step - loss: 0.0016 - accuracy: 1.0000 - val_loss: 0.3780 - val_accuracy: 0.9286\n",
            "Epoch 1967/4000\n",
            "1/1 [==============================] - 0s 34ms/step - loss: 0.0016 - accuracy: 1.0000 - val_loss: 0.3781 - val_accuracy: 0.9286\n",
            "Epoch 1968/4000\n",
            "1/1 [==============================] - 0s 33ms/step - loss: 0.0016 - accuracy: 1.0000 - val_loss: 0.3782 - val_accuracy: 0.9286\n",
            "Epoch 1969/4000\n",
            "1/1 [==============================] - 0s 50ms/step - loss: 0.0016 - accuracy: 1.0000 - val_loss: 0.3783 - val_accuracy: 0.9286\n",
            "Epoch 1970/4000\n",
            "1/1 [==============================] - 0s 34ms/step - loss: 0.0016 - accuracy: 1.0000 - val_loss: 0.3784 - val_accuracy: 0.9286\n",
            "Epoch 1971/4000\n",
            "1/1 [==============================] - 0s 47ms/step - loss: 0.0016 - accuracy: 1.0000 - val_loss: 0.3785 - val_accuracy: 0.9286\n",
            "Epoch 1972/4000\n",
            "1/1 [==============================] - 0s 35ms/step - loss: 0.0016 - accuracy: 1.0000 - val_loss: 0.3786 - val_accuracy: 0.9286\n",
            "Epoch 1973/4000\n",
            "1/1 [==============================] - 0s 47ms/step - loss: 0.0016 - accuracy: 1.0000 - val_loss: 0.3787 - val_accuracy: 0.9286\n",
            "Epoch 1974/4000\n",
            "1/1 [==============================] - 0s 50ms/step - loss: 0.0016 - accuracy: 1.0000 - val_loss: 0.3788 - val_accuracy: 0.9286\n",
            "Epoch 1975/4000\n",
            "1/1 [==============================] - 0s 47ms/step - loss: 0.0016 - accuracy: 1.0000 - val_loss: 0.3789 - val_accuracy: 0.9286\n",
            "Epoch 1976/4000\n",
            "1/1 [==============================] - 0s 56ms/step - loss: 0.0016 - accuracy: 1.0000 - val_loss: 0.3789 - val_accuracy: 0.9286\n",
            "Epoch 1977/4000\n",
            "1/1 [==============================] - 0s 46ms/step - loss: 0.0016 - accuracy: 1.0000 - val_loss: 0.3790 - val_accuracy: 0.9286\n",
            "Epoch 1978/4000\n",
            "1/1 [==============================] - 0s 37ms/step - loss: 0.0016 - accuracy: 1.0000 - val_loss: 0.3791 - val_accuracy: 0.9286\n",
            "Epoch 1979/4000\n",
            "1/1 [==============================] - 0s 38ms/step - loss: 0.0016 - accuracy: 1.0000 - val_loss: 0.3792 - val_accuracy: 0.9286\n",
            "Epoch 1980/4000\n",
            "1/1 [==============================] - 0s 48ms/step - loss: 0.0016 - accuracy: 1.0000 - val_loss: 0.3793 - val_accuracy: 0.9286\n",
            "Epoch 1981/4000\n",
            "1/1 [==============================] - 0s 36ms/step - loss: 0.0016 - accuracy: 1.0000 - val_loss: 0.3794 - val_accuracy: 0.9286\n",
            "Epoch 1982/4000\n",
            "1/1 [==============================] - 0s 39ms/step - loss: 0.0016 - accuracy: 1.0000 - val_loss: 0.3795 - val_accuracy: 0.9286\n",
            "Epoch 1983/4000\n",
            "1/1 [==============================] - 0s 34ms/step - loss: 0.0016 - accuracy: 1.0000 - val_loss: 0.3796 - val_accuracy: 0.9286\n",
            "Epoch 1984/4000\n",
            "1/1 [==============================] - 0s 33ms/step - loss: 0.0016 - accuracy: 1.0000 - val_loss: 0.3797 - val_accuracy: 0.9286\n",
            "Epoch 1985/4000\n",
            "1/1 [==============================] - 0s 45ms/step - loss: 0.0016 - accuracy: 1.0000 - val_loss: 0.3798 - val_accuracy: 0.9286\n",
            "Epoch 1986/4000\n",
            "1/1 [==============================] - 0s 47ms/step - loss: 0.0016 - accuracy: 1.0000 - val_loss: 0.3799 - val_accuracy: 0.9286\n",
            "Epoch 1987/4000\n",
            "1/1 [==============================] - 0s 51ms/step - loss: 0.0016 - accuracy: 1.0000 - val_loss: 0.3799 - val_accuracy: 0.9286\n",
            "Epoch 1988/4000\n",
            "1/1 [==============================] - 0s 51ms/step - loss: 0.0016 - accuracy: 1.0000 - val_loss: 0.3800 - val_accuracy: 0.9286\n",
            "Epoch 1989/4000\n",
            "1/1 [==============================] - 0s 37ms/step - loss: 0.0015 - accuracy: 1.0000 - val_loss: 0.3801 - val_accuracy: 0.9286\n",
            "Epoch 1990/4000\n",
            "1/1 [==============================] - 0s 52ms/step - loss: 0.0015 - accuracy: 1.0000 - val_loss: 0.3802 - val_accuracy: 0.9286\n",
            "Epoch 1991/4000\n",
            "1/1 [==============================] - 0s 32ms/step - loss: 0.0015 - accuracy: 1.0000 - val_loss: 0.3803 - val_accuracy: 0.9286\n",
            "Epoch 1992/4000\n",
            "1/1 [==============================] - 0s 47ms/step - loss: 0.0015 - accuracy: 1.0000 - val_loss: 0.3804 - val_accuracy: 0.9286\n",
            "Epoch 1993/4000\n",
            "1/1 [==============================] - 0s 48ms/step - loss: 0.0015 - accuracy: 1.0000 - val_loss: 0.3805 - val_accuracy: 0.9286\n",
            "Epoch 1994/4000\n",
            "1/1 [==============================] - 0s 47ms/step - loss: 0.0015 - accuracy: 1.0000 - val_loss: 0.3806 - val_accuracy: 0.9286\n",
            "Epoch 1995/4000\n",
            "1/1 [==============================] - 0s 49ms/step - loss: 0.0015 - accuracy: 1.0000 - val_loss: 0.3807 - val_accuracy: 0.9286\n",
            "Epoch 1996/4000\n",
            "1/1 [==============================] - 0s 46ms/step - loss: 0.0015 - accuracy: 1.0000 - val_loss: 0.3808 - val_accuracy: 0.9286\n",
            "Epoch 1997/4000\n",
            "1/1 [==============================] - 0s 54ms/step - loss: 0.0015 - accuracy: 1.0000 - val_loss: 0.3809 - val_accuracy: 0.9286\n",
            "Epoch 1998/4000\n",
            "1/1 [==============================] - 0s 50ms/step - loss: 0.0015 - accuracy: 1.0000 - val_loss: 0.3810 - val_accuracy: 0.9286\n",
            "Epoch 1999/4000\n",
            "1/1 [==============================] - 0s 52ms/step - loss: 0.0015 - accuracy: 1.0000 - val_loss: 0.3811 - val_accuracy: 0.9286\n",
            "Epoch 2000/4000\n",
            "1/1 [==============================] - 0s 32ms/step - loss: 0.0015 - accuracy: 1.0000 - val_loss: 0.3811 - val_accuracy: 0.9286\n",
            "Epoch 2001/4000\n",
            "1/1 [==============================] - 0s 49ms/step - loss: 0.0015 - accuracy: 1.0000 - val_loss: 0.3812 - val_accuracy: 0.9286\n",
            "Epoch 2002/4000\n",
            "1/1 [==============================] - 0s 48ms/step - loss: 0.0015 - accuracy: 1.0000 - val_loss: 0.3813 - val_accuracy: 0.9286\n",
            "Epoch 2003/4000\n",
            "1/1 [==============================] - 0s 34ms/step - loss: 0.0015 - accuracy: 1.0000 - val_loss: 0.3814 - val_accuracy: 0.9286\n",
            "Epoch 2004/4000\n",
            "1/1 [==============================] - 0s 35ms/step - loss: 0.0015 - accuracy: 1.0000 - val_loss: 0.3815 - val_accuracy: 0.9286\n",
            "Epoch 2005/4000\n",
            "1/1 [==============================] - 0s 43ms/step - loss: 0.0015 - accuracy: 1.0000 - val_loss: 0.3816 - val_accuracy: 0.9286\n",
            "Epoch 2006/4000\n",
            "1/1 [==============================] - 0s 50ms/step - loss: 0.0015 - accuracy: 1.0000 - val_loss: 0.3817 - val_accuracy: 0.9286\n",
            "Epoch 2007/4000\n",
            "1/1 [==============================] - 0s 46ms/step - loss: 0.0015 - accuracy: 1.0000 - val_loss: 0.3818 - val_accuracy: 0.9286\n",
            "Epoch 2008/4000\n",
            "1/1 [==============================] - 0s 51ms/step - loss: 0.0015 - accuracy: 1.0000 - val_loss: 0.3819 - val_accuracy: 0.9286\n",
            "Epoch 2009/4000\n",
            "1/1 [==============================] - 0s 49ms/step - loss: 0.0015 - accuracy: 1.0000 - val_loss: 0.3819 - val_accuracy: 0.9286\n",
            "Epoch 2010/4000\n",
            "1/1 [==============================] - 0s 53ms/step - loss: 0.0015 - accuracy: 1.0000 - val_loss: 0.3820 - val_accuracy: 0.9286\n",
            "Epoch 2011/4000\n",
            "1/1 [==============================] - 0s 48ms/step - loss: 0.0015 - accuracy: 1.0000 - val_loss: 0.3821 - val_accuracy: 0.9286\n",
            "Epoch 2012/4000\n",
            "1/1 [==============================] - 0s 51ms/step - loss: 0.0015 - accuracy: 1.0000 - val_loss: 0.3822 - val_accuracy: 0.9286\n",
            "Epoch 2013/4000\n",
            "1/1 [==============================] - 0s 34ms/step - loss: 0.0015 - accuracy: 1.0000 - val_loss: 0.3823 - val_accuracy: 0.9286\n",
            "Epoch 2014/4000\n",
            "1/1 [==============================] - 0s 48ms/step - loss: 0.0015 - accuracy: 1.0000 - val_loss: 0.3824 - val_accuracy: 0.9286\n",
            "Epoch 2015/4000\n",
            "1/1 [==============================] - 0s 35ms/step - loss: 0.0015 - accuracy: 1.0000 - val_loss: 0.3825 - val_accuracy: 0.9286\n",
            "Epoch 2016/4000\n",
            "1/1 [==============================] - 0s 50ms/step - loss: 0.0015 - accuracy: 1.0000 - val_loss: 0.3826 - val_accuracy: 0.9286\n",
            "Epoch 2017/4000\n",
            "1/1 [==============================] - 0s 34ms/step - loss: 0.0015 - accuracy: 1.0000 - val_loss: 0.3827 - val_accuracy: 0.9286\n",
            "Epoch 2018/4000\n",
            "1/1 [==============================] - 0s 42ms/step - loss: 0.0015 - accuracy: 1.0000 - val_loss: 0.3827 - val_accuracy: 0.9286\n",
            "Epoch 2019/4000\n",
            "1/1 [==============================] - 0s 60ms/step - loss: 0.0015 - accuracy: 1.0000 - val_loss: 0.3828 - val_accuracy: 0.9286\n",
            "Epoch 2020/4000\n",
            "1/1 [==============================] - 0s 38ms/step - loss: 0.0015 - accuracy: 1.0000 - val_loss: 0.3829 - val_accuracy: 0.9286\n",
            "Epoch 2021/4000\n",
            "1/1 [==============================] - 0s 46ms/step - loss: 0.0015 - accuracy: 1.0000 - val_loss: 0.3830 - val_accuracy: 0.9286\n",
            "Epoch 2022/4000\n",
            "1/1 [==============================] - 0s 49ms/step - loss: 0.0015 - accuracy: 1.0000 - val_loss: 0.3831 - val_accuracy: 0.9286\n",
            "Epoch 2023/4000\n",
            "1/1 [==============================] - 0s 52ms/step - loss: 0.0015 - accuracy: 1.0000 - val_loss: 0.3832 - val_accuracy: 0.9286\n",
            "Epoch 2024/4000\n",
            "1/1 [==============================] - 0s 52ms/step - loss: 0.0015 - accuracy: 1.0000 - val_loss: 0.3833 - val_accuracy: 0.9286\n",
            "Epoch 2025/4000\n",
            "1/1 [==============================] - 0s 40ms/step - loss: 0.0015 - accuracy: 1.0000 - val_loss: 0.3834 - val_accuracy: 0.9286\n",
            "Epoch 2026/4000\n",
            "1/1 [==============================] - 0s 48ms/step - loss: 0.0015 - accuracy: 1.0000 - val_loss: 0.3835 - val_accuracy: 0.9286\n",
            "Epoch 2027/4000\n",
            "1/1 [==============================] - 0s 50ms/step - loss: 0.0015 - accuracy: 1.0000 - val_loss: 0.3836 - val_accuracy: 0.9286\n",
            "Epoch 2028/4000\n",
            "1/1 [==============================] - 0s 35ms/step - loss: 0.0015 - accuracy: 1.0000 - val_loss: 0.3837 - val_accuracy: 0.9286\n",
            "Epoch 2029/4000\n",
            "1/1 [==============================] - 0s 54ms/step - loss: 0.0015 - accuracy: 1.0000 - val_loss: 0.3838 - val_accuracy: 0.9286\n",
            "Epoch 2030/4000\n",
            "1/1 [==============================] - 0s 32ms/step - loss: 0.0015 - accuracy: 1.0000 - val_loss: 0.3838 - val_accuracy: 0.9286\n",
            "Epoch 2031/4000\n",
            "1/1 [==============================] - 0s 34ms/step - loss: 0.0015 - accuracy: 1.0000 - val_loss: 0.3839 - val_accuracy: 0.9286\n",
            "Epoch 2032/4000\n",
            "1/1 [==============================] - 0s 46ms/step - loss: 0.0015 - accuracy: 1.0000 - val_loss: 0.3840 - val_accuracy: 0.9286\n",
            "Epoch 2033/4000\n",
            "1/1 [==============================] - 0s 47ms/step - loss: 0.0015 - accuracy: 1.0000 - val_loss: 0.3841 - val_accuracy: 0.9286\n",
            "Epoch 2034/4000\n",
            "1/1 [==============================] - 0s 37ms/step - loss: 0.0014 - accuracy: 1.0000 - val_loss: 0.3842 - val_accuracy: 0.9286\n",
            "Epoch 2035/4000\n",
            "1/1 [==============================] - 0s 46ms/step - loss: 0.0014 - accuracy: 1.0000 - val_loss: 0.3843 - val_accuracy: 0.9286\n",
            "Epoch 2036/4000\n",
            "1/1 [==============================] - 0s 33ms/step - loss: 0.0014 - accuracy: 1.0000 - val_loss: 0.3844 - val_accuracy: 0.9286\n",
            "Epoch 2037/4000\n",
            "1/1 [==============================] - 0s 47ms/step - loss: 0.0014 - accuracy: 1.0000 - val_loss: 0.3845 - val_accuracy: 0.9286\n",
            "Epoch 2038/4000\n",
            "1/1 [==============================] - 0s 34ms/step - loss: 0.0014 - accuracy: 1.0000 - val_loss: 0.3846 - val_accuracy: 0.9286\n",
            "Epoch 2039/4000\n",
            "1/1 [==============================] - 0s 50ms/step - loss: 0.0014 - accuracy: 1.0000 - val_loss: 0.3847 - val_accuracy: 0.9286\n",
            "Epoch 2040/4000\n",
            "1/1 [==============================] - 0s 53ms/step - loss: 0.0014 - accuracy: 1.0000 - val_loss: 0.3847 - val_accuracy: 0.9286\n",
            "Epoch 2041/4000\n",
            "1/1 [==============================] - 0s 52ms/step - loss: 0.0014 - accuracy: 1.0000 - val_loss: 0.3848 - val_accuracy: 0.9286\n",
            "Epoch 2042/4000\n",
            "1/1 [==============================] - 0s 54ms/step - loss: 0.0014 - accuracy: 1.0000 - val_loss: 0.3849 - val_accuracy: 0.9286\n",
            "Epoch 2043/4000\n",
            "1/1 [==============================] - 0s 51ms/step - loss: 0.0014 - accuracy: 1.0000 - val_loss: 0.3850 - val_accuracy: 0.9286\n",
            "Epoch 2044/4000\n",
            "1/1 [==============================] - 0s 49ms/step - loss: 0.0014 - accuracy: 1.0000 - val_loss: 0.3851 - val_accuracy: 0.9286\n",
            "Epoch 2045/4000\n",
            "1/1 [==============================] - 0s 49ms/step - loss: 0.0014 - accuracy: 1.0000 - val_loss: 0.3852 - val_accuracy: 0.9286\n",
            "Epoch 2046/4000\n",
            "1/1 [==============================] - 0s 57ms/step - loss: 0.0014 - accuracy: 1.0000 - val_loss: 0.3853 - val_accuracy: 0.9286\n",
            "Epoch 2047/4000\n",
            "1/1 [==============================] - 0s 47ms/step - loss: 0.0014 - accuracy: 1.0000 - val_loss: 0.3854 - val_accuracy: 0.9286\n",
            "Epoch 2048/4000\n",
            "1/1 [==============================] - 0s 53ms/step - loss: 0.0014 - accuracy: 1.0000 - val_loss: 0.3855 - val_accuracy: 0.9286\n",
            "Epoch 2049/4000\n",
            "1/1 [==============================] - 0s 52ms/step - loss: 0.0014 - accuracy: 1.0000 - val_loss: 0.3856 - val_accuracy: 0.9286\n",
            "Epoch 2050/4000\n",
            "1/1 [==============================] - 0s 55ms/step - loss: 0.0014 - accuracy: 1.0000 - val_loss: 0.3857 - val_accuracy: 0.9286\n",
            "Epoch 2051/4000\n",
            "1/1 [==============================] - 0s 47ms/step - loss: 0.0014 - accuracy: 1.0000 - val_loss: 0.3858 - val_accuracy: 0.9286\n",
            "Epoch 2052/4000\n",
            "1/1 [==============================] - 0s 46ms/step - loss: 0.0014 - accuracy: 1.0000 - val_loss: 0.3859 - val_accuracy: 0.9286\n",
            "Epoch 2053/4000\n",
            "1/1 [==============================] - 0s 50ms/step - loss: 0.0014 - accuracy: 1.0000 - val_loss: 0.3860 - val_accuracy: 0.9286\n",
            "Epoch 2054/4000\n",
            "1/1 [==============================] - 0s 51ms/step - loss: 0.0014 - accuracy: 1.0000 - val_loss: 0.3860 - val_accuracy: 0.9286\n",
            "Epoch 2055/4000\n",
            "1/1 [==============================] - 0s 53ms/step - loss: 0.0014 - accuracy: 1.0000 - val_loss: 0.3861 - val_accuracy: 0.9286\n",
            "Epoch 2056/4000\n",
            "1/1 [==============================] - 0s 47ms/step - loss: 0.0014 - accuracy: 1.0000 - val_loss: 0.3862 - val_accuracy: 0.9286\n",
            "Epoch 2057/4000\n",
            "1/1 [==============================] - 0s 50ms/step - loss: 0.0014 - accuracy: 1.0000 - val_loss: 0.3863 - val_accuracy: 0.9286\n",
            "Epoch 2058/4000\n",
            "1/1 [==============================] - 0s 40ms/step - loss: 0.0014 - accuracy: 1.0000 - val_loss: 0.3864 - val_accuracy: 0.9286\n",
            "Epoch 2059/4000\n",
            "1/1 [==============================] - 0s 57ms/step - loss: 0.0014 - accuracy: 1.0000 - val_loss: 0.3865 - val_accuracy: 0.9286\n",
            "Epoch 2060/4000\n",
            "1/1 [==============================] - 0s 52ms/step - loss: 0.0014 - accuracy: 1.0000 - val_loss: 0.3866 - val_accuracy: 0.9286\n",
            "Epoch 2061/4000\n",
            "1/1 [==============================] - 0s 46ms/step - loss: 0.0014 - accuracy: 1.0000 - val_loss: 0.3867 - val_accuracy: 0.9286\n",
            "Epoch 2062/4000\n",
            "1/1 [==============================] - 0s 53ms/step - loss: 0.0014 - accuracy: 1.0000 - val_loss: 0.3867 - val_accuracy: 0.9286\n",
            "Epoch 2063/4000\n",
            "1/1 [==============================] - 0s 46ms/step - loss: 0.0014 - accuracy: 1.0000 - val_loss: 0.3868 - val_accuracy: 0.9286\n",
            "Epoch 2064/4000\n",
            "1/1 [==============================] - 0s 54ms/step - loss: 0.0014 - accuracy: 1.0000 - val_loss: 0.3869 - val_accuracy: 0.9286\n",
            "Epoch 2065/4000\n",
            "1/1 [==============================] - 0s 37ms/step - loss: 0.0014 - accuracy: 1.0000 - val_loss: 0.3870 - val_accuracy: 0.9286\n",
            "Epoch 2066/4000\n",
            "1/1 [==============================] - 0s 46ms/step - loss: 0.0014 - accuracy: 1.0000 - val_loss: 0.3871 - val_accuracy: 0.9286\n",
            "Epoch 2067/4000\n",
            "1/1 [==============================] - 0s 42ms/step - loss: 0.0014 - accuracy: 1.0000 - val_loss: 0.3872 - val_accuracy: 0.9286\n",
            "Epoch 2068/4000\n",
            "1/1 [==============================] - 0s 34ms/step - loss: 0.0014 - accuracy: 1.0000 - val_loss: 0.3873 - val_accuracy: 0.9286\n",
            "Epoch 2069/4000\n",
            "1/1 [==============================] - 0s 40ms/step - loss: 0.0014 - accuracy: 1.0000 - val_loss: 0.3874 - val_accuracy: 0.9286\n",
            "Epoch 2070/4000\n",
            "1/1 [==============================] - 0s 57ms/step - loss: 0.0014 - accuracy: 1.0000 - val_loss: 0.3875 - val_accuracy: 0.9286\n",
            "Epoch 2071/4000\n",
            "1/1 [==============================] - 0s 48ms/step - loss: 0.0014 - accuracy: 1.0000 - val_loss: 0.3876 - val_accuracy: 0.9286\n",
            "Epoch 2072/4000\n",
            "1/1 [==============================] - 0s 49ms/step - loss: 0.0014 - accuracy: 1.0000 - val_loss: 0.3877 - val_accuracy: 0.9286\n",
            "Epoch 2073/4000\n",
            "1/1 [==============================] - 0s 36ms/step - loss: 0.0014 - accuracy: 1.0000 - val_loss: 0.3877 - val_accuracy: 0.9286\n",
            "Epoch 2074/4000\n",
            "1/1 [==============================] - 0s 47ms/step - loss: 0.0014 - accuracy: 1.0000 - val_loss: 0.3878 - val_accuracy: 0.9286\n",
            "Epoch 2075/4000\n",
            "1/1 [==============================] - 0s 42ms/step - loss: 0.0014 - accuracy: 1.0000 - val_loss: 0.3879 - val_accuracy: 0.9286\n",
            "Epoch 2076/4000\n",
            "1/1 [==============================] - 0s 45ms/step - loss: 0.0014 - accuracy: 1.0000 - val_loss: 0.3880 - val_accuracy: 0.9286\n",
            "Epoch 2077/4000\n",
            "1/1 [==============================] - 0s 50ms/step - loss: 0.0014 - accuracy: 1.0000 - val_loss: 0.3881 - val_accuracy: 0.9286\n",
            "Epoch 2078/4000\n",
            "1/1 [==============================] - 0s 50ms/step - loss: 0.0014 - accuracy: 1.0000 - val_loss: 0.3882 - val_accuracy: 0.9286\n",
            "Epoch 2079/4000\n",
            "1/1 [==============================] - 0s 46ms/step - loss: 0.0014 - accuracy: 1.0000 - val_loss: 0.3883 - val_accuracy: 0.9286\n",
            "Epoch 2080/4000\n",
            "1/1 [==============================] - 0s 182ms/step - loss: 0.0014 - accuracy: 1.0000 - val_loss: 0.3883 - val_accuracy: 0.9286\n",
            "Epoch 2081/4000\n",
            "1/1 [==============================] - 0s 101ms/step - loss: 0.0014 - accuracy: 1.0000 - val_loss: 0.3884 - val_accuracy: 0.9286\n",
            "Epoch 2082/4000\n",
            "1/1 [==============================] - 0s 109ms/step - loss: 0.0014 - accuracy: 1.0000 - val_loss: 0.3885 - val_accuracy: 0.9286\n",
            "Epoch 2083/4000\n",
            "1/1 [==============================] - 0s 91ms/step - loss: 0.0014 - accuracy: 1.0000 - val_loss: 0.3886 - val_accuracy: 0.9286\n",
            "Epoch 2084/4000\n",
            "1/1 [==============================] - 0s 72ms/step - loss: 0.0014 - accuracy: 1.0000 - val_loss: 0.3887 - val_accuracy: 0.9286\n",
            "Epoch 2085/4000\n",
            "1/1 [==============================] - 0s 79ms/step - loss: 0.0013 - accuracy: 1.0000 - val_loss: 0.3888 - val_accuracy: 0.9286\n",
            "Epoch 2086/4000\n",
            "1/1 [==============================] - 0s 50ms/step - loss: 0.0013 - accuracy: 1.0000 - val_loss: 0.3889 - val_accuracy: 0.9286\n",
            "Epoch 2087/4000\n",
            "1/1 [==============================] - 0s 40ms/step - loss: 0.0013 - accuracy: 1.0000 - val_loss: 0.3890 - val_accuracy: 0.9286\n",
            "Epoch 2088/4000\n",
            "1/1 [==============================] - 0s 47ms/step - loss: 0.0013 - accuracy: 1.0000 - val_loss: 0.3891 - val_accuracy: 0.9286\n",
            "Epoch 2089/4000\n",
            "1/1 [==============================] - 0s 41ms/step - loss: 0.0013 - accuracy: 1.0000 - val_loss: 0.3892 - val_accuracy: 0.9286\n",
            "Epoch 2090/4000\n",
            "1/1 [==============================] - 0s 47ms/step - loss: 0.0013 - accuracy: 1.0000 - val_loss: 0.3893 - val_accuracy: 0.9286\n",
            "Epoch 2091/4000\n",
            "1/1 [==============================] - 0s 41ms/step - loss: 0.0013 - accuracy: 1.0000 - val_loss: 0.3893 - val_accuracy: 0.9286\n",
            "Epoch 2092/4000\n",
            "1/1 [==============================] - 0s 45ms/step - loss: 0.0013 - accuracy: 1.0000 - val_loss: 0.3894 - val_accuracy: 0.9286\n",
            "Epoch 2093/4000\n",
            "1/1 [==============================] - 0s 56ms/step - loss: 0.0013 - accuracy: 1.0000 - val_loss: 0.3895 - val_accuracy: 0.9286\n",
            "Epoch 2094/4000\n",
            "1/1 [==============================] - 0s 40ms/step - loss: 0.0013 - accuracy: 1.0000 - val_loss: 0.3896 - val_accuracy: 0.9286\n",
            "Epoch 2095/4000\n",
            "1/1 [==============================] - 0s 46ms/step - loss: 0.0013 - accuracy: 1.0000 - val_loss: 0.3897 - val_accuracy: 0.9286\n",
            "Epoch 2096/4000\n",
            "1/1 [==============================] - 0s 52ms/step - loss: 0.0013 - accuracy: 1.0000 - val_loss: 0.3898 - val_accuracy: 0.9286\n",
            "Epoch 2097/4000\n",
            "1/1 [==============================] - 0s 35ms/step - loss: 0.0013 - accuracy: 1.0000 - val_loss: 0.3898 - val_accuracy: 0.9286\n",
            "Epoch 2098/4000\n",
            "1/1 [==============================] - 0s 49ms/step - loss: 0.0013 - accuracy: 1.0000 - val_loss: 0.3899 - val_accuracy: 0.9286\n",
            "Epoch 2099/4000\n",
            "1/1 [==============================] - 0s 52ms/step - loss: 0.0013 - accuracy: 1.0000 - val_loss: 0.3900 - val_accuracy: 0.9286\n",
            "Epoch 2100/4000\n",
            "1/1 [==============================] - 0s 46ms/step - loss: 0.0013 - accuracy: 1.0000 - val_loss: 0.3901 - val_accuracy: 0.9286\n",
            "Epoch 2101/4000\n",
            "1/1 [==============================] - 0s 55ms/step - loss: 0.0013 - accuracy: 1.0000 - val_loss: 0.3902 - val_accuracy: 0.9286\n",
            "Epoch 2102/4000\n",
            "1/1 [==============================] - 0s 38ms/step - loss: 0.0013 - accuracy: 1.0000 - val_loss: 0.3903 - val_accuracy: 0.9286\n",
            "Epoch 2103/4000\n",
            "1/1 [==============================] - 0s 37ms/step - loss: 0.0013 - accuracy: 1.0000 - val_loss: 0.3904 - val_accuracy: 0.9286\n",
            "Epoch 2104/4000\n",
            "1/1 [==============================] - 0s 48ms/step - loss: 0.0013 - accuracy: 1.0000 - val_loss: 0.3905 - val_accuracy: 0.9286\n",
            "Epoch 2105/4000\n",
            "1/1 [==============================] - 0s 34ms/step - loss: 0.0013 - accuracy: 1.0000 - val_loss: 0.3906 - val_accuracy: 0.9286\n",
            "Epoch 2106/4000\n",
            "1/1 [==============================] - 0s 47ms/step - loss: 0.0013 - accuracy: 1.0000 - val_loss: 0.3906 - val_accuracy: 0.9286\n",
            "Epoch 2107/4000\n",
            "1/1 [==============================] - 0s 49ms/step - loss: 0.0013 - accuracy: 1.0000 - val_loss: 0.3907 - val_accuracy: 0.9286\n",
            "Epoch 2108/4000\n",
            "1/1 [==============================] - 0s 48ms/step - loss: 0.0013 - accuracy: 1.0000 - val_loss: 0.3908 - val_accuracy: 0.9286\n",
            "Epoch 2109/4000\n",
            "1/1 [==============================] - 0s 49ms/step - loss: 0.0013 - accuracy: 1.0000 - val_loss: 0.3909 - val_accuracy: 0.9286\n",
            "Epoch 2110/4000\n",
            "1/1 [==============================] - 0s 50ms/step - loss: 0.0013 - accuracy: 1.0000 - val_loss: 0.3910 - val_accuracy: 0.9286\n",
            "Epoch 2111/4000\n",
            "1/1 [==============================] - 0s 51ms/step - loss: 0.0013 - accuracy: 1.0000 - val_loss: 0.3911 - val_accuracy: 0.9286\n",
            "Epoch 2112/4000\n",
            "1/1 [==============================] - 0s 49ms/step - loss: 0.0013 - accuracy: 1.0000 - val_loss: 0.3912 - val_accuracy: 0.9286\n",
            "Epoch 2113/4000\n",
            "1/1 [==============================] - 0s 46ms/step - loss: 0.0013 - accuracy: 1.0000 - val_loss: 0.3913 - val_accuracy: 0.9286\n",
            "Epoch 2114/4000\n",
            "1/1 [==============================] - 0s 38ms/step - loss: 0.0013 - accuracy: 1.0000 - val_loss: 0.3913 - val_accuracy: 0.9286\n",
            "Epoch 2115/4000\n",
            "1/1 [==============================] - 0s 47ms/step - loss: 0.0013 - accuracy: 1.0000 - val_loss: 0.3914 - val_accuracy: 0.9286\n",
            "Epoch 2116/4000\n",
            "1/1 [==============================] - 0s 35ms/step - loss: 0.0013 - accuracy: 1.0000 - val_loss: 0.3915 - val_accuracy: 0.9286\n",
            "Epoch 2117/4000\n",
            "1/1 [==============================] - 0s 37ms/step - loss: 0.0013 - accuracy: 1.0000 - val_loss: 0.3916 - val_accuracy: 0.9286\n",
            "Epoch 2118/4000\n",
            "1/1 [==============================] - 0s 50ms/step - loss: 0.0013 - accuracy: 1.0000 - val_loss: 0.3917 - val_accuracy: 0.9286\n",
            "Epoch 2119/4000\n",
            "1/1 [==============================] - 0s 48ms/step - loss: 0.0013 - accuracy: 1.0000 - val_loss: 0.3918 - val_accuracy: 0.9286\n",
            "Epoch 2120/4000\n",
            "1/1 [==============================] - 0s 56ms/step - loss: 0.0013 - accuracy: 1.0000 - val_loss: 0.3919 - val_accuracy: 0.9286\n",
            "Epoch 2121/4000\n",
            "1/1 [==============================] - 0s 34ms/step - loss: 0.0013 - accuracy: 1.0000 - val_loss: 0.3919 - val_accuracy: 0.9286\n",
            "Epoch 2122/4000\n",
            "1/1 [==============================] - 0s 48ms/step - loss: 0.0013 - accuracy: 1.0000 - val_loss: 0.3920 - val_accuracy: 0.9286\n",
            "Epoch 2123/4000\n",
            "1/1 [==============================] - 0s 47ms/step - loss: 0.0013 - accuracy: 1.0000 - val_loss: 0.3921 - val_accuracy: 0.9286\n",
            "Epoch 2124/4000\n",
            "1/1 [==============================] - 0s 48ms/step - loss: 0.0013 - accuracy: 1.0000 - val_loss: 0.3922 - val_accuracy: 0.9286\n",
            "Epoch 2125/4000\n",
            "1/1 [==============================] - 0s 54ms/step - loss: 0.0013 - accuracy: 1.0000 - val_loss: 0.3923 - val_accuracy: 0.9286\n",
            "Epoch 2126/4000\n",
            "1/1 [==============================] - 0s 47ms/step - loss: 0.0013 - accuracy: 1.0000 - val_loss: 0.3924 - val_accuracy: 0.9286\n",
            "Epoch 2127/4000\n",
            "1/1 [==============================] - 0s 37ms/step - loss: 0.0013 - accuracy: 1.0000 - val_loss: 0.3925 - val_accuracy: 0.9286\n",
            "Epoch 2128/4000\n",
            "1/1 [==============================] - 0s 47ms/step - loss: 0.0013 - accuracy: 1.0000 - val_loss: 0.3926 - val_accuracy: 0.9286\n",
            "Epoch 2129/4000\n",
            "1/1 [==============================] - 0s 47ms/step - loss: 0.0013 - accuracy: 1.0000 - val_loss: 0.3926 - val_accuracy: 0.9286\n",
            "Epoch 2130/4000\n",
            "1/1 [==============================] - 0s 43ms/step - loss: 0.0013 - accuracy: 1.0000 - val_loss: 0.3927 - val_accuracy: 0.9286\n",
            "Epoch 2131/4000\n",
            "1/1 [==============================] - 0s 47ms/step - loss: 0.0013 - accuracy: 1.0000 - val_loss: 0.3928 - val_accuracy: 0.9286\n",
            "Epoch 2132/4000\n",
            "1/1 [==============================] - 0s 49ms/step - loss: 0.0013 - accuracy: 1.0000 - val_loss: 0.3929 - val_accuracy: 0.9286\n",
            "Epoch 2133/4000\n",
            "1/1 [==============================] - 0s 46ms/step - loss: 0.0013 - accuracy: 1.0000 - val_loss: 0.3930 - val_accuracy: 0.9286\n",
            "Epoch 2134/4000\n",
            "1/1 [==============================] - 0s 51ms/step - loss: 0.0013 - accuracy: 1.0000 - val_loss: 0.3930 - val_accuracy: 0.9286\n",
            "Epoch 2135/4000\n",
            "1/1 [==============================] - 0s 47ms/step - loss: 0.0013 - accuracy: 1.0000 - val_loss: 0.3931 - val_accuracy: 0.9286\n",
            "Epoch 2136/4000\n",
            "1/1 [==============================] - 0s 47ms/step - loss: 0.0013 - accuracy: 1.0000 - val_loss: 0.3932 - val_accuracy: 0.9286\n",
            "Epoch 2137/4000\n",
            "1/1 [==============================] - 0s 51ms/step - loss: 0.0013 - accuracy: 1.0000 - val_loss: 0.3933 - val_accuracy: 0.9286\n",
            "Epoch 2138/4000\n",
            "1/1 [==============================] - 0s 46ms/step - loss: 0.0013 - accuracy: 1.0000 - val_loss: 0.3934 - val_accuracy: 0.9286\n",
            "Epoch 2139/4000\n",
            "1/1 [==============================] - 0s 52ms/step - loss: 0.0013 - accuracy: 1.0000 - val_loss: 0.3935 - val_accuracy: 0.9286\n",
            "Epoch 2140/4000\n",
            "1/1 [==============================] - 0s 49ms/step - loss: 0.0013 - accuracy: 1.0000 - val_loss: 0.3936 - val_accuracy: 0.9286\n",
            "Epoch 2141/4000\n",
            "1/1 [==============================] - 0s 51ms/step - loss: 0.0012 - accuracy: 1.0000 - val_loss: 0.3937 - val_accuracy: 0.9286\n",
            "Epoch 2142/4000\n",
            "1/1 [==============================] - 0s 49ms/step - loss: 0.0012 - accuracy: 1.0000 - val_loss: 0.3938 - val_accuracy: 0.9286\n",
            "Epoch 2143/4000\n",
            "1/1 [==============================] - 0s 34ms/step - loss: 0.0012 - accuracy: 1.0000 - val_loss: 0.3938 - val_accuracy: 0.9286\n",
            "Epoch 2144/4000\n",
            "1/1 [==============================] - 0s 48ms/step - loss: 0.0012 - accuracy: 1.0000 - val_loss: 0.3939 - val_accuracy: 0.9286\n",
            "Epoch 2145/4000\n",
            "1/1 [==============================] - 0s 49ms/step - loss: 0.0012 - accuracy: 1.0000 - val_loss: 0.3940 - val_accuracy: 0.9286\n",
            "Epoch 2146/4000\n",
            "1/1 [==============================] - 0s 53ms/step - loss: 0.0012 - accuracy: 1.0000 - val_loss: 0.3941 - val_accuracy: 0.9286\n",
            "Epoch 2147/4000\n",
            "1/1 [==============================] - 0s 48ms/step - loss: 0.0012 - accuracy: 1.0000 - val_loss: 0.3942 - val_accuracy: 0.9286\n",
            "Epoch 2148/4000\n",
            "1/1 [==============================] - 0s 40ms/step - loss: 0.0012 - accuracy: 1.0000 - val_loss: 0.3943 - val_accuracy: 0.9286\n",
            "Epoch 2149/4000\n",
            "1/1 [==============================] - 0s 46ms/step - loss: 0.0012 - accuracy: 1.0000 - val_loss: 0.3943 - val_accuracy: 0.9286\n",
            "Epoch 2150/4000\n",
            "1/1 [==============================] - 0s 50ms/step - loss: 0.0012 - accuracy: 1.0000 - val_loss: 0.3944 - val_accuracy: 0.9286\n",
            "Epoch 2151/4000\n",
            "1/1 [==============================] - 0s 49ms/step - loss: 0.0012 - accuracy: 1.0000 - val_loss: 0.3945 - val_accuracy: 0.9286\n",
            "Epoch 2152/4000\n",
            "1/1 [==============================] - 0s 48ms/step - loss: 0.0012 - accuracy: 1.0000 - val_loss: 0.3946 - val_accuracy: 0.9286\n",
            "Epoch 2153/4000\n",
            "1/1 [==============================] - 0s 45ms/step - loss: 0.0012 - accuracy: 1.0000 - val_loss: 0.3947 - val_accuracy: 0.9286\n",
            "Epoch 2154/4000\n",
            "1/1 [==============================] - 0s 49ms/step - loss: 0.0012 - accuracy: 1.0000 - val_loss: 0.3947 - val_accuracy: 0.9286\n",
            "Epoch 2155/4000\n",
            "1/1 [==============================] - 0s 51ms/step - loss: 0.0012 - accuracy: 1.0000 - val_loss: 0.3948 - val_accuracy: 0.9286\n",
            "Epoch 2156/4000\n",
            "1/1 [==============================] - 0s 49ms/step - loss: 0.0012 - accuracy: 1.0000 - val_loss: 0.3949 - val_accuracy: 0.9286\n",
            "Epoch 2157/4000\n",
            "1/1 [==============================] - 0s 49ms/step - loss: 0.0012 - accuracy: 1.0000 - val_loss: 0.3950 - val_accuracy: 0.9286\n",
            "Epoch 2158/4000\n",
            "1/1 [==============================] - 0s 48ms/step - loss: 0.0012 - accuracy: 1.0000 - val_loss: 0.3951 - val_accuracy: 0.9286\n",
            "Epoch 2159/4000\n",
            "1/1 [==============================] - 0s 45ms/step - loss: 0.0012 - accuracy: 1.0000 - val_loss: 0.3952 - val_accuracy: 0.9286\n",
            "Epoch 2160/4000\n",
            "1/1 [==============================] - 0s 36ms/step - loss: 0.0012 - accuracy: 1.0000 - val_loss: 0.3953 - val_accuracy: 0.9286\n",
            "Epoch 2161/4000\n",
            "1/1 [==============================] - 0s 53ms/step - loss: 0.0012 - accuracy: 1.0000 - val_loss: 0.3954 - val_accuracy: 0.9286\n",
            "Epoch 2162/4000\n",
            "1/1 [==============================] - 0s 47ms/step - loss: 0.0012 - accuracy: 1.0000 - val_loss: 0.3955 - val_accuracy: 0.9286\n",
            "Epoch 2163/4000\n",
            "1/1 [==============================] - 0s 50ms/step - loss: 0.0012 - accuracy: 1.0000 - val_loss: 0.3955 - val_accuracy: 0.9286\n",
            "Epoch 2164/4000\n",
            "1/1 [==============================] - 0s 50ms/step - loss: 0.0012 - accuracy: 1.0000 - val_loss: 0.3956 - val_accuracy: 0.9286\n",
            "Epoch 2165/4000\n",
            "1/1 [==============================] - 0s 37ms/step - loss: 0.0012 - accuracy: 1.0000 - val_loss: 0.3957 - val_accuracy: 0.9286\n",
            "Epoch 2166/4000\n",
            "1/1 [==============================] - 0s 47ms/step - loss: 0.0012 - accuracy: 1.0000 - val_loss: 0.3958 - val_accuracy: 0.9286\n",
            "Epoch 2167/4000\n",
            "1/1 [==============================] - 0s 33ms/step - loss: 0.0012 - accuracy: 1.0000 - val_loss: 0.3959 - val_accuracy: 0.9286\n",
            "Epoch 2168/4000\n",
            "1/1 [==============================] - 0s 47ms/step - loss: 0.0012 - accuracy: 1.0000 - val_loss: 0.3960 - val_accuracy: 0.9286\n",
            "Epoch 2169/4000\n",
            "1/1 [==============================] - 0s 52ms/step - loss: 0.0012 - accuracy: 1.0000 - val_loss: 0.3960 - val_accuracy: 0.9286\n",
            "Epoch 2170/4000\n",
            "1/1 [==============================] - 0s 51ms/step - loss: 0.0012 - accuracy: 1.0000 - val_loss: 0.3961 - val_accuracy: 0.9286\n",
            "Epoch 2171/4000\n",
            "1/1 [==============================] - 0s 47ms/step - loss: 0.0012 - accuracy: 1.0000 - val_loss: 0.3962 - val_accuracy: 0.9286\n",
            "Epoch 2172/4000\n",
            "1/1 [==============================] - 0s 49ms/step - loss: 0.0012 - accuracy: 1.0000 - val_loss: 0.3963 - val_accuracy: 0.9286\n",
            "Epoch 2173/4000\n",
            "1/1 [==============================] - 0s 43ms/step - loss: 0.0012 - accuracy: 1.0000 - val_loss: 0.3964 - val_accuracy: 0.9286\n",
            "Epoch 2174/4000\n",
            "1/1 [==============================] - 0s 46ms/step - loss: 0.0012 - accuracy: 1.0000 - val_loss: 0.3965 - val_accuracy: 0.9286\n",
            "Epoch 2175/4000\n",
            "1/1 [==============================] - 0s 37ms/step - loss: 0.0012 - accuracy: 1.0000 - val_loss: 0.3965 - val_accuracy: 0.9286\n",
            "Epoch 2176/4000\n",
            "1/1 [==============================] - 0s 48ms/step - loss: 0.0012 - accuracy: 1.0000 - val_loss: 0.3966 - val_accuracy: 0.9286\n",
            "Epoch 2177/4000\n",
            "1/1 [==============================] - 0s 34ms/step - loss: 0.0012 - accuracy: 1.0000 - val_loss: 0.3967 - val_accuracy: 0.9286\n",
            "Epoch 2178/4000\n",
            "1/1 [==============================] - 0s 51ms/step - loss: 0.0012 - accuracy: 1.0000 - val_loss: 0.3968 - val_accuracy: 0.9286\n",
            "Epoch 2179/4000\n",
            "1/1 [==============================] - 0s 36ms/step - loss: 0.0012 - accuracy: 1.0000 - val_loss: 0.3969 - val_accuracy: 0.9286\n",
            "Epoch 2180/4000\n",
            "1/1 [==============================] - 0s 51ms/step - loss: 0.0012 - accuracy: 1.0000 - val_loss: 0.3970 - val_accuracy: 0.9286\n",
            "Epoch 2181/4000\n",
            "1/1 [==============================] - 0s 47ms/step - loss: 0.0012 - accuracy: 1.0000 - val_loss: 0.3971 - val_accuracy: 0.9286\n",
            "Epoch 2182/4000\n",
            "1/1 [==============================] - 0s 47ms/step - loss: 0.0012 - accuracy: 1.0000 - val_loss: 0.3971 - val_accuracy: 0.9286\n",
            "Epoch 2183/4000\n",
            "1/1 [==============================] - 0s 35ms/step - loss: 0.0012 - accuracy: 1.0000 - val_loss: 0.3972 - val_accuracy: 0.9286\n",
            "Epoch 2184/4000\n",
            "1/1 [==============================] - 0s 39ms/step - loss: 0.0012 - accuracy: 1.0000 - val_loss: 0.3973 - val_accuracy: 0.9286\n",
            "Epoch 2185/4000\n",
            "1/1 [==============================] - 0s 34ms/step - loss: 0.0012 - accuracy: 1.0000 - val_loss: 0.3974 - val_accuracy: 0.9286\n",
            "Epoch 2186/4000\n",
            "1/1 [==============================] - 0s 48ms/step - loss: 0.0012 - accuracy: 1.0000 - val_loss: 0.3975 - val_accuracy: 0.9286\n",
            "Epoch 2187/4000\n",
            "1/1 [==============================] - 0s 47ms/step - loss: 0.0012 - accuracy: 1.0000 - val_loss: 0.3975 - val_accuracy: 0.9286\n",
            "Epoch 2188/4000\n",
            "1/1 [==============================] - 0s 53ms/step - loss: 0.0012 - accuracy: 1.0000 - val_loss: 0.3976 - val_accuracy: 0.9286\n",
            "Epoch 2189/4000\n",
            "1/1 [==============================] - 0s 47ms/step - loss: 0.0012 - accuracy: 1.0000 - val_loss: 0.3977 - val_accuracy: 0.9286\n",
            "Epoch 2190/4000\n",
            "1/1 [==============================] - 0s 52ms/step - loss: 0.0012 - accuracy: 1.0000 - val_loss: 0.3978 - val_accuracy: 0.9286\n",
            "Epoch 2191/4000\n",
            "1/1 [==============================] - 0s 33ms/step - loss: 0.0012 - accuracy: 1.0000 - val_loss: 0.3979 - val_accuracy: 0.9286\n",
            "Epoch 2192/4000\n",
            "1/1 [==============================] - 0s 54ms/step - loss: 0.0012 - accuracy: 1.0000 - val_loss: 0.3980 - val_accuracy: 0.9286\n",
            "Epoch 2193/4000\n",
            "1/1 [==============================] - 0s 33ms/step - loss: 0.0012 - accuracy: 1.0000 - val_loss: 0.3981 - val_accuracy: 0.9286\n",
            "Epoch 2194/4000\n",
            "1/1 [==============================] - 0s 53ms/step - loss: 0.0012 - accuracy: 1.0000 - val_loss: 0.3981 - val_accuracy: 0.9286\n",
            "Epoch 2195/4000\n",
            "1/1 [==============================] - 0s 42ms/step - loss: 0.0012 - accuracy: 1.0000 - val_loss: 0.3982 - val_accuracy: 0.9286\n",
            "Epoch 2196/4000\n",
            "1/1 [==============================] - 0s 35ms/step - loss: 0.0012 - accuracy: 1.0000 - val_loss: 0.3983 - val_accuracy: 0.9286\n",
            "Epoch 2197/4000\n",
            "1/1 [==============================] - 0s 37ms/step - loss: 0.0012 - accuracy: 1.0000 - val_loss: 0.3984 - val_accuracy: 0.9286\n",
            "Epoch 2198/4000\n",
            "1/1 [==============================] - 0s 47ms/step - loss: 0.0012 - accuracy: 1.0000 - val_loss: 0.3985 - val_accuracy: 0.9286\n",
            "Epoch 2199/4000\n",
            "1/1 [==============================] - 0s 42ms/step - loss: 0.0012 - accuracy: 1.0000 - val_loss: 0.3985 - val_accuracy: 0.9286\n",
            "Epoch 2200/4000\n",
            "1/1 [==============================] - 0s 36ms/step - loss: 0.0012 - accuracy: 1.0000 - val_loss: 0.3986 - val_accuracy: 0.9286\n",
            "Epoch 2201/4000\n",
            "1/1 [==============================] - 0s 49ms/step - loss: 0.0012 - accuracy: 1.0000 - val_loss: 0.3987 - val_accuracy: 0.9286\n",
            "Epoch 2202/4000\n",
            "1/1 [==============================] - 0s 35ms/step - loss: 0.0012 - accuracy: 1.0000 - val_loss: 0.3988 - val_accuracy: 0.9286\n",
            "Epoch 2203/4000\n",
            "1/1 [==============================] - 0s 37ms/step - loss: 0.0011 - accuracy: 1.0000 - val_loss: 0.3989 - val_accuracy: 0.9286\n",
            "Epoch 2204/4000\n",
            "1/1 [==============================] - 0s 54ms/step - loss: 0.0011 - accuracy: 1.0000 - val_loss: 0.3990 - val_accuracy: 0.9286\n",
            "Epoch 2205/4000\n",
            "1/1 [==============================] - 0s 35ms/step - loss: 0.0011 - accuracy: 1.0000 - val_loss: 0.3991 - val_accuracy: 0.9286\n",
            "Epoch 2206/4000\n",
            "1/1 [==============================] - 0s 49ms/step - loss: 0.0011 - accuracy: 1.0000 - val_loss: 0.3991 - val_accuracy: 0.9286\n",
            "Epoch 2207/4000\n",
            "1/1 [==============================] - 0s 47ms/step - loss: 0.0011 - accuracy: 1.0000 - val_loss: 0.3992 - val_accuracy: 0.9286\n",
            "Epoch 2208/4000\n",
            "1/1 [==============================] - 0s 37ms/step - loss: 0.0011 - accuracy: 1.0000 - val_loss: 0.3993 - val_accuracy: 0.9286\n",
            "Epoch 2209/4000\n",
            "1/1 [==============================] - 0s 47ms/step - loss: 0.0011 - accuracy: 1.0000 - val_loss: 0.3994 - val_accuracy: 0.9286\n",
            "Epoch 2210/4000\n",
            "1/1 [==============================] - 0s 48ms/step - loss: 0.0011 - accuracy: 1.0000 - val_loss: 0.3995 - val_accuracy: 0.9286\n",
            "Epoch 2211/4000\n",
            "1/1 [==============================] - 0s 37ms/step - loss: 0.0011 - accuracy: 1.0000 - val_loss: 0.3995 - val_accuracy: 0.9286\n",
            "Epoch 2212/4000\n",
            "1/1 [==============================] - 0s 50ms/step - loss: 0.0011 - accuracy: 1.0000 - val_loss: 0.3996 - val_accuracy: 0.9286\n",
            "Epoch 2213/4000\n",
            "1/1 [==============================] - 0s 48ms/step - loss: 0.0011 - accuracy: 1.0000 - val_loss: 0.3997 - val_accuracy: 0.9286\n",
            "Epoch 2214/4000\n",
            "1/1 [==============================] - 0s 45ms/step - loss: 0.0011 - accuracy: 1.0000 - val_loss: 0.3998 - val_accuracy: 0.9286\n",
            "Epoch 2215/4000\n",
            "1/1 [==============================] - 0s 52ms/step - loss: 0.0011 - accuracy: 1.0000 - val_loss: 0.3999 - val_accuracy: 0.9286\n",
            "Epoch 2216/4000\n",
            "1/1 [==============================] - 0s 33ms/step - loss: 0.0011 - accuracy: 1.0000 - val_loss: 0.4000 - val_accuracy: 0.9286\n",
            "Epoch 2217/4000\n",
            "1/1 [==============================] - 0s 39ms/step - loss: 0.0011 - accuracy: 1.0000 - val_loss: 0.4001 - val_accuracy: 0.9286\n",
            "Epoch 2218/4000\n",
            "1/1 [==============================] - 0s 48ms/step - loss: 0.0011 - accuracy: 1.0000 - val_loss: 0.4002 - val_accuracy: 0.9286\n",
            "Epoch 2219/4000\n",
            "1/1 [==============================] - 0s 47ms/step - loss: 0.0011 - accuracy: 1.0000 - val_loss: 0.4002 - val_accuracy: 0.9286\n",
            "Epoch 2220/4000\n",
            "1/1 [==============================] - 0s 42ms/step - loss: 0.0011 - accuracy: 1.0000 - val_loss: 0.4003 - val_accuracy: 0.9286\n",
            "Epoch 2221/4000\n",
            "1/1 [==============================] - 0s 38ms/step - loss: 0.0011 - accuracy: 1.0000 - val_loss: 0.4004 - val_accuracy: 0.9286\n",
            "Epoch 2222/4000\n",
            "1/1 [==============================] - 0s 50ms/step - loss: 0.0011 - accuracy: 1.0000 - val_loss: 0.4005 - val_accuracy: 0.9286\n",
            "Epoch 2223/4000\n",
            "1/1 [==============================] - 0s 48ms/step - loss: 0.0011 - accuracy: 1.0000 - val_loss: 0.4005 - val_accuracy: 0.9286\n",
            "Epoch 2224/4000\n",
            "1/1 [==============================] - 0s 36ms/step - loss: 0.0011 - accuracy: 1.0000 - val_loss: 0.4006 - val_accuracy: 0.9286\n",
            "Epoch 2225/4000\n",
            "1/1 [==============================] - 0s 47ms/step - loss: 0.0011 - accuracy: 1.0000 - val_loss: 0.4007 - val_accuracy: 0.9286\n",
            "Epoch 2226/4000\n",
            "1/1 [==============================] - 0s 51ms/step - loss: 0.0011 - accuracy: 1.0000 - val_loss: 0.4008 - val_accuracy: 0.9286\n",
            "Epoch 2227/4000\n",
            "1/1 [==============================] - 0s 48ms/step - loss: 0.0011 - accuracy: 1.0000 - val_loss: 0.4009 - val_accuracy: 0.9286\n",
            "Epoch 2228/4000\n",
            "1/1 [==============================] - 0s 34ms/step - loss: 0.0011 - accuracy: 1.0000 - val_loss: 0.4010 - val_accuracy: 0.9286\n",
            "Epoch 2229/4000\n",
            "1/1 [==============================] - 0s 52ms/step - loss: 0.0011 - accuracy: 1.0000 - val_loss: 0.4011 - val_accuracy: 0.9286\n",
            "Epoch 2230/4000\n",
            "1/1 [==============================] - 0s 49ms/step - loss: 0.0011 - accuracy: 1.0000 - val_loss: 0.4011 - val_accuracy: 0.9286\n",
            "Epoch 2231/4000\n",
            "1/1 [==============================] - 0s 31ms/step - loss: 0.0011 - accuracy: 1.0000 - val_loss: 0.4012 - val_accuracy: 0.9286\n",
            "Epoch 2232/4000\n",
            "1/1 [==============================] - 0s 48ms/step - loss: 0.0011 - accuracy: 1.0000 - val_loss: 0.4013 - val_accuracy: 0.9286\n",
            "Epoch 2233/4000\n",
            "1/1 [==============================] - 0s 47ms/step - loss: 0.0011 - accuracy: 1.0000 - val_loss: 0.4014 - val_accuracy: 0.9286\n",
            "Epoch 2234/4000\n",
            "1/1 [==============================] - 0s 35ms/step - loss: 0.0011 - accuracy: 1.0000 - val_loss: 0.4015 - val_accuracy: 0.9286\n",
            "Epoch 2235/4000\n",
            "1/1 [==============================] - 0s 33ms/step - loss: 0.0011 - accuracy: 1.0000 - val_loss: 0.4015 - val_accuracy: 0.9286\n",
            "Epoch 2236/4000\n",
            "1/1 [==============================] - 0s 51ms/step - loss: 0.0011 - accuracy: 1.0000 - val_loss: 0.4016 - val_accuracy: 0.9286\n",
            "Epoch 2237/4000\n",
            "1/1 [==============================] - 0s 51ms/step - loss: 0.0011 - accuracy: 1.0000 - val_loss: 0.4017 - val_accuracy: 0.9286\n",
            "Epoch 2238/4000\n",
            "1/1 [==============================] - 0s 51ms/step - loss: 0.0011 - accuracy: 1.0000 - val_loss: 0.4018 - val_accuracy: 0.9286\n",
            "Epoch 2239/4000\n",
            "1/1 [==============================] - 0s 32ms/step - loss: 0.0011 - accuracy: 1.0000 - val_loss: 0.4019 - val_accuracy: 0.9286\n",
            "Epoch 2240/4000\n",
            "1/1 [==============================] - 0s 55ms/step - loss: 0.0011 - accuracy: 1.0000 - val_loss: 0.4020 - val_accuracy: 0.9286\n",
            "Epoch 2241/4000\n",
            "1/1 [==============================] - 0s 34ms/step - loss: 0.0011 - accuracy: 1.0000 - val_loss: 0.4020 - val_accuracy: 0.9286\n",
            "Epoch 2242/4000\n",
            "1/1 [==============================] - 0s 48ms/step - loss: 0.0011 - accuracy: 1.0000 - val_loss: 0.4021 - val_accuracy: 0.9286\n",
            "Epoch 2243/4000\n",
            "1/1 [==============================] - 0s 42ms/step - loss: 0.0011 - accuracy: 1.0000 - val_loss: 0.4022 - val_accuracy: 0.9286\n",
            "Epoch 2244/4000\n",
            "1/1 [==============================] - 0s 35ms/step - loss: 0.0011 - accuracy: 1.0000 - val_loss: 0.4023 - val_accuracy: 0.9286\n",
            "Epoch 2245/4000\n",
            "1/1 [==============================] - 0s 49ms/step - loss: 0.0011 - accuracy: 1.0000 - val_loss: 0.4024 - val_accuracy: 0.9286\n",
            "Epoch 2246/4000\n",
            "1/1 [==============================] - 0s 33ms/step - loss: 0.0011 - accuracy: 1.0000 - val_loss: 0.4024 - val_accuracy: 0.9286\n",
            "Epoch 2247/4000\n",
            "1/1 [==============================] - 0s 50ms/step - loss: 0.0011 - accuracy: 1.0000 - val_loss: 0.4025 - val_accuracy: 0.9286\n",
            "Epoch 2248/4000\n",
            "1/1 [==============================] - 0s 36ms/step - loss: 0.0011 - accuracy: 1.0000 - val_loss: 0.4026 - val_accuracy: 0.9286\n",
            "Epoch 2249/4000\n",
            "1/1 [==============================] - 0s 51ms/step - loss: 0.0011 - accuracy: 1.0000 - val_loss: 0.4027 - val_accuracy: 0.9286\n",
            "Epoch 2250/4000\n",
            "1/1 [==============================] - 0s 47ms/step - loss: 0.0011 - accuracy: 1.0000 - val_loss: 0.4028 - val_accuracy: 0.9286\n",
            "Epoch 2251/4000\n",
            "1/1 [==============================] - 0s 39ms/step - loss: 0.0011 - accuracy: 1.0000 - val_loss: 0.4028 - val_accuracy: 0.9286\n",
            "Epoch 2252/4000\n",
            "1/1 [==============================] - 0s 32ms/step - loss: 0.0011 - accuracy: 1.0000 - val_loss: 0.4029 - val_accuracy: 0.9286\n",
            "Epoch 2253/4000\n",
            "1/1 [==============================] - 0s 49ms/step - loss: 0.0011 - accuracy: 1.0000 - val_loss: 0.4030 - val_accuracy: 0.9286\n",
            "Epoch 2254/4000\n",
            "1/1 [==============================] - 0s 36ms/step - loss: 0.0011 - accuracy: 1.0000 - val_loss: 0.4031 - val_accuracy: 0.9286\n",
            "Epoch 2255/4000\n",
            "1/1 [==============================] - 0s 47ms/step - loss: 0.0011 - accuracy: 1.0000 - val_loss: 0.4032 - val_accuracy: 0.9286\n",
            "Epoch 2256/4000\n",
            "1/1 [==============================] - 0s 58ms/step - loss: 0.0011 - accuracy: 1.0000 - val_loss: 0.4033 - val_accuracy: 0.9286\n",
            "Epoch 2257/4000\n",
            "1/1 [==============================] - 0s 41ms/step - loss: 0.0011 - accuracy: 1.0000 - val_loss: 0.4033 - val_accuracy: 0.9286\n",
            "Epoch 2258/4000\n",
            "1/1 [==============================] - 0s 47ms/step - loss: 0.0011 - accuracy: 1.0000 - val_loss: 0.4034 - val_accuracy: 0.9286\n",
            "Epoch 2259/4000\n",
            "1/1 [==============================] - 0s 59ms/step - loss: 0.0011 - accuracy: 1.0000 - val_loss: 0.4035 - val_accuracy: 0.9286\n",
            "Epoch 2260/4000\n",
            "1/1 [==============================] - 0s 52ms/step - loss: 0.0011 - accuracy: 1.0000 - val_loss: 0.4036 - val_accuracy: 0.9286\n",
            "Epoch 2261/4000\n",
            "1/1 [==============================] - 0s 58ms/step - loss: 0.0011 - accuracy: 1.0000 - val_loss: 0.4037 - val_accuracy: 0.9286\n",
            "Epoch 2262/4000\n",
            "1/1 [==============================] - 0s 54ms/step - loss: 0.0011 - accuracy: 1.0000 - val_loss: 0.4037 - val_accuracy: 0.9286\n",
            "Epoch 2263/4000\n",
            "1/1 [==============================] - 0s 45ms/step - loss: 0.0011 - accuracy: 1.0000 - val_loss: 0.4038 - val_accuracy: 0.9286\n",
            "Epoch 2264/4000\n",
            "1/1 [==============================] - 0s 49ms/step - loss: 0.0011 - accuracy: 1.0000 - val_loss: 0.4039 - val_accuracy: 0.9286\n",
            "Epoch 2265/4000\n",
            "1/1 [==============================] - 0s 40ms/step - loss: 0.0011 - accuracy: 1.0000 - val_loss: 0.4040 - val_accuracy: 0.9286\n",
            "Epoch 2266/4000\n",
            "1/1 [==============================] - 0s 47ms/step - loss: 0.0011 - accuracy: 1.0000 - val_loss: 0.4041 - val_accuracy: 0.9286\n",
            "Epoch 2267/4000\n",
            "1/1 [==============================] - 0s 51ms/step - loss: 0.0011 - accuracy: 1.0000 - val_loss: 0.4042 - val_accuracy: 0.9286\n",
            "Epoch 2268/4000\n",
            "1/1 [==============================] - 0s 47ms/step - loss: 0.0011 - accuracy: 1.0000 - val_loss: 0.4042 - val_accuracy: 0.9286\n",
            "Epoch 2269/4000\n",
            "1/1 [==============================] - 0s 50ms/step - loss: 0.0011 - accuracy: 1.0000 - val_loss: 0.4043 - val_accuracy: 0.9286\n",
            "Epoch 2270/4000\n",
            "1/1 [==============================] - 0s 51ms/step - loss: 0.0011 - accuracy: 1.0000 - val_loss: 0.4044 - val_accuracy: 0.9286\n",
            "Epoch 2271/4000\n",
            "1/1 [==============================] - 0s 55ms/step - loss: 0.0011 - accuracy: 1.0000 - val_loss: 0.4045 - val_accuracy: 0.9286\n",
            "Epoch 2272/4000\n",
            "1/1 [==============================] - 0s 48ms/step - loss: 0.0011 - accuracy: 1.0000 - val_loss: 0.4045 - val_accuracy: 0.9286\n",
            "Epoch 2273/4000\n",
            "1/1 [==============================] - 0s 47ms/step - loss: 0.0010 - accuracy: 1.0000 - val_loss: 0.4046 - val_accuracy: 0.9286\n",
            "Epoch 2274/4000\n",
            "1/1 [==============================] - 0s 46ms/step - loss: 0.0010 - accuracy: 1.0000 - val_loss: 0.4047 - val_accuracy: 0.9286\n",
            "Epoch 2275/4000\n",
            "1/1 [==============================] - 0s 39ms/step - loss: 0.0010 - accuracy: 1.0000 - val_loss: 0.4048 - val_accuracy: 0.9286\n",
            "Epoch 2276/4000\n",
            "1/1 [==============================] - 0s 48ms/step - loss: 0.0010 - accuracy: 1.0000 - val_loss: 0.4049 - val_accuracy: 0.9286\n",
            "Epoch 2277/4000\n",
            "1/1 [==============================] - 0s 38ms/step - loss: 0.0010 - accuracy: 1.0000 - val_loss: 0.4049 - val_accuracy: 0.9286\n",
            "Epoch 2278/4000\n",
            "1/1 [==============================] - 0s 47ms/step - loss: 0.0010 - accuracy: 1.0000 - val_loss: 0.4050 - val_accuracy: 0.9286\n",
            "Epoch 2279/4000\n",
            "1/1 [==============================] - 0s 52ms/step - loss: 0.0010 - accuracy: 1.0000 - val_loss: 0.4051 - val_accuracy: 0.9286\n",
            "Epoch 2280/4000\n",
            "1/1 [==============================] - 0s 48ms/step - loss: 0.0010 - accuracy: 1.0000 - val_loss: 0.4052 - val_accuracy: 0.9286\n",
            "Epoch 2281/4000\n",
            "1/1 [==============================] - 0s 46ms/step - loss: 0.0010 - accuracy: 1.0000 - val_loss: 0.4053 - val_accuracy: 0.9286\n",
            "Epoch 2282/4000\n",
            "1/1 [==============================] - 0s 46ms/step - loss: 0.0010 - accuracy: 1.0000 - val_loss: 0.4054 - val_accuracy: 0.9286\n",
            "Epoch 2283/4000\n",
            "1/1 [==============================] - 0s 37ms/step - loss: 0.0010 - accuracy: 1.0000 - val_loss: 0.4054 - val_accuracy: 0.9286\n",
            "Epoch 2284/4000\n",
            "1/1 [==============================] - 0s 37ms/step - loss: 0.0010 - accuracy: 1.0000 - val_loss: 0.4055 - val_accuracy: 0.9286\n",
            "Epoch 2285/4000\n",
            "1/1 [==============================] - 0s 58ms/step - loss: 0.0010 - accuracy: 1.0000 - val_loss: 0.4056 - val_accuracy: 0.9286\n",
            "Epoch 2286/4000\n",
            "1/1 [==============================] - 0s 38ms/step - loss: 0.0010 - accuracy: 1.0000 - val_loss: 0.4057 - val_accuracy: 0.9286\n",
            "Epoch 2287/4000\n",
            "1/1 [==============================] - 0s 38ms/step - loss: 0.0010 - accuracy: 1.0000 - val_loss: 0.4057 - val_accuracy: 0.9286\n",
            "Epoch 2288/4000\n",
            "1/1 [==============================] - 0s 50ms/step - loss: 0.0010 - accuracy: 1.0000 - val_loss: 0.4058 - val_accuracy: 0.9286\n",
            "Epoch 2289/4000\n",
            "1/1 [==============================] - 0s 52ms/step - loss: 0.0010 - accuracy: 1.0000 - val_loss: 0.4059 - val_accuracy: 0.9286\n",
            "Epoch 2290/4000\n",
            "1/1 [==============================] - 0s 49ms/step - loss: 0.0010 - accuracy: 1.0000 - val_loss: 0.4060 - val_accuracy: 0.9286\n",
            "Epoch 2291/4000\n",
            "1/1 [==============================] - 0s 49ms/step - loss: 0.0010 - accuracy: 1.0000 - val_loss: 0.4061 - val_accuracy: 0.9286\n",
            "Epoch 2292/4000\n",
            "1/1 [==============================] - 0s 51ms/step - loss: 0.0010 - accuracy: 1.0000 - val_loss: 0.4062 - val_accuracy: 0.9286\n",
            "Epoch 2293/4000\n",
            "1/1 [==============================] - 0s 45ms/step - loss: 0.0010 - accuracy: 1.0000 - val_loss: 0.4062 - val_accuracy: 0.9286\n",
            "Epoch 2294/4000\n",
            "1/1 [==============================] - 0s 47ms/step - loss: 0.0010 - accuracy: 1.0000 - val_loss: 0.4063 - val_accuracy: 0.9286\n",
            "Epoch 2295/4000\n",
            "1/1 [==============================] - 0s 37ms/step - loss: 0.0010 - accuracy: 1.0000 - val_loss: 0.4064 - val_accuracy: 0.9286\n",
            "Epoch 2296/4000\n",
            "1/1 [==============================] - 0s 37ms/step - loss: 0.0010 - accuracy: 1.0000 - val_loss: 0.4065 - val_accuracy: 0.9286\n",
            "Epoch 2297/4000\n",
            "1/1 [==============================] - 0s 34ms/step - loss: 0.0010 - accuracy: 1.0000 - val_loss: 0.4066 - val_accuracy: 0.9286\n",
            "Epoch 2298/4000\n",
            "1/1 [==============================] - 0s 46ms/step - loss: 0.0010 - accuracy: 1.0000 - val_loss: 0.4066 - val_accuracy: 0.9286\n",
            "Epoch 2299/4000\n",
            "1/1 [==============================] - 0s 49ms/step - loss: 0.0010 - accuracy: 1.0000 - val_loss: 0.4067 - val_accuracy: 0.9286\n",
            "Epoch 2300/4000\n",
            "1/1 [==============================] - 0s 48ms/step - loss: 0.0010 - accuracy: 1.0000 - val_loss: 0.4068 - val_accuracy: 0.9286\n",
            "Epoch 2301/4000\n",
            "1/1 [==============================] - 0s 57ms/step - loss: 0.0010 - accuracy: 1.0000 - val_loss: 0.4069 - val_accuracy: 0.9286\n",
            "Epoch 2302/4000\n",
            "1/1 [==============================] - 0s 40ms/step - loss: 0.0010 - accuracy: 1.0000 - val_loss: 0.4070 - val_accuracy: 0.9286\n",
            "Epoch 2303/4000\n",
            "1/1 [==============================] - 0s 33ms/step - loss: 0.0010 - accuracy: 1.0000 - val_loss: 0.4070 - val_accuracy: 0.9286\n",
            "Epoch 2304/4000\n",
            "1/1 [==============================] - 0s 32ms/step - loss: 0.0010 - accuracy: 1.0000 - val_loss: 0.4071 - val_accuracy: 0.9286\n",
            "Epoch 2305/4000\n",
            "1/1 [==============================] - 0s 40ms/step - loss: 0.0010 - accuracy: 1.0000 - val_loss: 0.4072 - val_accuracy: 0.9286\n",
            "Epoch 2306/4000\n",
            "1/1 [==============================] - 0s 36ms/step - loss: 0.0010 - accuracy: 1.0000 - val_loss: 0.4073 - val_accuracy: 0.9286\n",
            "Epoch 2307/4000\n",
            "1/1 [==============================] - 0s 34ms/step - loss: 0.0010 - accuracy: 1.0000 - val_loss: 0.4074 - val_accuracy: 0.9286\n",
            "Epoch 2308/4000\n",
            "1/1 [==============================] - 0s 35ms/step - loss: 0.0010 - accuracy: 1.0000 - val_loss: 0.4074 - val_accuracy: 0.9286\n",
            "Epoch 2309/4000\n",
            "1/1 [==============================] - 0s 51ms/step - loss: 0.0010 - accuracy: 1.0000 - val_loss: 0.4075 - val_accuracy: 0.9286\n",
            "Epoch 2310/4000\n",
            "1/1 [==============================] - 0s 53ms/step - loss: 0.0010 - accuracy: 1.0000 - val_loss: 0.4076 - val_accuracy: 0.9286\n",
            "Epoch 2311/4000\n",
            "1/1 [==============================] - 0s 49ms/step - loss: 0.0010 - accuracy: 1.0000 - val_loss: 0.4077 - val_accuracy: 0.9286\n",
            "Epoch 2312/4000\n",
            "1/1 [==============================] - 0s 48ms/step - loss: 9.9943e-04 - accuracy: 1.0000 - val_loss: 0.4078 - val_accuracy: 0.9286\n",
            "Epoch 2313/4000\n",
            "1/1 [==============================] - 0s 48ms/step - loss: 9.9819e-04 - accuracy: 1.0000 - val_loss: 0.4078 - val_accuracy: 0.9286\n",
            "Epoch 2314/4000\n",
            "1/1 [==============================] - 0s 35ms/step - loss: 9.9696e-04 - accuracy: 1.0000 - val_loss: 0.4079 - val_accuracy: 0.9286\n",
            "Epoch 2315/4000\n",
            "1/1 [==============================] - 0s 49ms/step - loss: 9.9570e-04 - accuracy: 1.0000 - val_loss: 0.4080 - val_accuracy: 0.9286\n",
            "Epoch 2316/4000\n",
            "1/1 [==============================] - 0s 41ms/step - loss: 9.9444e-04 - accuracy: 1.0000 - val_loss: 0.4081 - val_accuracy: 0.9286\n",
            "Epoch 2317/4000\n",
            "1/1 [==============================] - 0s 33ms/step - loss: 9.9324e-04 - accuracy: 1.0000 - val_loss: 0.4082 - val_accuracy: 0.9286\n",
            "Epoch 2318/4000\n",
            "1/1 [==============================] - 0s 47ms/step - loss: 9.9199e-04 - accuracy: 1.0000 - val_loss: 0.4083 - val_accuracy: 0.9286\n",
            "Epoch 2319/4000\n",
            "1/1 [==============================] - 0s 55ms/step - loss: 9.9075e-04 - accuracy: 1.0000 - val_loss: 0.4083 - val_accuracy: 0.9286\n",
            "Epoch 2320/4000\n",
            "1/1 [==============================] - 0s 52ms/step - loss: 9.8948e-04 - accuracy: 1.0000 - val_loss: 0.4084 - val_accuracy: 0.9286\n",
            "Epoch 2321/4000\n",
            "1/1 [==============================] - 0s 46ms/step - loss: 9.8828e-04 - accuracy: 1.0000 - val_loss: 0.4085 - val_accuracy: 0.9286\n",
            "Epoch 2322/4000\n",
            "1/1 [==============================] - 0s 53ms/step - loss: 9.8704e-04 - accuracy: 1.0000 - val_loss: 0.4085 - val_accuracy: 0.9286\n",
            "Epoch 2323/4000\n",
            "1/1 [==============================] - 0s 33ms/step - loss: 9.8582e-04 - accuracy: 1.0000 - val_loss: 0.4086 - val_accuracy: 0.9286\n",
            "Epoch 2324/4000\n",
            "1/1 [==============================] - 0s 46ms/step - loss: 9.8459e-04 - accuracy: 1.0000 - val_loss: 0.4087 - val_accuracy: 0.9286\n",
            "Epoch 2325/4000\n",
            "1/1 [==============================] - 0s 48ms/step - loss: 9.8339e-04 - accuracy: 1.0000 - val_loss: 0.4088 - val_accuracy: 0.9286\n",
            "Epoch 2326/4000\n",
            "1/1 [==============================] - 0s 48ms/step - loss: 9.8221e-04 - accuracy: 1.0000 - val_loss: 0.4089 - val_accuracy: 0.9286\n",
            "Epoch 2327/4000\n",
            "1/1 [==============================] - 0s 51ms/step - loss: 9.8099e-04 - accuracy: 1.0000 - val_loss: 0.4090 - val_accuracy: 0.9286\n",
            "Epoch 2328/4000\n",
            "1/1 [==============================] - 0s 47ms/step - loss: 9.7974e-04 - accuracy: 1.0000 - val_loss: 0.4090 - val_accuracy: 0.9286\n",
            "Epoch 2329/4000\n",
            "1/1 [==============================] - 0s 51ms/step - loss: 9.7858e-04 - accuracy: 1.0000 - val_loss: 0.4091 - val_accuracy: 0.9286\n",
            "Epoch 2330/4000\n",
            "1/1 [==============================] - 0s 33ms/step - loss: 9.7744e-04 - accuracy: 1.0000 - val_loss: 0.4092 - val_accuracy: 0.9286\n",
            "Epoch 2331/4000\n",
            "1/1 [==============================] - 0s 49ms/step - loss: 9.7622e-04 - accuracy: 1.0000 - val_loss: 0.4093 - val_accuracy: 0.9286\n",
            "Epoch 2332/4000\n",
            "1/1 [==============================] - 0s 48ms/step - loss: 9.7490e-04 - accuracy: 1.0000 - val_loss: 0.4093 - val_accuracy: 0.9286\n",
            "Epoch 2333/4000\n",
            "1/1 [==============================] - 0s 51ms/step - loss: 9.7372e-04 - accuracy: 1.0000 - val_loss: 0.4094 - val_accuracy: 0.9286\n",
            "Epoch 2334/4000\n",
            "1/1 [==============================] - 0s 35ms/step - loss: 9.7262e-04 - accuracy: 1.0000 - val_loss: 0.4095 - val_accuracy: 0.9286\n",
            "Epoch 2335/4000\n",
            "1/1 [==============================] - 0s 59ms/step - loss: 9.7138e-04 - accuracy: 1.0000 - val_loss: 0.4096 - val_accuracy: 0.9286\n",
            "Epoch 2336/4000\n",
            "1/1 [==============================] - 0s 48ms/step - loss: 9.7012e-04 - accuracy: 1.0000 - val_loss: 0.4097 - val_accuracy: 0.9286\n",
            "Epoch 2337/4000\n",
            "1/1 [==============================] - 0s 49ms/step - loss: 9.6896e-04 - accuracy: 1.0000 - val_loss: 0.4097 - val_accuracy: 0.9286\n",
            "Epoch 2338/4000\n",
            "1/1 [==============================] - 0s 33ms/step - loss: 9.6783e-04 - accuracy: 1.0000 - val_loss: 0.4098 - val_accuracy: 0.9286\n",
            "Epoch 2339/4000\n",
            "1/1 [==============================] - 0s 52ms/step - loss: 9.6668e-04 - accuracy: 1.0000 - val_loss: 0.4099 - val_accuracy: 0.9286\n",
            "Epoch 2340/4000\n",
            "1/1 [==============================] - 0s 33ms/step - loss: 9.6545e-04 - accuracy: 1.0000 - val_loss: 0.4100 - val_accuracy: 0.9286\n",
            "Epoch 2341/4000\n",
            "1/1 [==============================] - 0s 47ms/step - loss: 9.6426e-04 - accuracy: 1.0000 - val_loss: 0.4101 - val_accuracy: 0.9286\n",
            "Epoch 2342/4000\n",
            "1/1 [==============================] - 0s 41ms/step - loss: 9.6309e-04 - accuracy: 1.0000 - val_loss: 0.4101 - val_accuracy: 0.9286\n",
            "Epoch 2343/4000\n",
            "1/1 [==============================] - 0s 49ms/step - loss: 9.6186e-04 - accuracy: 1.0000 - val_loss: 0.4102 - val_accuracy: 0.9286\n",
            "Epoch 2344/4000\n",
            "1/1 [==============================] - 0s 49ms/step - loss: 9.6063e-04 - accuracy: 1.0000 - val_loss: 0.4103 - val_accuracy: 0.9286\n",
            "Epoch 2345/4000\n",
            "1/1 [==============================] - 0s 35ms/step - loss: 9.5950e-04 - accuracy: 1.0000 - val_loss: 0.4104 - val_accuracy: 0.9286\n",
            "Epoch 2346/4000\n",
            "1/1 [==============================] - 0s 47ms/step - loss: 9.5837e-04 - accuracy: 1.0000 - val_loss: 0.4105 - val_accuracy: 0.9286\n",
            "Epoch 2347/4000\n",
            "1/1 [==============================] - 0s 51ms/step - loss: 9.5713e-04 - accuracy: 1.0000 - val_loss: 0.4105 - val_accuracy: 0.9286\n",
            "Epoch 2348/4000\n",
            "1/1 [==============================] - 0s 55ms/step - loss: 9.5593e-04 - accuracy: 1.0000 - val_loss: 0.4106 - val_accuracy: 0.9286\n",
            "Epoch 2349/4000\n",
            "1/1 [==============================] - 0s 38ms/step - loss: 9.5481e-04 - accuracy: 1.0000 - val_loss: 0.4107 - val_accuracy: 0.9286\n",
            "Epoch 2350/4000\n",
            "1/1 [==============================] - 0s 51ms/step - loss: 9.5364e-04 - accuracy: 1.0000 - val_loss: 0.4108 - val_accuracy: 0.9286\n",
            "Epoch 2351/4000\n",
            "1/1 [==============================] - 0s 53ms/step - loss: 9.5242e-04 - accuracy: 1.0000 - val_loss: 0.4108 - val_accuracy: 0.9286\n",
            "Epoch 2352/4000\n",
            "1/1 [==============================] - 0s 35ms/step - loss: 9.5129e-04 - accuracy: 1.0000 - val_loss: 0.4109 - val_accuracy: 0.9286\n",
            "Epoch 2353/4000\n",
            "1/1 [==============================] - 0s 49ms/step - loss: 9.5016e-04 - accuracy: 1.0000 - val_loss: 0.4110 - val_accuracy: 0.9286\n",
            "Epoch 2354/4000\n",
            "1/1 [==============================] - 0s 51ms/step - loss: 9.4904e-04 - accuracy: 1.0000 - val_loss: 0.4111 - val_accuracy: 0.9286\n",
            "Epoch 2355/4000\n",
            "1/1 [==============================] - 0s 34ms/step - loss: 9.4785e-04 - accuracy: 1.0000 - val_loss: 0.4111 - val_accuracy: 0.9286\n",
            "Epoch 2356/4000\n",
            "1/1 [==============================] - 0s 49ms/step - loss: 9.4662e-04 - accuracy: 1.0000 - val_loss: 0.4112 - val_accuracy: 0.9286\n",
            "Epoch 2357/4000\n",
            "1/1 [==============================] - 0s 51ms/step - loss: 9.4545e-04 - accuracy: 1.0000 - val_loss: 0.4113 - val_accuracy: 0.9286\n",
            "Epoch 2358/4000\n",
            "1/1 [==============================] - 0s 46ms/step - loss: 9.4434e-04 - accuracy: 1.0000 - val_loss: 0.4114 - val_accuracy: 0.9286\n",
            "Epoch 2359/4000\n",
            "1/1 [==============================] - 0s 48ms/step - loss: 9.4320e-04 - accuracy: 1.0000 - val_loss: 0.4115 - val_accuracy: 0.9286\n",
            "Epoch 2360/4000\n",
            "1/1 [==============================] - 0s 51ms/step - loss: 9.4199e-04 - accuracy: 1.0000 - val_loss: 0.4116 - val_accuracy: 0.9286\n",
            "Epoch 2361/4000\n",
            "1/1 [==============================] - 0s 36ms/step - loss: 9.4082e-04 - accuracy: 1.0000 - val_loss: 0.4116 - val_accuracy: 0.9286\n",
            "Epoch 2362/4000\n",
            "1/1 [==============================] - 0s 46ms/step - loss: 9.3971e-04 - accuracy: 1.0000 - val_loss: 0.4117 - val_accuracy: 0.9286\n",
            "Epoch 2363/4000\n",
            "1/1 [==============================] - 0s 42ms/step - loss: 9.3863e-04 - accuracy: 1.0000 - val_loss: 0.4118 - val_accuracy: 0.9286\n",
            "Epoch 2364/4000\n",
            "1/1 [==============================] - 0s 47ms/step - loss: 9.3745e-04 - accuracy: 1.0000 - val_loss: 0.4118 - val_accuracy: 0.9286\n",
            "Epoch 2365/4000\n",
            "1/1 [==============================] - 0s 41ms/step - loss: 9.3631e-04 - accuracy: 1.0000 - val_loss: 0.4119 - val_accuracy: 0.9286\n",
            "Epoch 2366/4000\n",
            "1/1 [==============================] - 0s 46ms/step - loss: 9.3517e-04 - accuracy: 1.0000 - val_loss: 0.4120 - val_accuracy: 0.9286\n",
            "Epoch 2367/4000\n",
            "1/1 [==============================] - 0s 40ms/step - loss: 9.3403e-04 - accuracy: 1.0000 - val_loss: 0.4121 - val_accuracy: 0.9286\n",
            "Epoch 2368/4000\n",
            "1/1 [==============================] - 0s 51ms/step - loss: 9.3286e-04 - accuracy: 1.0000 - val_loss: 0.4122 - val_accuracy: 0.9286\n",
            "Epoch 2369/4000\n",
            "1/1 [==============================] - 0s 51ms/step - loss: 9.3172e-04 - accuracy: 1.0000 - val_loss: 0.4123 - val_accuracy: 0.9286\n",
            "Epoch 2370/4000\n",
            "1/1 [==============================] - 0s 46ms/step - loss: 9.3061e-04 - accuracy: 1.0000 - val_loss: 0.4123 - val_accuracy: 0.9286\n",
            "Epoch 2371/4000\n",
            "1/1 [==============================] - 0s 41ms/step - loss: 9.2947e-04 - accuracy: 1.0000 - val_loss: 0.4124 - val_accuracy: 0.9286\n",
            "Epoch 2372/4000\n",
            "1/1 [==============================] - 0s 56ms/step - loss: 9.2827e-04 - accuracy: 1.0000 - val_loss: 0.4125 - val_accuracy: 0.9286\n",
            "Epoch 2373/4000\n",
            "1/1 [==============================] - 0s 48ms/step - loss: 9.2720e-04 - accuracy: 1.0000 - val_loss: 0.4126 - val_accuracy: 0.9286\n",
            "Epoch 2374/4000\n",
            "1/1 [==============================] - 0s 37ms/step - loss: 9.2610e-04 - accuracy: 1.0000 - val_loss: 0.4126 - val_accuracy: 0.9286\n",
            "Epoch 2375/4000\n",
            "1/1 [==============================] - 0s 33ms/step - loss: 9.2497e-04 - accuracy: 1.0000 - val_loss: 0.4127 - val_accuracy: 0.9286\n",
            "Epoch 2376/4000\n",
            "1/1 [==============================] - 0s 48ms/step - loss: 9.2384e-04 - accuracy: 1.0000 - val_loss: 0.4128 - val_accuracy: 0.9286\n",
            "Epoch 2377/4000\n",
            "1/1 [==============================] - 0s 49ms/step - loss: 9.2271e-04 - accuracy: 1.0000 - val_loss: 0.4129 - val_accuracy: 0.9286\n",
            "Epoch 2378/4000\n",
            "1/1 [==============================] - 0s 38ms/step - loss: 9.2164e-04 - accuracy: 1.0000 - val_loss: 0.4130 - val_accuracy: 0.9286\n",
            "Epoch 2379/4000\n",
            "1/1 [==============================] - 0s 34ms/step - loss: 9.2051e-04 - accuracy: 1.0000 - val_loss: 0.4130 - val_accuracy: 0.9286\n",
            "Epoch 2380/4000\n",
            "1/1 [==============================] - 0s 47ms/step - loss: 9.1935e-04 - accuracy: 1.0000 - val_loss: 0.4131 - val_accuracy: 0.9286\n",
            "Epoch 2381/4000\n",
            "1/1 [==============================] - 0s 34ms/step - loss: 9.1823e-04 - accuracy: 1.0000 - val_loss: 0.4132 - val_accuracy: 0.9286\n",
            "Epoch 2382/4000\n",
            "1/1 [==============================] - 0s 50ms/step - loss: 9.1707e-04 - accuracy: 1.0000 - val_loss: 0.4133 - val_accuracy: 0.9286\n",
            "Epoch 2383/4000\n",
            "1/1 [==============================] - 0s 48ms/step - loss: 9.1599e-04 - accuracy: 1.0000 - val_loss: 0.4134 - val_accuracy: 0.9286\n",
            "Epoch 2384/4000\n",
            "1/1 [==============================] - 0s 59ms/step - loss: 9.1491e-04 - accuracy: 1.0000 - val_loss: 0.4134 - val_accuracy: 0.9286\n",
            "Epoch 2385/4000\n",
            "1/1 [==============================] - 0s 47ms/step - loss: 9.1381e-04 - accuracy: 1.0000 - val_loss: 0.4135 - val_accuracy: 0.9286\n",
            "Epoch 2386/4000\n",
            "1/1 [==============================] - 0s 37ms/step - loss: 9.1265e-04 - accuracy: 1.0000 - val_loss: 0.4136 - val_accuracy: 0.9286\n",
            "Epoch 2387/4000\n",
            "1/1 [==============================] - 0s 46ms/step - loss: 9.1154e-04 - accuracy: 1.0000 - val_loss: 0.4137 - val_accuracy: 0.9286\n",
            "Epoch 2388/4000\n",
            "1/1 [==============================] - 0s 52ms/step - loss: 9.1049e-04 - accuracy: 1.0000 - val_loss: 0.4137 - val_accuracy: 0.9286\n",
            "Epoch 2389/4000\n",
            "1/1 [==============================] - 0s 52ms/step - loss: 9.0938e-04 - accuracy: 1.0000 - val_loss: 0.4138 - val_accuracy: 0.9286\n",
            "Epoch 2390/4000\n",
            "1/1 [==============================] - 0s 35ms/step - loss: 9.0829e-04 - accuracy: 1.0000 - val_loss: 0.4139 - val_accuracy: 0.9286\n",
            "Epoch 2391/4000\n",
            "1/1 [==============================] - 0s 48ms/step - loss: 9.0722e-04 - accuracy: 1.0000 - val_loss: 0.4140 - val_accuracy: 0.9286\n",
            "Epoch 2392/4000\n",
            "1/1 [==============================] - 0s 34ms/step - loss: 9.0611e-04 - accuracy: 1.0000 - val_loss: 0.4141 - val_accuracy: 0.9286\n",
            "Epoch 2393/4000\n",
            "1/1 [==============================] - 0s 48ms/step - loss: 9.0504e-04 - accuracy: 1.0000 - val_loss: 0.4141 - val_accuracy: 0.9286\n",
            "Epoch 2394/4000\n",
            "1/1 [==============================] - 0s 48ms/step - loss: 9.0395e-04 - accuracy: 1.0000 - val_loss: 0.4142 - val_accuracy: 0.9286\n",
            "Epoch 2395/4000\n",
            "1/1 [==============================] - 0s 33ms/step - loss: 9.0280e-04 - accuracy: 1.0000 - val_loss: 0.4143 - val_accuracy: 0.9286\n",
            "Epoch 2396/4000\n",
            "1/1 [==============================] - 0s 34ms/step - loss: 9.0172e-04 - accuracy: 1.0000 - val_loss: 0.4144 - val_accuracy: 0.9286\n",
            "Epoch 2397/4000\n",
            "1/1 [==============================] - 0s 34ms/step - loss: 9.0068e-04 - accuracy: 1.0000 - val_loss: 0.4144 - val_accuracy: 0.9286\n",
            "Epoch 2398/4000\n",
            "1/1 [==============================] - 0s 55ms/step - loss: 8.9958e-04 - accuracy: 1.0000 - val_loss: 0.4145 - val_accuracy: 0.9286\n",
            "Epoch 2399/4000\n",
            "1/1 [==============================] - 0s 53ms/step - loss: 8.9850e-04 - accuracy: 1.0000 - val_loss: 0.4146 - val_accuracy: 0.9286\n",
            "Epoch 2400/4000\n",
            "1/1 [==============================] - 0s 47ms/step - loss: 8.9737e-04 - accuracy: 1.0000 - val_loss: 0.4147 - val_accuracy: 0.9286\n",
            "Epoch 2401/4000\n",
            "1/1 [==============================] - 0s 48ms/step - loss: 8.9630e-04 - accuracy: 1.0000 - val_loss: 0.4148 - val_accuracy: 0.9286\n",
            "Epoch 2402/4000\n",
            "1/1 [==============================] - 0s 51ms/step - loss: 8.9526e-04 - accuracy: 1.0000 - val_loss: 0.4148 - val_accuracy: 0.9286\n",
            "Epoch 2403/4000\n",
            "1/1 [==============================] - 0s 39ms/step - loss: 8.9419e-04 - accuracy: 1.0000 - val_loss: 0.4149 - val_accuracy: 0.9286\n",
            "Epoch 2404/4000\n",
            "1/1 [==============================] - 0s 50ms/step - loss: 8.9308e-04 - accuracy: 1.0000 - val_loss: 0.4150 - val_accuracy: 0.9286\n",
            "Epoch 2405/4000\n",
            "1/1 [==============================] - 0s 47ms/step - loss: 8.9198e-04 - accuracy: 1.0000 - val_loss: 0.4151 - val_accuracy: 0.9286\n",
            "Epoch 2406/4000\n",
            "1/1 [==============================] - 0s 55ms/step - loss: 8.9095e-04 - accuracy: 1.0000 - val_loss: 0.4152 - val_accuracy: 0.9286\n",
            "Epoch 2407/4000\n",
            "1/1 [==============================] - 0s 46ms/step - loss: 8.8991e-04 - accuracy: 1.0000 - val_loss: 0.4152 - val_accuracy: 0.9286\n",
            "Epoch 2408/4000\n",
            "1/1 [==============================] - 0s 37ms/step - loss: 8.8884e-04 - accuracy: 1.0000 - val_loss: 0.4153 - val_accuracy: 0.9286\n",
            "Epoch 2409/4000\n",
            "1/1 [==============================] - 0s 48ms/step - loss: 8.8776e-04 - accuracy: 1.0000 - val_loss: 0.4154 - val_accuracy: 0.9286\n",
            "Epoch 2410/4000\n",
            "1/1 [==============================] - 0s 48ms/step - loss: 8.8667e-04 - accuracy: 1.0000 - val_loss: 0.4154 - val_accuracy: 0.9286\n",
            "Epoch 2411/4000\n",
            "1/1 [==============================] - 0s 49ms/step - loss: 8.8565e-04 - accuracy: 1.0000 - val_loss: 0.4155 - val_accuracy: 0.9286\n",
            "Epoch 2412/4000\n",
            "1/1 [==============================] - 0s 52ms/step - loss: 8.8466e-04 - accuracy: 1.0000 - val_loss: 0.4156 - val_accuracy: 0.9286\n",
            "Epoch 2413/4000\n",
            "1/1 [==============================] - 0s 46ms/step - loss: 8.8354e-04 - accuracy: 1.0000 - val_loss: 0.4157 - val_accuracy: 0.9286\n",
            "Epoch 2414/4000\n",
            "1/1 [==============================] - 0s 48ms/step - loss: 8.8246e-04 - accuracy: 1.0000 - val_loss: 0.4158 - val_accuracy: 0.9286\n",
            "Epoch 2415/4000\n",
            "1/1 [==============================] - 0s 52ms/step - loss: 8.8140e-04 - accuracy: 1.0000 - val_loss: 0.4158 - val_accuracy: 0.9286\n",
            "Epoch 2416/4000\n",
            "1/1 [==============================] - 0s 35ms/step - loss: 8.8037e-04 - accuracy: 1.0000 - val_loss: 0.4159 - val_accuracy: 0.9286\n",
            "Epoch 2417/4000\n",
            "1/1 [==============================] - 0s 50ms/step - loss: 8.7937e-04 - accuracy: 1.0000 - val_loss: 0.4160 - val_accuracy: 0.9286\n",
            "Epoch 2418/4000\n",
            "1/1 [==============================] - 0s 51ms/step - loss: 8.7829e-04 - accuracy: 1.0000 - val_loss: 0.4161 - val_accuracy: 0.9286\n",
            "Epoch 2419/4000\n",
            "1/1 [==============================] - 0s 35ms/step - loss: 8.7726e-04 - accuracy: 1.0000 - val_loss: 0.4161 - val_accuracy: 0.9286\n",
            "Epoch 2420/4000\n",
            "1/1 [==============================] - 0s 51ms/step - loss: 8.7622e-04 - accuracy: 1.0000 - val_loss: 0.4162 - val_accuracy: 0.9286\n",
            "Epoch 2421/4000\n",
            "1/1 [==============================] - 0s 49ms/step - loss: 8.7521e-04 - accuracy: 1.0000 - val_loss: 0.4163 - val_accuracy: 0.9286\n",
            "Epoch 2422/4000\n",
            "1/1 [==============================] - 0s 41ms/step - loss: 8.7416e-04 - accuracy: 1.0000 - val_loss: 0.4164 - val_accuracy: 0.9286\n",
            "Epoch 2423/4000\n",
            "1/1 [==============================] - 0s 53ms/step - loss: 8.7307e-04 - accuracy: 1.0000 - val_loss: 0.4165 - val_accuracy: 0.9286\n",
            "Epoch 2424/4000\n",
            "1/1 [==============================] - 0s 46ms/step - loss: 8.7204e-04 - accuracy: 1.0000 - val_loss: 0.4165 - val_accuracy: 0.9286\n",
            "Epoch 2425/4000\n",
            "1/1 [==============================] - 0s 48ms/step - loss: 8.7101e-04 - accuracy: 1.0000 - val_loss: 0.4166 - val_accuracy: 0.9286\n",
            "Epoch 2426/4000\n",
            "1/1 [==============================] - 0s 46ms/step - loss: 8.7000e-04 - accuracy: 1.0000 - val_loss: 0.4167 - val_accuracy: 0.9286\n",
            "Epoch 2427/4000\n",
            "1/1 [==============================] - 0s 50ms/step - loss: 8.6893e-04 - accuracy: 1.0000 - val_loss: 0.4168 - val_accuracy: 0.9286\n",
            "Epoch 2428/4000\n",
            "1/1 [==============================] - 0s 53ms/step - loss: 8.6787e-04 - accuracy: 1.0000 - val_loss: 0.4169 - val_accuracy: 0.9286\n",
            "Epoch 2429/4000\n",
            "1/1 [==============================] - 0s 46ms/step - loss: 8.6684e-04 - accuracy: 1.0000 - val_loss: 0.4169 - val_accuracy: 0.9286\n",
            "Epoch 2430/4000\n",
            "1/1 [==============================] - 0s 47ms/step - loss: 8.6587e-04 - accuracy: 1.0000 - val_loss: 0.4170 - val_accuracy: 0.9286\n",
            "Epoch 2431/4000\n",
            "1/1 [==============================] - 0s 56ms/step - loss: 8.6483e-04 - accuracy: 1.0000 - val_loss: 0.4171 - val_accuracy: 0.9286\n",
            "Epoch 2432/4000\n",
            "1/1 [==============================] - 0s 53ms/step - loss: 8.6386e-04 - accuracy: 1.0000 - val_loss: 0.4172 - val_accuracy: 0.9286\n",
            "Epoch 2433/4000\n",
            "1/1 [==============================] - 0s 47ms/step - loss: 8.6283e-04 - accuracy: 1.0000 - val_loss: 0.4172 - val_accuracy: 0.9286\n",
            "Epoch 2434/4000\n",
            "1/1 [==============================] - 0s 32ms/step - loss: 8.6178e-04 - accuracy: 1.0000 - val_loss: 0.4173 - val_accuracy: 0.9286\n",
            "Epoch 2435/4000\n",
            "1/1 [==============================] - 0s 47ms/step - loss: 8.6076e-04 - accuracy: 1.0000 - val_loss: 0.4174 - val_accuracy: 0.9286\n",
            "Epoch 2436/4000\n",
            "1/1 [==============================] - 0s 49ms/step - loss: 8.5976e-04 - accuracy: 1.0000 - val_loss: 0.4174 - val_accuracy: 0.9286\n",
            "Epoch 2437/4000\n",
            "1/1 [==============================] - 0s 48ms/step - loss: 8.5876e-04 - accuracy: 1.0000 - val_loss: 0.4175 - val_accuracy: 0.9286\n",
            "Epoch 2438/4000\n",
            "1/1 [==============================] - 0s 47ms/step - loss: 8.5771e-04 - accuracy: 1.0000 - val_loss: 0.4176 - val_accuracy: 0.9286\n",
            "Epoch 2439/4000\n",
            "1/1 [==============================] - 0s 51ms/step - loss: 8.5665e-04 - accuracy: 1.0000 - val_loss: 0.4177 - val_accuracy: 0.9286\n",
            "Epoch 2440/4000\n",
            "1/1 [==============================] - 0s 51ms/step - loss: 8.5566e-04 - accuracy: 1.0000 - val_loss: 0.4178 - val_accuracy: 0.9286\n",
            "Epoch 2441/4000\n",
            "1/1 [==============================] - 0s 33ms/step - loss: 8.5469e-04 - accuracy: 1.0000 - val_loss: 0.4179 - val_accuracy: 0.9286\n",
            "Epoch 2442/4000\n",
            "1/1 [==============================] - 0s 47ms/step - loss: 8.5366e-04 - accuracy: 1.0000 - val_loss: 0.4179 - val_accuracy: 0.9286\n",
            "Epoch 2443/4000\n",
            "1/1 [==============================] - 0s 54ms/step - loss: 8.5263e-04 - accuracy: 1.0000 - val_loss: 0.4180 - val_accuracy: 0.9286\n",
            "Epoch 2444/4000\n",
            "1/1 [==============================] - 0s 46ms/step - loss: 8.5165e-04 - accuracy: 1.0000 - val_loss: 0.4181 - val_accuracy: 0.9286\n",
            "Epoch 2445/4000\n",
            "1/1 [==============================] - 0s 57ms/step - loss: 8.5062e-04 - accuracy: 1.0000 - val_loss: 0.4181 - val_accuracy: 0.9286\n",
            "Epoch 2446/4000\n",
            "1/1 [==============================] - 0s 51ms/step - loss: 8.4962e-04 - accuracy: 1.0000 - val_loss: 0.4182 - val_accuracy: 0.9286\n",
            "Epoch 2447/4000\n",
            "1/1 [==============================] - 0s 47ms/step - loss: 8.4870e-04 - accuracy: 1.0000 - val_loss: 0.4183 - val_accuracy: 0.9286\n",
            "Epoch 2448/4000\n",
            "1/1 [==============================] - 0s 42ms/step - loss: 8.4773e-04 - accuracy: 1.0000 - val_loss: 0.4184 - val_accuracy: 0.9286\n",
            "Epoch 2449/4000\n",
            "1/1 [==============================] - 0s 46ms/step - loss: 8.4668e-04 - accuracy: 1.0000 - val_loss: 0.4184 - val_accuracy: 0.9286\n",
            "Epoch 2450/4000\n",
            "1/1 [==============================] - 0s 49ms/step - loss: 8.4567e-04 - accuracy: 1.0000 - val_loss: 0.4185 - val_accuracy: 0.9286\n",
            "Epoch 2451/4000\n",
            "1/1 [==============================] - 0s 46ms/step - loss: 8.4464e-04 - accuracy: 1.0000 - val_loss: 0.4186 - val_accuracy: 0.9286\n",
            "Epoch 2452/4000\n",
            "1/1 [==============================] - 0s 33ms/step - loss: 8.4366e-04 - accuracy: 1.0000 - val_loss: 0.4187 - val_accuracy: 0.9286\n",
            "Epoch 2453/4000\n",
            "1/1 [==============================] - 0s 48ms/step - loss: 8.4270e-04 - accuracy: 1.0000 - val_loss: 0.4188 - val_accuracy: 0.9286\n",
            "Epoch 2454/4000\n",
            "1/1 [==============================] - 0s 38ms/step - loss: 8.4164e-04 - accuracy: 1.0000 - val_loss: 0.4188 - val_accuracy: 0.9286\n",
            "Epoch 2455/4000\n",
            "1/1 [==============================] - 0s 47ms/step - loss: 8.4064e-04 - accuracy: 1.0000 - val_loss: 0.4189 - val_accuracy: 0.9286\n",
            "Epoch 2456/4000\n",
            "1/1 [==============================] - 0s 37ms/step - loss: 8.3968e-04 - accuracy: 1.0000 - val_loss: 0.4190 - val_accuracy: 0.9286\n",
            "Epoch 2457/4000\n",
            "1/1 [==============================] - 0s 55ms/step - loss: 8.3865e-04 - accuracy: 1.0000 - val_loss: 0.4190 - val_accuracy: 0.9286\n",
            "Epoch 2458/4000\n",
            "1/1 [==============================] - 0s 50ms/step - loss: 8.3769e-04 - accuracy: 1.0000 - val_loss: 0.4191 - val_accuracy: 0.9286\n",
            "Epoch 2459/4000\n",
            "1/1 [==============================] - 0s 38ms/step - loss: 8.3671e-04 - accuracy: 1.0000 - val_loss: 0.4192 - val_accuracy: 0.9286\n",
            "Epoch 2460/4000\n",
            "1/1 [==============================] - 0s 47ms/step - loss: 8.3568e-04 - accuracy: 1.0000 - val_loss: 0.4193 - val_accuracy: 0.9286\n",
            "Epoch 2461/4000\n",
            "1/1 [==============================] - 0s 48ms/step - loss: 8.3474e-04 - accuracy: 1.0000 - val_loss: 0.4194 - val_accuracy: 0.9286\n",
            "Epoch 2462/4000\n",
            "1/1 [==============================] - 0s 48ms/step - loss: 8.3380e-04 - accuracy: 1.0000 - val_loss: 0.4194 - val_accuracy: 0.9286\n",
            "Epoch 2463/4000\n",
            "1/1 [==============================] - 0s 41ms/step - loss: 8.3282e-04 - accuracy: 1.0000 - val_loss: 0.4195 - val_accuracy: 0.9286\n",
            "Epoch 2464/4000\n",
            "1/1 [==============================] - 0s 60ms/step - loss: 8.3183e-04 - accuracy: 1.0000 - val_loss: 0.4196 - val_accuracy: 0.9286\n",
            "Epoch 2465/4000\n",
            "1/1 [==============================] - 0s 51ms/step - loss: 8.3087e-04 - accuracy: 1.0000 - val_loss: 0.4197 - val_accuracy: 0.9286\n",
            "Epoch 2466/4000\n",
            "1/1 [==============================] - 0s 37ms/step - loss: 8.2989e-04 - accuracy: 1.0000 - val_loss: 0.4197 - val_accuracy: 0.9286\n",
            "Epoch 2467/4000\n",
            "1/1 [==============================] - 0s 46ms/step - loss: 8.2891e-04 - accuracy: 1.0000 - val_loss: 0.4198 - val_accuracy: 0.9286\n",
            "Epoch 2468/4000\n",
            "1/1 [==============================] - 0s 46ms/step - loss: 8.2794e-04 - accuracy: 1.0000 - val_loss: 0.4199 - val_accuracy: 0.9286\n",
            "Epoch 2469/4000\n",
            "1/1 [==============================] - 0s 52ms/step - loss: 8.2696e-04 - accuracy: 1.0000 - val_loss: 0.4200 - val_accuracy: 0.9286\n",
            "Epoch 2470/4000\n",
            "1/1 [==============================] - 0s 47ms/step - loss: 8.2599e-04 - accuracy: 1.0000 - val_loss: 0.4200 - val_accuracy: 0.9286\n",
            "Epoch 2471/4000\n",
            "1/1 [==============================] - 0s 49ms/step - loss: 8.2506e-04 - accuracy: 1.0000 - val_loss: 0.4201 - val_accuracy: 0.9286\n",
            "Epoch 2472/4000\n",
            "1/1 [==============================] - 0s 42ms/step - loss: 8.2410e-04 - accuracy: 1.0000 - val_loss: 0.4202 - val_accuracy: 0.9286\n",
            "Epoch 2473/4000\n",
            "1/1 [==============================] - 0s 35ms/step - loss: 8.2313e-04 - accuracy: 1.0000 - val_loss: 0.4203 - val_accuracy: 0.9286\n",
            "Epoch 2474/4000\n",
            "1/1 [==============================] - 0s 51ms/step - loss: 8.2219e-04 - accuracy: 1.0000 - val_loss: 0.4203 - val_accuracy: 0.9286\n",
            "Epoch 2475/4000\n",
            "1/1 [==============================] - 0s 52ms/step - loss: 8.2122e-04 - accuracy: 1.0000 - val_loss: 0.4204 - val_accuracy: 0.9286\n",
            "Epoch 2476/4000\n",
            "1/1 [==============================] - 0s 47ms/step - loss: 8.2026e-04 - accuracy: 1.0000 - val_loss: 0.4205 - val_accuracy: 0.9286\n",
            "Epoch 2477/4000\n",
            "1/1 [==============================] - 0s 54ms/step - loss: 8.1930e-04 - accuracy: 1.0000 - val_loss: 0.4206 - val_accuracy: 0.9286\n",
            "Epoch 2478/4000\n",
            "1/1 [==============================] - 0s 48ms/step - loss: 8.1836e-04 - accuracy: 1.0000 - val_loss: 0.4206 - val_accuracy: 0.9286\n",
            "Epoch 2479/4000\n",
            "1/1 [==============================] - 0s 55ms/step - loss: 8.1741e-04 - accuracy: 1.0000 - val_loss: 0.4207 - val_accuracy: 0.9286\n",
            "Epoch 2480/4000\n",
            "1/1 [==============================] - 0s 57ms/step - loss: 8.1641e-04 - accuracy: 1.0000 - val_loss: 0.4208 - val_accuracy: 0.9286\n",
            "Epoch 2481/4000\n",
            "1/1 [==============================] - 0s 48ms/step - loss: 8.1547e-04 - accuracy: 1.0000 - val_loss: 0.4209 - val_accuracy: 0.9286\n",
            "Epoch 2482/4000\n",
            "1/1 [==============================] - 0s 46ms/step - loss: 8.1456e-04 - accuracy: 1.0000 - val_loss: 0.4209 - val_accuracy: 0.9286\n",
            "Epoch 2483/4000\n",
            "1/1 [==============================] - 0s 48ms/step - loss: 8.1359e-04 - accuracy: 1.0000 - val_loss: 0.4210 - val_accuracy: 0.9286\n",
            "Epoch 2484/4000\n",
            "1/1 [==============================] - 0s 55ms/step - loss: 8.1264e-04 - accuracy: 1.0000 - val_loss: 0.4211 - val_accuracy: 0.9286\n",
            "Epoch 2485/4000\n",
            "1/1 [==============================] - 0s 55ms/step - loss: 8.1171e-04 - accuracy: 1.0000 - val_loss: 0.4212 - val_accuracy: 0.9286\n",
            "Epoch 2486/4000\n",
            "1/1 [==============================] - 0s 46ms/step - loss: 8.1080e-04 - accuracy: 1.0000 - val_loss: 0.4212 - val_accuracy: 0.9286\n",
            "Epoch 2487/4000\n",
            "1/1 [==============================] - 0s 32ms/step - loss: 8.0987e-04 - accuracy: 1.0000 - val_loss: 0.4213 - val_accuracy: 0.9286\n",
            "Epoch 2488/4000\n",
            "1/1 [==============================] - 0s 32ms/step - loss: 8.0892e-04 - accuracy: 1.0000 - val_loss: 0.4214 - val_accuracy: 0.9286\n",
            "Epoch 2489/4000\n",
            "1/1 [==============================] - 0s 35ms/step - loss: 8.0798e-04 - accuracy: 1.0000 - val_loss: 0.4215 - val_accuracy: 0.9286\n",
            "Epoch 2490/4000\n",
            "1/1 [==============================] - 0s 45ms/step - loss: 8.0704e-04 - accuracy: 1.0000 - val_loss: 0.4215 - val_accuracy: 0.9286\n",
            "Epoch 2491/4000\n",
            "1/1 [==============================] - 0s 42ms/step - loss: 8.0610e-04 - accuracy: 1.0000 - val_loss: 0.4216 - val_accuracy: 0.9286\n",
            "Epoch 2492/4000\n",
            "1/1 [==============================] - 0s 40ms/step - loss: 8.0517e-04 - accuracy: 1.0000 - val_loss: 0.4217 - val_accuracy: 0.9286\n",
            "Epoch 2493/4000\n",
            "1/1 [==============================] - 0s 43ms/step - loss: 8.0426e-04 - accuracy: 1.0000 - val_loss: 0.4217 - val_accuracy: 0.9286\n",
            "Epoch 2494/4000\n",
            "1/1 [==============================] - 0s 41ms/step - loss: 8.0332e-04 - accuracy: 1.0000 - val_loss: 0.4218 - val_accuracy: 0.9286\n",
            "Epoch 2495/4000\n",
            "1/1 [==============================] - 0s 48ms/step - loss: 8.0240e-04 - accuracy: 1.0000 - val_loss: 0.4219 - val_accuracy: 0.9286\n",
            "Epoch 2496/4000\n",
            "1/1 [==============================] - 0s 36ms/step - loss: 8.0151e-04 - accuracy: 1.0000 - val_loss: 0.4220 - val_accuracy: 0.9286\n",
            "Epoch 2497/4000\n",
            "1/1 [==============================] - 0s 33ms/step - loss: 8.0057e-04 - accuracy: 1.0000 - val_loss: 0.4220 - val_accuracy: 0.9286\n",
            "Epoch 2498/4000\n",
            "1/1 [==============================] - 0s 47ms/step - loss: 7.9960e-04 - accuracy: 1.0000 - val_loss: 0.4221 - val_accuracy: 0.9286\n",
            "Epoch 2499/4000\n",
            "1/1 [==============================] - 0s 35ms/step - loss: 7.9872e-04 - accuracy: 1.0000 - val_loss: 0.4222 - val_accuracy: 0.9286\n",
            "Epoch 2500/4000\n",
            "1/1 [==============================] - 0s 50ms/step - loss: 7.9779e-04 - accuracy: 1.0000 - val_loss: 0.4223 - val_accuracy: 0.9286\n",
            "Epoch 2501/4000\n",
            "1/1 [==============================] - 0s 36ms/step - loss: 7.9688e-04 - accuracy: 1.0000 - val_loss: 0.4224 - val_accuracy: 0.9286\n",
            "Epoch 2502/4000\n",
            "1/1 [==============================] - 0s 50ms/step - loss: 7.9597e-04 - accuracy: 1.0000 - val_loss: 0.4224 - val_accuracy: 0.9286\n",
            "Epoch 2503/4000\n",
            "1/1 [==============================] - 0s 50ms/step - loss: 7.9503e-04 - accuracy: 1.0000 - val_loss: 0.4225 - val_accuracy: 0.9286\n",
            "Epoch 2504/4000\n",
            "1/1 [==============================] - 0s 32ms/step - loss: 7.9411e-04 - accuracy: 1.0000 - val_loss: 0.4226 - val_accuracy: 0.9286\n",
            "Epoch 2505/4000\n",
            "1/1 [==============================] - 0s 47ms/step - loss: 7.9323e-04 - accuracy: 1.0000 - val_loss: 0.4227 - val_accuracy: 0.9286\n",
            "Epoch 2506/4000\n",
            "1/1 [==============================] - 0s 47ms/step - loss: 7.9233e-04 - accuracy: 1.0000 - val_loss: 0.4227 - val_accuracy: 0.9286\n",
            "Epoch 2507/4000\n",
            "1/1 [==============================] - 0s 51ms/step - loss: 7.9136e-04 - accuracy: 1.0000 - val_loss: 0.4228 - val_accuracy: 0.9286\n",
            "Epoch 2508/4000\n",
            "1/1 [==============================] - 0s 47ms/step - loss: 7.9046e-04 - accuracy: 1.0000 - val_loss: 0.4229 - val_accuracy: 0.9286\n",
            "Epoch 2509/4000\n",
            "1/1 [==============================] - 0s 51ms/step - loss: 7.8957e-04 - accuracy: 1.0000 - val_loss: 0.4230 - val_accuracy: 0.9286\n",
            "Epoch 2510/4000\n",
            "1/1 [==============================] - 0s 44ms/step - loss: 7.8866e-04 - accuracy: 1.0000 - val_loss: 0.4230 - val_accuracy: 0.9286\n",
            "Epoch 2511/4000\n",
            "1/1 [==============================] - 0s 50ms/step - loss: 7.8778e-04 - accuracy: 1.0000 - val_loss: 0.4231 - val_accuracy: 0.9286\n",
            "Epoch 2512/4000\n",
            "1/1 [==============================] - 0s 54ms/step - loss: 7.8688e-04 - accuracy: 1.0000 - val_loss: 0.4232 - val_accuracy: 0.9286\n",
            "Epoch 2513/4000\n",
            "1/1 [==============================] - 0s 50ms/step - loss: 7.8600e-04 - accuracy: 1.0000 - val_loss: 0.4232 - val_accuracy: 0.9286\n",
            "Epoch 2514/4000\n",
            "1/1 [==============================] - 0s 57ms/step - loss: 7.8508e-04 - accuracy: 1.0000 - val_loss: 0.4233 - val_accuracy: 0.9286\n",
            "Epoch 2515/4000\n",
            "1/1 [==============================] - 0s 39ms/step - loss: 7.8414e-04 - accuracy: 1.0000 - val_loss: 0.4234 - val_accuracy: 0.9286\n",
            "Epoch 2516/4000\n",
            "1/1 [==============================] - 0s 45ms/step - loss: 7.8327e-04 - accuracy: 1.0000 - val_loss: 0.4235 - val_accuracy: 0.9286\n",
            "Epoch 2517/4000\n",
            "1/1 [==============================] - 0s 52ms/step - loss: 7.8240e-04 - accuracy: 1.0000 - val_loss: 0.4235 - val_accuracy: 0.9286\n",
            "Epoch 2518/4000\n",
            "1/1 [==============================] - 0s 37ms/step - loss: 7.8147e-04 - accuracy: 1.0000 - val_loss: 0.4236 - val_accuracy: 0.9286\n",
            "Epoch 2519/4000\n",
            "1/1 [==============================] - 0s 42ms/step - loss: 7.8058e-04 - accuracy: 1.0000 - val_loss: 0.4237 - val_accuracy: 0.9286\n",
            "Epoch 2520/4000\n",
            "1/1 [==============================] - 0s 33ms/step - loss: 7.7970e-04 - accuracy: 1.0000 - val_loss: 0.4238 - val_accuracy: 0.9286\n",
            "Epoch 2521/4000\n",
            "1/1 [==============================] - 0s 41ms/step - loss: 7.7879e-04 - accuracy: 1.0000 - val_loss: 0.4238 - val_accuracy: 0.9286\n",
            "Epoch 2522/4000\n",
            "1/1 [==============================] - 0s 39ms/step - loss: 7.7789e-04 - accuracy: 1.0000 - val_loss: 0.4239 - val_accuracy: 0.9286\n",
            "Epoch 2523/4000\n",
            "1/1 [==============================] - 0s 50ms/step - loss: 7.7704e-04 - accuracy: 1.0000 - val_loss: 0.4240 - val_accuracy: 0.9286\n",
            "Epoch 2524/4000\n",
            "1/1 [==============================] - 0s 36ms/step - loss: 7.7610e-04 - accuracy: 1.0000 - val_loss: 0.4240 - val_accuracy: 0.9286\n",
            "Epoch 2525/4000\n",
            "1/1 [==============================] - 0s 48ms/step - loss: 7.7522e-04 - accuracy: 1.0000 - val_loss: 0.4241 - val_accuracy: 0.9286\n",
            "Epoch 2526/4000\n",
            "1/1 [==============================] - 0s 50ms/step - loss: 7.7433e-04 - accuracy: 1.0000 - val_loss: 0.4242 - val_accuracy: 0.9286\n",
            "Epoch 2527/4000\n",
            "1/1 [==============================] - 0s 49ms/step - loss: 7.7346e-04 - accuracy: 1.0000 - val_loss: 0.4243 - val_accuracy: 0.9286\n",
            "Epoch 2528/4000\n",
            "1/1 [==============================] - 0s 53ms/step - loss: 7.7258e-04 - accuracy: 1.0000 - val_loss: 0.4244 - val_accuracy: 0.9286\n",
            "Epoch 2529/4000\n",
            "1/1 [==============================] - 0s 48ms/step - loss: 7.7168e-04 - accuracy: 1.0000 - val_loss: 0.4244 - val_accuracy: 0.9286\n",
            "Epoch 2530/4000\n",
            "1/1 [==============================] - 0s 43ms/step - loss: 7.7080e-04 - accuracy: 1.0000 - val_loss: 0.4245 - val_accuracy: 0.9286\n",
            "Epoch 2531/4000\n",
            "1/1 [==============================] - 0s 50ms/step - loss: 7.6996e-04 - accuracy: 1.0000 - val_loss: 0.4246 - val_accuracy: 0.9286\n",
            "Epoch 2532/4000\n",
            "1/1 [==============================] - 0s 50ms/step - loss: 7.6907e-04 - accuracy: 1.0000 - val_loss: 0.4246 - val_accuracy: 0.9286\n",
            "Epoch 2533/4000\n",
            "1/1 [==============================] - 0s 34ms/step - loss: 7.6812e-04 - accuracy: 1.0000 - val_loss: 0.4247 - val_accuracy: 0.9286\n",
            "Epoch 2534/4000\n",
            "1/1 [==============================] - 0s 32ms/step - loss: 7.6731e-04 - accuracy: 1.0000 - val_loss: 0.4248 - val_accuracy: 0.9286\n",
            "Epoch 2535/4000\n",
            "1/1 [==============================] - 0s 46ms/step - loss: 7.6647e-04 - accuracy: 1.0000 - val_loss: 0.4249 - val_accuracy: 0.9286\n",
            "Epoch 2536/4000\n",
            "1/1 [==============================] - 0s 44ms/step - loss: 7.6561e-04 - accuracy: 1.0000 - val_loss: 0.4249 - val_accuracy: 0.9286\n",
            "Epoch 2537/4000\n",
            "1/1 [==============================] - 0s 48ms/step - loss: 7.6471e-04 - accuracy: 1.0000 - val_loss: 0.4250 - val_accuracy: 0.9286\n",
            "Epoch 2538/4000\n",
            "1/1 [==============================] - 0s 50ms/step - loss: 7.6385e-04 - accuracy: 1.0000 - val_loss: 0.4251 - val_accuracy: 0.9286\n",
            "Epoch 2539/4000\n",
            "1/1 [==============================] - 0s 40ms/step - loss: 7.6298e-04 - accuracy: 1.0000 - val_loss: 0.4252 - val_accuracy: 0.9286\n",
            "Epoch 2540/4000\n",
            "1/1 [==============================] - 0s 46ms/step - loss: 7.6214e-04 - accuracy: 1.0000 - val_loss: 0.4252 - val_accuracy: 0.9286\n",
            "Epoch 2541/4000\n",
            "1/1 [==============================] - 0s 33ms/step - loss: 7.6128e-04 - accuracy: 1.0000 - val_loss: 0.4253 - val_accuracy: 0.9286\n",
            "Epoch 2542/4000\n",
            "1/1 [==============================] - 0s 50ms/step - loss: 7.6036e-04 - accuracy: 1.0000 - val_loss: 0.4254 - val_accuracy: 0.9286\n",
            "Epoch 2543/4000\n",
            "1/1 [==============================] - 0s 57ms/step - loss: 7.5950e-04 - accuracy: 1.0000 - val_loss: 0.4255 - val_accuracy: 0.9286\n",
            "Epoch 2544/4000\n",
            "1/1 [==============================] - 0s 49ms/step - loss: 7.5865e-04 - accuracy: 1.0000 - val_loss: 0.4255 - val_accuracy: 0.9286\n",
            "Epoch 2545/4000\n",
            "1/1 [==============================] - 0s 50ms/step - loss: 7.5780e-04 - accuracy: 1.0000 - val_loss: 0.4256 - val_accuracy: 0.9286\n",
            "Epoch 2546/4000\n",
            "1/1 [==============================] - 0s 46ms/step - loss: 7.5696e-04 - accuracy: 1.0000 - val_loss: 0.4257 - val_accuracy: 0.9286\n",
            "Epoch 2547/4000\n",
            "1/1 [==============================] - 0s 48ms/step - loss: 7.5610e-04 - accuracy: 1.0000 - val_loss: 0.4257 - val_accuracy: 0.9286\n",
            "Epoch 2548/4000\n",
            "1/1 [==============================] - 0s 50ms/step - loss: 7.5523e-04 - accuracy: 1.0000 - val_loss: 0.4258 - val_accuracy: 0.9286\n",
            "Epoch 2549/4000\n",
            "1/1 [==============================] - 0s 47ms/step - loss: 7.5443e-04 - accuracy: 1.0000 - val_loss: 0.4259 - val_accuracy: 0.9286\n",
            "Epoch 2550/4000\n",
            "1/1 [==============================] - 0s 54ms/step - loss: 7.5354e-04 - accuracy: 1.0000 - val_loss: 0.4260 - val_accuracy: 0.9286\n",
            "Epoch 2551/4000\n",
            "1/1 [==============================] - 0s 44ms/step - loss: 7.5265e-04 - accuracy: 1.0000 - val_loss: 0.4260 - val_accuracy: 0.9286\n",
            "Epoch 2552/4000\n",
            "1/1 [==============================] - 0s 49ms/step - loss: 7.5180e-04 - accuracy: 1.0000 - val_loss: 0.4261 - val_accuracy: 0.9286\n",
            "Epoch 2553/4000\n",
            "1/1 [==============================] - 0s 33ms/step - loss: 7.5099e-04 - accuracy: 1.0000 - val_loss: 0.4262 - val_accuracy: 0.9286\n",
            "Epoch 2554/4000\n",
            "1/1 [==============================] - 0s 50ms/step - loss: 7.5011e-04 - accuracy: 1.0000 - val_loss: 0.4263 - val_accuracy: 0.9286\n",
            "Epoch 2555/4000\n",
            "1/1 [==============================] - 0s 52ms/step - loss: 7.4927e-04 - accuracy: 1.0000 - val_loss: 0.4263 - val_accuracy: 0.9286\n",
            "Epoch 2556/4000\n",
            "1/1 [==============================] - 0s 52ms/step - loss: 7.4843e-04 - accuracy: 1.0000 - val_loss: 0.4264 - val_accuracy: 0.9286\n",
            "Epoch 2557/4000\n",
            "1/1 [==============================] - 0s 34ms/step - loss: 7.4758e-04 - accuracy: 1.0000 - val_loss: 0.4265 - val_accuracy: 0.9286\n",
            "Epoch 2558/4000\n",
            "1/1 [==============================] - 0s 47ms/step - loss: 7.4678e-04 - accuracy: 1.0000 - val_loss: 0.4265 - val_accuracy: 0.9286\n",
            "Epoch 2559/4000\n",
            "1/1 [==============================] - 0s 52ms/step - loss: 7.4594e-04 - accuracy: 1.0000 - val_loss: 0.4266 - val_accuracy: 0.9286\n",
            "Epoch 2560/4000\n",
            "1/1 [==============================] - 0s 35ms/step - loss: 7.4510e-04 - accuracy: 1.0000 - val_loss: 0.4267 - val_accuracy: 0.9286\n",
            "Epoch 2561/4000\n",
            "1/1 [==============================] - 0s 55ms/step - loss: 7.4426e-04 - accuracy: 1.0000 - val_loss: 0.4268 - val_accuracy: 0.9286\n",
            "Epoch 2562/4000\n",
            "1/1 [==============================] - 0s 50ms/step - loss: 7.4344e-04 - accuracy: 1.0000 - val_loss: 0.4268 - val_accuracy: 0.9286\n",
            "Epoch 2563/4000\n",
            "1/1 [==============================] - 0s 49ms/step - loss: 7.4259e-04 - accuracy: 1.0000 - val_loss: 0.4269 - val_accuracy: 0.9286\n",
            "Epoch 2564/4000\n",
            "1/1 [==============================] - 0s 38ms/step - loss: 7.4175e-04 - accuracy: 1.0000 - val_loss: 0.4270 - val_accuracy: 0.9286\n",
            "Epoch 2565/4000\n",
            "1/1 [==============================] - 0s 47ms/step - loss: 7.4098e-04 - accuracy: 1.0000 - val_loss: 0.4270 - val_accuracy: 0.9286\n",
            "Epoch 2566/4000\n",
            "1/1 [==============================] - 0s 50ms/step - loss: 7.4012e-04 - accuracy: 1.0000 - val_loss: 0.4271 - val_accuracy: 0.9286\n",
            "Epoch 2567/4000\n",
            "1/1 [==============================] - 0s 31ms/step - loss: 7.3925e-04 - accuracy: 1.0000 - val_loss: 0.4272 - val_accuracy: 0.9286\n",
            "Epoch 2568/4000\n",
            "1/1 [==============================] - 0s 49ms/step - loss: 7.3839e-04 - accuracy: 1.0000 - val_loss: 0.4273 - val_accuracy: 0.9286\n",
            "Epoch 2569/4000\n",
            "1/1 [==============================] - 0s 58ms/step - loss: 7.3757e-04 - accuracy: 1.0000 - val_loss: 0.4273 - val_accuracy: 0.9286\n",
            "Epoch 2570/4000\n",
            "1/1 [==============================] - 0s 47ms/step - loss: 7.3680e-04 - accuracy: 1.0000 - val_loss: 0.4274 - val_accuracy: 0.9286\n",
            "Epoch 2571/4000\n",
            "1/1 [==============================] - 0s 31ms/step - loss: 7.3596e-04 - accuracy: 1.0000 - val_loss: 0.4275 - val_accuracy: 0.9286\n",
            "Epoch 2572/4000\n",
            "1/1 [==============================] - 0s 89ms/step - loss: 7.3512e-04 - accuracy: 1.0000 - val_loss: 0.4276 - val_accuracy: 0.9286\n",
            "Epoch 2573/4000\n",
            "1/1 [==============================] - 0s 33ms/step - loss: 7.3431e-04 - accuracy: 1.0000 - val_loss: 0.4276 - val_accuracy: 0.9286\n",
            "Epoch 2574/4000\n",
            "1/1 [==============================] - 0s 34ms/step - loss: 7.3348e-04 - accuracy: 1.0000 - val_loss: 0.4277 - val_accuracy: 0.9286\n",
            "Epoch 2575/4000\n",
            "1/1 [==============================] - 0s 48ms/step - loss: 7.3264e-04 - accuracy: 1.0000 - val_loss: 0.4278 - val_accuracy: 0.9286\n",
            "Epoch 2576/4000\n",
            "1/1 [==============================] - 0s 47ms/step - loss: 7.3183e-04 - accuracy: 1.0000 - val_loss: 0.4279 - val_accuracy: 0.9286\n",
            "Epoch 2577/4000\n",
            "1/1 [==============================] - 0s 42ms/step - loss: 7.3105e-04 - accuracy: 1.0000 - val_loss: 0.4279 - val_accuracy: 0.9286\n",
            "Epoch 2578/4000\n",
            "1/1 [==============================] - 0s 47ms/step - loss: 7.3022e-04 - accuracy: 1.0000 - val_loss: 0.4280 - val_accuracy: 0.9286\n",
            "Epoch 2579/4000\n",
            "1/1 [==============================] - 0s 47ms/step - loss: 7.2938e-04 - accuracy: 1.0000 - val_loss: 0.4281 - val_accuracy: 0.9286\n",
            "Epoch 2580/4000\n",
            "1/1 [==============================] - 0s 46ms/step - loss: 7.2858e-04 - accuracy: 1.0000 - val_loss: 0.4281 - val_accuracy: 0.9286\n",
            "Epoch 2581/4000\n",
            "1/1 [==============================] - 0s 50ms/step - loss: 7.2772e-04 - accuracy: 1.0000 - val_loss: 0.4282 - val_accuracy: 0.9286\n",
            "Epoch 2582/4000\n",
            "1/1 [==============================] - 0s 49ms/step - loss: 7.2693e-04 - accuracy: 1.0000 - val_loss: 0.4283 - val_accuracy: 0.9286\n",
            "Epoch 2583/4000\n",
            "1/1 [==============================] - 0s 46ms/step - loss: 7.2613e-04 - accuracy: 1.0000 - val_loss: 0.4284 - val_accuracy: 0.9286\n",
            "Epoch 2584/4000\n",
            "1/1 [==============================] - 0s 48ms/step - loss: 7.2533e-04 - accuracy: 1.0000 - val_loss: 0.4284 - val_accuracy: 0.9286\n",
            "Epoch 2585/4000\n",
            "1/1 [==============================] - 0s 35ms/step - loss: 7.2457e-04 - accuracy: 1.0000 - val_loss: 0.4285 - val_accuracy: 0.9286\n",
            "Epoch 2586/4000\n",
            "1/1 [==============================] - 0s 51ms/step - loss: 7.2373e-04 - accuracy: 1.0000 - val_loss: 0.4286 - val_accuracy: 0.9286\n",
            "Epoch 2587/4000\n",
            "1/1 [==============================] - 0s 34ms/step - loss: 7.2290e-04 - accuracy: 1.0000 - val_loss: 0.4286 - val_accuracy: 0.9286\n",
            "Epoch 2588/4000\n",
            "1/1 [==============================] - 0s 43ms/step - loss: 7.2213e-04 - accuracy: 1.0000 - val_loss: 0.4287 - val_accuracy: 0.9286\n",
            "Epoch 2589/4000\n",
            "1/1 [==============================] - 0s 55ms/step - loss: 7.2135e-04 - accuracy: 1.0000 - val_loss: 0.4288 - val_accuracy: 0.9286\n",
            "Epoch 2590/4000\n",
            "1/1 [==============================] - 0s 51ms/step - loss: 7.2051e-04 - accuracy: 1.0000 - val_loss: 0.4289 - val_accuracy: 0.9286\n",
            "Epoch 2591/4000\n",
            "1/1 [==============================] - 0s 51ms/step - loss: 7.1972e-04 - accuracy: 1.0000 - val_loss: 0.4289 - val_accuracy: 0.9286\n",
            "Epoch 2592/4000\n",
            "1/1 [==============================] - 0s 50ms/step - loss: 7.1895e-04 - accuracy: 1.0000 - val_loss: 0.4290 - val_accuracy: 0.9286\n",
            "Epoch 2593/4000\n",
            "1/1 [==============================] - 0s 38ms/step - loss: 7.1815e-04 - accuracy: 1.0000 - val_loss: 0.4291 - val_accuracy: 0.9286\n",
            "Epoch 2594/4000\n",
            "1/1 [==============================] - 0s 47ms/step - loss: 7.1735e-04 - accuracy: 1.0000 - val_loss: 0.4291 - val_accuracy: 0.9286\n",
            "Epoch 2595/4000\n",
            "1/1 [==============================] - 0s 34ms/step - loss: 7.1656e-04 - accuracy: 1.0000 - val_loss: 0.4292 - val_accuracy: 0.9286\n",
            "Epoch 2596/4000\n",
            "1/1 [==============================] - 0s 46ms/step - loss: 7.1576e-04 - accuracy: 1.0000 - val_loss: 0.4293 - val_accuracy: 0.9286\n",
            "Epoch 2597/4000\n",
            "1/1 [==============================] - 0s 49ms/step - loss: 7.1500e-04 - accuracy: 1.0000 - val_loss: 0.4294 - val_accuracy: 0.9286\n",
            "Epoch 2598/4000\n",
            "1/1 [==============================] - 0s 34ms/step - loss: 7.1423e-04 - accuracy: 1.0000 - val_loss: 0.4294 - val_accuracy: 0.9286\n",
            "Epoch 2599/4000\n",
            "1/1 [==============================] - 0s 37ms/step - loss: 7.1343e-04 - accuracy: 1.0000 - val_loss: 0.4295 - val_accuracy: 0.9286\n",
            "Epoch 2600/4000\n",
            "1/1 [==============================] - 0s 47ms/step - loss: 7.1260e-04 - accuracy: 1.0000 - val_loss: 0.4296 - val_accuracy: 0.9286\n",
            "Epoch 2601/4000\n",
            "1/1 [==============================] - 0s 41ms/step - loss: 7.1180e-04 - accuracy: 1.0000 - val_loss: 0.4296 - val_accuracy: 0.9286\n",
            "Epoch 2602/4000\n",
            "1/1 [==============================] - 0s 36ms/step - loss: 7.1103e-04 - accuracy: 1.0000 - val_loss: 0.4297 - val_accuracy: 0.9286\n",
            "Epoch 2603/4000\n",
            "1/1 [==============================] - 0s 33ms/step - loss: 7.1028e-04 - accuracy: 1.0000 - val_loss: 0.4298 - val_accuracy: 0.9286\n",
            "Epoch 2604/4000\n",
            "1/1 [==============================] - 0s 52ms/step - loss: 7.0949e-04 - accuracy: 1.0000 - val_loss: 0.4299 - val_accuracy: 0.9286\n",
            "Epoch 2605/4000\n",
            "1/1 [==============================] - 0s 49ms/step - loss: 7.0866e-04 - accuracy: 1.0000 - val_loss: 0.4299 - val_accuracy: 0.9286\n",
            "Epoch 2606/4000\n",
            "1/1 [==============================] - 0s 57ms/step - loss: 7.0788e-04 - accuracy: 1.0000 - val_loss: 0.4300 - val_accuracy: 0.9286\n",
            "Epoch 2607/4000\n",
            "1/1 [==============================] - 0s 49ms/step - loss: 7.0718e-04 - accuracy: 1.0000 - val_loss: 0.4301 - val_accuracy: 0.9286\n",
            "Epoch 2608/4000\n",
            "1/1 [==============================] - 0s 35ms/step - loss: 7.0642e-04 - accuracy: 1.0000 - val_loss: 0.4302 - val_accuracy: 0.9286\n",
            "Epoch 2609/4000\n",
            "1/1 [==============================] - 0s 49ms/step - loss: 7.0563e-04 - accuracy: 1.0000 - val_loss: 0.4302 - val_accuracy: 0.9286\n",
            "Epoch 2610/4000\n",
            "1/1 [==============================] - 0s 36ms/step - loss: 7.0484e-04 - accuracy: 1.0000 - val_loss: 0.4303 - val_accuracy: 0.9286\n",
            "Epoch 2611/4000\n",
            "1/1 [==============================] - 0s 55ms/step - loss: 7.0405e-04 - accuracy: 1.0000 - val_loss: 0.4303 - val_accuracy: 0.9286\n",
            "Epoch 2612/4000\n",
            "1/1 [==============================] - 0s 49ms/step - loss: 7.0329e-04 - accuracy: 1.0000 - val_loss: 0.4304 - val_accuracy: 0.9286\n",
            "Epoch 2613/4000\n",
            "1/1 [==============================] - 0s 46ms/step - loss: 7.0254e-04 - accuracy: 1.0000 - val_loss: 0.4305 - val_accuracy: 0.9286\n",
            "Epoch 2614/4000\n",
            "1/1 [==============================] - 0s 44ms/step - loss: 7.0176e-04 - accuracy: 1.0000 - val_loss: 0.4306 - val_accuracy: 0.9286\n",
            "Epoch 2615/4000\n",
            "1/1 [==============================] - 0s 46ms/step - loss: 7.0098e-04 - accuracy: 1.0000 - val_loss: 0.4307 - val_accuracy: 0.9286\n",
            "Epoch 2616/4000\n",
            "1/1 [==============================] - 0s 41ms/step - loss: 7.0017e-04 - accuracy: 1.0000 - val_loss: 0.4307 - val_accuracy: 0.9286\n",
            "Epoch 2617/4000\n",
            "1/1 [==============================] - 0s 46ms/step - loss: 6.9942e-04 - accuracy: 1.0000 - val_loss: 0.4308 - val_accuracy: 0.9286\n",
            "Epoch 2618/4000\n",
            "1/1 [==============================] - 0s 55ms/step - loss: 6.9871e-04 - accuracy: 1.0000 - val_loss: 0.4309 - val_accuracy: 0.9286\n",
            "Epoch 2619/4000\n",
            "1/1 [==============================] - 0s 34ms/step - loss: 6.9796e-04 - accuracy: 1.0000 - val_loss: 0.4309 - val_accuracy: 0.9286\n",
            "Epoch 2620/4000\n",
            "1/1 [==============================] - 0s 49ms/step - loss: 6.9713e-04 - accuracy: 1.0000 - val_loss: 0.4310 - val_accuracy: 0.9286\n",
            "Epoch 2621/4000\n",
            "1/1 [==============================] - 0s 58ms/step - loss: 6.9633e-04 - accuracy: 1.0000 - val_loss: 0.4311 - val_accuracy: 0.9286\n",
            "Epoch 2622/4000\n",
            "1/1 [==============================] - 0s 48ms/step - loss: 6.9562e-04 - accuracy: 1.0000 - val_loss: 0.4312 - val_accuracy: 0.9286\n",
            "Epoch 2623/4000\n",
            "1/1 [==============================] - 0s 50ms/step - loss: 6.9488e-04 - accuracy: 1.0000 - val_loss: 0.4312 - val_accuracy: 0.9286\n",
            "Epoch 2624/4000\n",
            "1/1 [==============================] - 0s 47ms/step - loss: 6.9411e-04 - accuracy: 1.0000 - val_loss: 0.4313 - val_accuracy: 0.9286\n",
            "Epoch 2625/4000\n",
            "1/1 [==============================] - 0s 51ms/step - loss: 6.9332e-04 - accuracy: 1.0000 - val_loss: 0.4314 - val_accuracy: 0.9286\n",
            "Epoch 2626/4000\n",
            "1/1 [==============================] - 0s 37ms/step - loss: 6.9251e-04 - accuracy: 1.0000 - val_loss: 0.4314 - val_accuracy: 0.9286\n",
            "Epoch 2627/4000\n",
            "1/1 [==============================] - 0s 32ms/step - loss: 6.9176e-04 - accuracy: 1.0000 - val_loss: 0.4315 - val_accuracy: 0.9286\n",
            "Epoch 2628/4000\n",
            "1/1 [==============================] - 0s 41ms/step - loss: 6.9102e-04 - accuracy: 1.0000 - val_loss: 0.4316 - val_accuracy: 0.9286\n",
            "Epoch 2629/4000\n",
            "1/1 [==============================] - 0s 35ms/step - loss: 6.9027e-04 - accuracy: 1.0000 - val_loss: 0.4317 - val_accuracy: 0.9286\n",
            "Epoch 2630/4000\n",
            "1/1 [==============================] - 0s 46ms/step - loss: 6.8947e-04 - accuracy: 1.0000 - val_loss: 0.4317 - val_accuracy: 0.9286\n",
            "Epoch 2631/4000\n",
            "1/1 [==============================] - 0s 51ms/step - loss: 6.8872e-04 - accuracy: 1.0000 - val_loss: 0.4318 - val_accuracy: 0.9286\n",
            "Epoch 2632/4000\n",
            "1/1 [==============================] - 0s 49ms/step - loss: 6.8799e-04 - accuracy: 1.0000 - val_loss: 0.4319 - val_accuracy: 0.9286\n",
            "Epoch 2633/4000\n",
            "1/1 [==============================] - 0s 46ms/step - loss: 6.8726e-04 - accuracy: 1.0000 - val_loss: 0.4319 - val_accuracy: 0.9286\n",
            "Epoch 2634/4000\n",
            "1/1 [==============================] - 0s 38ms/step - loss: 6.8653e-04 - accuracy: 1.0000 - val_loss: 0.4320 - val_accuracy: 0.9286\n",
            "Epoch 2635/4000\n",
            "1/1 [==============================] - 0s 40ms/step - loss: 6.8576e-04 - accuracy: 1.0000 - val_loss: 0.4321 - val_accuracy: 0.9286\n",
            "Epoch 2636/4000\n",
            "1/1 [==============================] - 0s 48ms/step - loss: 6.8500e-04 - accuracy: 1.0000 - val_loss: 0.4321 - val_accuracy: 0.9286\n",
            "Epoch 2637/4000\n",
            "1/1 [==============================] - 0s 46ms/step - loss: 6.8425e-04 - accuracy: 1.0000 - val_loss: 0.4322 - val_accuracy: 0.9286\n",
            "Epoch 2638/4000\n",
            "1/1 [==============================] - 0s 54ms/step - loss: 6.8352e-04 - accuracy: 1.0000 - val_loss: 0.4323 - val_accuracy: 0.9286\n",
            "Epoch 2639/4000\n",
            "1/1 [==============================] - 0s 35ms/step - loss: 6.8276e-04 - accuracy: 1.0000 - val_loss: 0.4324 - val_accuracy: 0.9286\n",
            "Epoch 2640/4000\n",
            "1/1 [==============================] - 0s 47ms/step - loss: 6.8204e-04 - accuracy: 1.0000 - val_loss: 0.4324 - val_accuracy: 0.9286\n",
            "Epoch 2641/4000\n",
            "1/1 [==============================] - 0s 46ms/step - loss: 6.8129e-04 - accuracy: 1.0000 - val_loss: 0.4325 - val_accuracy: 0.9286\n",
            "Epoch 2642/4000\n",
            "1/1 [==============================] - 0s 51ms/step - loss: 6.8052e-04 - accuracy: 1.0000 - val_loss: 0.4326 - val_accuracy: 0.9286\n",
            "Epoch 2643/4000\n",
            "1/1 [==============================] - 0s 47ms/step - loss: 6.7978e-04 - accuracy: 1.0000 - val_loss: 0.4326 - val_accuracy: 0.9286\n",
            "Epoch 2644/4000\n",
            "1/1 [==============================] - 0s 52ms/step - loss: 6.7906e-04 - accuracy: 1.0000 - val_loss: 0.4327 - val_accuracy: 0.9286\n",
            "Epoch 2645/4000\n",
            "1/1 [==============================] - 0s 35ms/step - loss: 6.7836e-04 - accuracy: 1.0000 - val_loss: 0.4328 - val_accuracy: 0.9286\n",
            "Epoch 2646/4000\n",
            "1/1 [==============================] - 0s 52ms/step - loss: 6.7764e-04 - accuracy: 1.0000 - val_loss: 0.4328 - val_accuracy: 0.9286\n",
            "Epoch 2647/4000\n",
            "1/1 [==============================] - 0s 49ms/step - loss: 6.7686e-04 - accuracy: 1.0000 - val_loss: 0.4329 - val_accuracy: 0.9286\n",
            "Epoch 2648/4000\n",
            "1/1 [==============================] - 0s 48ms/step - loss: 6.7616e-04 - accuracy: 1.0000 - val_loss: 0.4330 - val_accuracy: 0.9286\n",
            "Epoch 2649/4000\n",
            "1/1 [==============================] - 0s 39ms/step - loss: 6.7547e-04 - accuracy: 1.0000 - val_loss: 0.4331 - val_accuracy: 0.9286\n",
            "Epoch 2650/4000\n",
            "1/1 [==============================] - 0s 49ms/step - loss: 6.7473e-04 - accuracy: 1.0000 - val_loss: 0.4331 - val_accuracy: 0.9286\n",
            "Epoch 2651/4000\n",
            "1/1 [==============================] - 0s 48ms/step - loss: 6.7394e-04 - accuracy: 1.0000 - val_loss: 0.4332 - val_accuracy: 0.9286\n",
            "Epoch 2652/4000\n",
            "1/1 [==============================] - 0s 46ms/step - loss: 6.7321e-04 - accuracy: 1.0000 - val_loss: 0.4333 - val_accuracy: 0.9286\n",
            "Epoch 2653/4000\n",
            "1/1 [==============================] - 0s 40ms/step - loss: 6.7254e-04 - accuracy: 1.0000 - val_loss: 0.4334 - val_accuracy: 0.9286\n",
            "Epoch 2654/4000\n",
            "1/1 [==============================] - 0s 47ms/step - loss: 6.7179e-04 - accuracy: 1.0000 - val_loss: 0.4334 - val_accuracy: 0.9286\n",
            "Epoch 2655/4000\n",
            "1/1 [==============================] - 0s 58ms/step - loss: 6.7099e-04 - accuracy: 1.0000 - val_loss: 0.4335 - val_accuracy: 0.9286\n",
            "Epoch 2656/4000\n",
            "1/1 [==============================] - 0s 51ms/step - loss: 6.7024e-04 - accuracy: 1.0000 - val_loss: 0.4336 - val_accuracy: 0.9286\n",
            "Epoch 2657/4000\n",
            "1/1 [==============================] - 0s 61ms/step - loss: 6.6952e-04 - accuracy: 1.0000 - val_loss: 0.4336 - val_accuracy: 0.9286\n",
            "Epoch 2658/4000\n",
            "1/1 [==============================] - 0s 52ms/step - loss: 6.6881e-04 - accuracy: 1.0000 - val_loss: 0.4337 - val_accuracy: 0.9286\n",
            "Epoch 2659/4000\n",
            "1/1 [==============================] - 0s 55ms/step - loss: 6.6811e-04 - accuracy: 1.0000 - val_loss: 0.4338 - val_accuracy: 0.9286\n",
            "Epoch 2660/4000\n",
            "1/1 [==============================] - 0s 56ms/step - loss: 6.6739e-04 - accuracy: 1.0000 - val_loss: 0.4338 - val_accuracy: 0.9286\n",
            "Epoch 2661/4000\n",
            "1/1 [==============================] - 0s 46ms/step - loss: 6.6667e-04 - accuracy: 1.0000 - val_loss: 0.4339 - val_accuracy: 0.9286\n",
            "Epoch 2662/4000\n",
            "1/1 [==============================] - 0s 43ms/step - loss: 6.6596e-04 - accuracy: 1.0000 - val_loss: 0.4340 - val_accuracy: 0.9286\n",
            "Epoch 2663/4000\n",
            "1/1 [==============================] - 0s 51ms/step - loss: 6.6525e-04 - accuracy: 1.0000 - val_loss: 0.4340 - val_accuracy: 0.9286\n",
            "Epoch 2664/4000\n",
            "1/1 [==============================] - 0s 41ms/step - loss: 6.6455e-04 - accuracy: 1.0000 - val_loss: 0.4341 - val_accuracy: 0.9286\n",
            "Epoch 2665/4000\n",
            "1/1 [==============================] - 0s 46ms/step - loss: 6.6382e-04 - accuracy: 1.0000 - val_loss: 0.4342 - val_accuracy: 0.9286\n",
            "Epoch 2666/4000\n",
            "1/1 [==============================] - 0s 46ms/step - loss: 6.6310e-04 - accuracy: 1.0000 - val_loss: 0.4343 - val_accuracy: 0.9286\n",
            "Epoch 2667/4000\n",
            "1/1 [==============================] - 0s 51ms/step - loss: 6.6237e-04 - accuracy: 1.0000 - val_loss: 0.4343 - val_accuracy: 0.9286\n",
            "Epoch 2668/4000\n",
            "1/1 [==============================] - 0s 48ms/step - loss: 6.6169e-04 - accuracy: 1.0000 - val_loss: 0.4344 - val_accuracy: 0.9286\n",
            "Epoch 2669/4000\n",
            "1/1 [==============================] - 0s 46ms/step - loss: 6.6100e-04 - accuracy: 1.0000 - val_loss: 0.4345 - val_accuracy: 0.9286\n",
            "Epoch 2670/4000\n",
            "1/1 [==============================] - 0s 40ms/step - loss: 6.6028e-04 - accuracy: 1.0000 - val_loss: 0.4346 - val_accuracy: 0.9286\n",
            "Epoch 2671/4000\n",
            "1/1 [==============================] - 0s 48ms/step - loss: 6.5952e-04 - accuracy: 1.0000 - val_loss: 0.4346 - val_accuracy: 0.9286\n",
            "Epoch 2672/4000\n",
            "1/1 [==============================] - 0s 56ms/step - loss: 6.5883e-04 - accuracy: 1.0000 - val_loss: 0.4347 - val_accuracy: 0.9286\n",
            "Epoch 2673/4000\n",
            "1/1 [==============================] - 0s 121ms/step - loss: 6.5813e-04 - accuracy: 1.0000 - val_loss: 0.4348 - val_accuracy: 0.9286\n",
            "Epoch 2674/4000\n",
            "1/1 [==============================] - 0s 150ms/step - loss: 6.5745e-04 - accuracy: 1.0000 - val_loss: 0.4348 - val_accuracy: 0.9286\n",
            "Epoch 2675/4000\n",
            "1/1 [==============================] - 0s 100ms/step - loss: 6.5675e-04 - accuracy: 1.0000 - val_loss: 0.4349 - val_accuracy: 0.9286\n",
            "Epoch 2676/4000\n",
            "1/1 [==============================] - 0s 108ms/step - loss: 6.5601e-04 - accuracy: 1.0000 - val_loss: 0.4350 - val_accuracy: 0.9286\n",
            "Epoch 2677/4000\n",
            "1/1 [==============================] - 0s 49ms/step - loss: 6.5530e-04 - accuracy: 1.0000 - val_loss: 0.4350 - val_accuracy: 0.9286\n",
            "Epoch 2678/4000\n",
            "1/1 [==============================] - 0s 34ms/step - loss: 6.5465e-04 - accuracy: 1.0000 - val_loss: 0.4351 - val_accuracy: 0.9286\n",
            "Epoch 2679/4000\n",
            "1/1 [==============================] - 0s 32ms/step - loss: 6.5397e-04 - accuracy: 1.0000 - val_loss: 0.4352 - val_accuracy: 0.9286\n",
            "Epoch 2680/4000\n",
            "1/1 [==============================] - 0s 38ms/step - loss: 6.5325e-04 - accuracy: 1.0000 - val_loss: 0.4352 - val_accuracy: 0.9286\n",
            "Epoch 2681/4000\n",
            "1/1 [==============================] - 0s 43ms/step - loss: 6.5254e-04 - accuracy: 1.0000 - val_loss: 0.4353 - val_accuracy: 0.9286\n",
            "Epoch 2682/4000\n",
            "1/1 [==============================] - 0s 42ms/step - loss: 6.5184e-04 - accuracy: 1.0000 - val_loss: 0.4354 - val_accuracy: 0.9286\n",
            "Epoch 2683/4000\n",
            "1/1 [==============================] - 0s 38ms/step - loss: 6.5113e-04 - accuracy: 1.0000 - val_loss: 0.4354 - val_accuracy: 0.9286\n",
            "Epoch 2684/4000\n",
            "1/1 [==============================] - 0s 49ms/step - loss: 6.5043e-04 - accuracy: 1.0000 - val_loss: 0.4355 - val_accuracy: 0.9286\n",
            "Epoch 2685/4000\n",
            "1/1 [==============================] - 0s 46ms/step - loss: 6.4976e-04 - accuracy: 1.0000 - val_loss: 0.4356 - val_accuracy: 0.9286\n",
            "Epoch 2686/4000\n",
            "1/1 [==============================] - 0s 52ms/step - loss: 6.4904e-04 - accuracy: 1.0000 - val_loss: 0.4357 - val_accuracy: 0.9286\n",
            "Epoch 2687/4000\n",
            "1/1 [==============================] - 0s 34ms/step - loss: 6.4836e-04 - accuracy: 1.0000 - val_loss: 0.4357 - val_accuracy: 0.9286\n",
            "Epoch 2688/4000\n",
            "1/1 [==============================] - 0s 49ms/step - loss: 6.4766e-04 - accuracy: 1.0000 - val_loss: 0.4358 - val_accuracy: 0.9286\n",
            "Epoch 2689/4000\n",
            "1/1 [==============================] - 0s 57ms/step - loss: 6.4696e-04 - accuracy: 1.0000 - val_loss: 0.4359 - val_accuracy: 0.9286\n",
            "Epoch 2690/4000\n",
            "1/1 [==============================] - 0s 50ms/step - loss: 6.4625e-04 - accuracy: 1.0000 - val_loss: 0.4359 - val_accuracy: 0.9286\n",
            "Epoch 2691/4000\n",
            "1/1 [==============================] - 0s 34ms/step - loss: 6.4556e-04 - accuracy: 1.0000 - val_loss: 0.4360 - val_accuracy: 0.9286\n",
            "Epoch 2692/4000\n",
            "1/1 [==============================] - 0s 40ms/step - loss: 6.4485e-04 - accuracy: 1.0000 - val_loss: 0.4361 - val_accuracy: 0.9286\n",
            "Epoch 2693/4000\n",
            "1/1 [==============================] - 0s 35ms/step - loss: 6.4415e-04 - accuracy: 1.0000 - val_loss: 0.4361 - val_accuracy: 0.9286\n",
            "Epoch 2694/4000\n",
            "1/1 [==============================] - 0s 41ms/step - loss: 6.4348e-04 - accuracy: 1.0000 - val_loss: 0.4362 - val_accuracy: 0.9286\n",
            "Epoch 2695/4000\n",
            "1/1 [==============================] - 0s 35ms/step - loss: 6.4278e-04 - accuracy: 1.0000 - val_loss: 0.4363 - val_accuracy: 0.9286\n",
            "Epoch 2696/4000\n",
            "1/1 [==============================] - 0s 37ms/step - loss: 6.4210e-04 - accuracy: 1.0000 - val_loss: 0.4363 - val_accuracy: 0.9286\n",
            "Epoch 2697/4000\n",
            "1/1 [==============================] - 0s 40ms/step - loss: 6.4143e-04 - accuracy: 1.0000 - val_loss: 0.4364 - val_accuracy: 0.9286\n",
            "Epoch 2698/4000\n",
            "1/1 [==============================] - 0s 38ms/step - loss: 6.4074e-04 - accuracy: 1.0000 - val_loss: 0.4365 - val_accuracy: 0.9286\n",
            "Epoch 2699/4000\n",
            "1/1 [==============================] - 0s 46ms/step - loss: 6.4006e-04 - accuracy: 1.0000 - val_loss: 0.4366 - val_accuracy: 0.9286\n",
            "Epoch 2700/4000\n",
            "1/1 [==============================] - 0s 50ms/step - loss: 6.3939e-04 - accuracy: 1.0000 - val_loss: 0.4366 - val_accuracy: 0.9286\n",
            "Epoch 2701/4000\n",
            "1/1 [==============================] - 0s 46ms/step - loss: 6.3871e-04 - accuracy: 1.0000 - val_loss: 0.4367 - val_accuracy: 0.9286\n",
            "Epoch 2702/4000\n",
            "1/1 [==============================] - 0s 35ms/step - loss: 6.3801e-04 - accuracy: 1.0000 - val_loss: 0.4368 - val_accuracy: 0.9286\n",
            "Epoch 2703/4000\n",
            "1/1 [==============================] - 0s 47ms/step - loss: 6.3734e-04 - accuracy: 1.0000 - val_loss: 0.4368 - val_accuracy: 0.9286\n",
            "Epoch 2704/4000\n",
            "1/1 [==============================] - 0s 52ms/step - loss: 6.3668e-04 - accuracy: 1.0000 - val_loss: 0.4369 - val_accuracy: 0.9286\n",
            "Epoch 2705/4000\n",
            "1/1 [==============================] - 0s 47ms/step - loss: 6.3601e-04 - accuracy: 1.0000 - val_loss: 0.4370 - val_accuracy: 0.9286\n",
            "Epoch 2706/4000\n",
            "1/1 [==============================] - 0s 48ms/step - loss: 6.3528e-04 - accuracy: 1.0000 - val_loss: 0.4370 - val_accuracy: 0.9286\n",
            "Epoch 2707/4000\n",
            "1/1 [==============================] - 0s 49ms/step - loss: 6.3457e-04 - accuracy: 1.0000 - val_loss: 0.4371 - val_accuracy: 0.9286\n",
            "Epoch 2708/4000\n",
            "1/1 [==============================] - 0s 46ms/step - loss: 6.3395e-04 - accuracy: 1.0000 - val_loss: 0.4372 - val_accuracy: 0.9286\n",
            "Epoch 2709/4000\n",
            "1/1 [==============================] - 0s 48ms/step - loss: 6.3331e-04 - accuracy: 1.0000 - val_loss: 0.4373 - val_accuracy: 0.9286\n",
            "Epoch 2710/4000\n",
            "1/1 [==============================] - 0s 35ms/step - loss: 6.3263e-04 - accuracy: 1.0000 - val_loss: 0.4373 - val_accuracy: 0.9286\n",
            "Epoch 2711/4000\n",
            "1/1 [==============================] - 0s 49ms/step - loss: 6.3195e-04 - accuracy: 1.0000 - val_loss: 0.4374 - val_accuracy: 0.9286\n",
            "Epoch 2712/4000\n",
            "1/1 [==============================] - 0s 49ms/step - loss: 6.3126e-04 - accuracy: 1.0000 - val_loss: 0.4375 - val_accuracy: 0.9286\n",
            "Epoch 2713/4000\n",
            "1/1 [==============================] - 0s 36ms/step - loss: 6.3059e-04 - accuracy: 1.0000 - val_loss: 0.4375 - val_accuracy: 0.9286\n",
            "Epoch 2714/4000\n",
            "1/1 [==============================] - 0s 34ms/step - loss: 6.2996e-04 - accuracy: 1.0000 - val_loss: 0.4376 - val_accuracy: 0.9286\n",
            "Epoch 2715/4000\n",
            "1/1 [==============================] - 0s 47ms/step - loss: 6.2927e-04 - accuracy: 1.0000 - val_loss: 0.4377 - val_accuracy: 0.9286\n",
            "Epoch 2716/4000\n",
            "1/1 [==============================] - 0s 52ms/step - loss: 6.2857e-04 - accuracy: 1.0000 - val_loss: 0.4377 - val_accuracy: 0.9286\n",
            "Epoch 2717/4000\n",
            "1/1 [==============================] - 0s 35ms/step - loss: 6.2789e-04 - accuracy: 1.0000 - val_loss: 0.4378 - val_accuracy: 0.9286\n",
            "Epoch 2718/4000\n",
            "1/1 [==============================] - 0s 53ms/step - loss: 6.2724e-04 - accuracy: 1.0000 - val_loss: 0.4379 - val_accuracy: 0.9286\n",
            "Epoch 2719/4000\n",
            "1/1 [==============================] - 0s 41ms/step - loss: 6.2659e-04 - accuracy: 1.0000 - val_loss: 0.4379 - val_accuracy: 0.9286\n",
            "Epoch 2720/4000\n",
            "1/1 [==============================] - 0s 32ms/step - loss: 6.2593e-04 - accuracy: 1.0000 - val_loss: 0.4380 - val_accuracy: 0.9286\n",
            "Epoch 2721/4000\n",
            "1/1 [==============================] - 0s 48ms/step - loss: 6.2525e-04 - accuracy: 1.0000 - val_loss: 0.4381 - val_accuracy: 0.9286\n",
            "Epoch 2722/4000\n",
            "1/1 [==============================] - 0s 49ms/step - loss: 6.2463e-04 - accuracy: 1.0000 - val_loss: 0.4381 - val_accuracy: 0.9286\n",
            "Epoch 2723/4000\n",
            "1/1 [==============================] - 0s 50ms/step - loss: 6.2399e-04 - accuracy: 1.0000 - val_loss: 0.4382 - val_accuracy: 0.9286\n",
            "Epoch 2724/4000\n",
            "1/1 [==============================] - 0s 46ms/step - loss: 6.2334e-04 - accuracy: 1.0000 - val_loss: 0.4383 - val_accuracy: 0.9286\n",
            "Epoch 2725/4000\n",
            "1/1 [==============================] - 0s 47ms/step - loss: 6.2267e-04 - accuracy: 1.0000 - val_loss: 0.4384 - val_accuracy: 0.9286\n",
            "Epoch 2726/4000\n",
            "1/1 [==============================] - 0s 47ms/step - loss: 6.2198e-04 - accuracy: 1.0000 - val_loss: 0.4384 - val_accuracy: 0.9286\n",
            "Epoch 2727/4000\n",
            "1/1 [==============================] - 0s 45ms/step - loss: 6.2134e-04 - accuracy: 1.0000 - val_loss: 0.4385 - val_accuracy: 0.9286\n",
            "Epoch 2728/4000\n",
            "1/1 [==============================] - 0s 50ms/step - loss: 6.2070e-04 - accuracy: 1.0000 - val_loss: 0.4386 - val_accuracy: 0.9286\n",
            "Epoch 2729/4000\n",
            "1/1 [==============================] - 0s 48ms/step - loss: 6.2007e-04 - accuracy: 1.0000 - val_loss: 0.4386 - val_accuracy: 0.9286\n",
            "Epoch 2730/4000\n",
            "1/1 [==============================] - 0s 49ms/step - loss: 6.1940e-04 - accuracy: 1.0000 - val_loss: 0.4387 - val_accuracy: 0.9286\n",
            "Epoch 2731/4000\n",
            "1/1 [==============================] - 0s 42ms/step - loss: 6.1872e-04 - accuracy: 1.0000 - val_loss: 0.4388 - val_accuracy: 0.9286\n",
            "Epoch 2732/4000\n",
            "1/1 [==============================] - 0s 48ms/step - loss: 6.1805e-04 - accuracy: 1.0000 - val_loss: 0.4389 - val_accuracy: 0.9286\n",
            "Epoch 2733/4000\n",
            "1/1 [==============================] - 0s 47ms/step - loss: 6.1742e-04 - accuracy: 1.0000 - val_loss: 0.4389 - val_accuracy: 0.9286\n",
            "Epoch 2734/4000\n",
            "1/1 [==============================] - 0s 52ms/step - loss: 6.1679e-04 - accuracy: 1.0000 - val_loss: 0.4390 - val_accuracy: 0.9286\n",
            "Epoch 2735/4000\n",
            "1/1 [==============================] - 0s 49ms/step - loss: 6.1613e-04 - accuracy: 1.0000 - val_loss: 0.4390 - val_accuracy: 0.9286\n",
            "Epoch 2736/4000\n",
            "1/1 [==============================] - 0s 49ms/step - loss: 6.1548e-04 - accuracy: 1.0000 - val_loss: 0.4391 - val_accuracy: 0.9286\n",
            "Epoch 2737/4000\n",
            "1/1 [==============================] - 0s 47ms/step - loss: 6.1483e-04 - accuracy: 1.0000 - val_loss: 0.4392 - val_accuracy: 0.9286\n",
            "Epoch 2738/4000\n",
            "1/1 [==============================] - 0s 49ms/step - loss: 6.1417e-04 - accuracy: 1.0000 - val_loss: 0.4393 - val_accuracy: 0.9286\n",
            "Epoch 2739/4000\n",
            "1/1 [==============================] - 0s 40ms/step - loss: 6.1354e-04 - accuracy: 1.0000 - val_loss: 0.4393 - val_accuracy: 0.9286\n",
            "Epoch 2740/4000\n",
            "1/1 [==============================] - 0s 49ms/step - loss: 6.1290e-04 - accuracy: 1.0000 - val_loss: 0.4394 - val_accuracy: 0.9286\n",
            "Epoch 2741/4000\n",
            "1/1 [==============================] - 0s 46ms/step - loss: 6.1224e-04 - accuracy: 1.0000 - val_loss: 0.4395 - val_accuracy: 0.9286\n",
            "Epoch 2742/4000\n",
            "1/1 [==============================] - 0s 38ms/step - loss: 6.1159e-04 - accuracy: 1.0000 - val_loss: 0.4395 - val_accuracy: 0.9286\n",
            "Epoch 2743/4000\n",
            "1/1 [==============================] - 0s 38ms/step - loss: 6.1096e-04 - accuracy: 1.0000 - val_loss: 0.4396 - val_accuracy: 0.9286\n",
            "Epoch 2744/4000\n",
            "1/1 [==============================] - 0s 45ms/step - loss: 6.1033e-04 - accuracy: 1.0000 - val_loss: 0.4397 - val_accuracy: 0.9286\n",
            "Epoch 2745/4000\n",
            "1/1 [==============================] - 0s 41ms/step - loss: 6.0966e-04 - accuracy: 1.0000 - val_loss: 0.4397 - val_accuracy: 0.9286\n",
            "Epoch 2746/4000\n",
            "1/1 [==============================] - 0s 39ms/step - loss: 6.0902e-04 - accuracy: 1.0000 - val_loss: 0.4398 - val_accuracy: 0.9286\n",
            "Epoch 2747/4000\n",
            "1/1 [==============================] - 0s 49ms/step - loss: 6.0839e-04 - accuracy: 1.0000 - val_loss: 0.4399 - val_accuracy: 0.9286\n",
            "Epoch 2748/4000\n",
            "1/1 [==============================] - 0s 47ms/step - loss: 6.0780e-04 - accuracy: 1.0000 - val_loss: 0.4399 - val_accuracy: 0.9286\n",
            "Epoch 2749/4000\n",
            "1/1 [==============================] - 0s 40ms/step - loss: 6.0716e-04 - accuracy: 1.0000 - val_loss: 0.4400 - val_accuracy: 0.9286\n",
            "Epoch 2750/4000\n",
            "1/1 [==============================] - 0s 53ms/step - loss: 6.0649e-04 - accuracy: 1.0000 - val_loss: 0.4401 - val_accuracy: 0.9286\n",
            "Epoch 2751/4000\n",
            "1/1 [==============================] - 0s 49ms/step - loss: 6.0587e-04 - accuracy: 1.0000 - val_loss: 0.4401 - val_accuracy: 0.9286\n",
            "Epoch 2752/4000\n",
            "1/1 [==============================] - 0s 46ms/step - loss: 6.0525e-04 - accuracy: 1.0000 - val_loss: 0.4402 - val_accuracy: 0.9286\n",
            "Epoch 2753/4000\n",
            "1/1 [==============================] - 0s 43ms/step - loss: 6.0465e-04 - accuracy: 1.0000 - val_loss: 0.4403 - val_accuracy: 0.9286\n",
            "Epoch 2754/4000\n",
            "1/1 [==============================] - 0s 48ms/step - loss: 6.0399e-04 - accuracy: 1.0000 - val_loss: 0.4404 - val_accuracy: 0.9286\n",
            "Epoch 2755/4000\n",
            "1/1 [==============================] - 0s 36ms/step - loss: 6.0333e-04 - accuracy: 1.0000 - val_loss: 0.4404 - val_accuracy: 0.9286\n",
            "Epoch 2756/4000\n",
            "1/1 [==============================] - 0s 47ms/step - loss: 6.0266e-04 - accuracy: 1.0000 - val_loss: 0.4405 - val_accuracy: 0.9286\n",
            "Epoch 2757/4000\n",
            "1/1 [==============================] - 0s 39ms/step - loss: 6.0209e-04 - accuracy: 1.0000 - val_loss: 0.4406 - val_accuracy: 0.9286\n",
            "Epoch 2758/4000\n",
            "1/1 [==============================] - 0s 53ms/step - loss: 6.0146e-04 - accuracy: 1.0000 - val_loss: 0.4406 - val_accuracy: 0.9286\n",
            "Epoch 2759/4000\n",
            "1/1 [==============================] - 0s 34ms/step - loss: 6.0081e-04 - accuracy: 1.0000 - val_loss: 0.4407 - val_accuracy: 0.9286\n",
            "Epoch 2760/4000\n",
            "1/1 [==============================] - 0s 35ms/step - loss: 6.0018e-04 - accuracy: 1.0000 - val_loss: 0.4408 - val_accuracy: 0.9286\n",
            "Epoch 2761/4000\n",
            "1/1 [==============================] - 0s 50ms/step - loss: 5.9954e-04 - accuracy: 1.0000 - val_loss: 0.4408 - val_accuracy: 0.9286\n",
            "Epoch 2762/4000\n",
            "1/1 [==============================] - 0s 52ms/step - loss: 5.9893e-04 - accuracy: 1.0000 - val_loss: 0.4409 - val_accuracy: 0.9286\n",
            "Epoch 2763/4000\n",
            "1/1 [==============================] - 0s 46ms/step - loss: 5.9832e-04 - accuracy: 1.0000 - val_loss: 0.4410 - val_accuracy: 0.9286\n",
            "Epoch 2764/4000\n",
            "1/1 [==============================] - 0s 50ms/step - loss: 5.9771e-04 - accuracy: 1.0000 - val_loss: 0.4410 - val_accuracy: 0.9286\n",
            "Epoch 2765/4000\n",
            "1/1 [==============================] - 0s 40ms/step - loss: 5.9706e-04 - accuracy: 1.0000 - val_loss: 0.4411 - val_accuracy: 0.9286\n",
            "Epoch 2766/4000\n",
            "1/1 [==============================] - 0s 48ms/step - loss: 5.9643e-04 - accuracy: 1.0000 - val_loss: 0.4412 - val_accuracy: 0.9286\n",
            "Epoch 2767/4000\n",
            "1/1 [==============================] - 0s 51ms/step - loss: 5.9580e-04 - accuracy: 1.0000 - val_loss: 0.4412 - val_accuracy: 0.9286\n",
            "Epoch 2768/4000\n",
            "1/1 [==============================] - 0s 49ms/step - loss: 5.9519e-04 - accuracy: 1.0000 - val_loss: 0.4413 - val_accuracy: 0.9286\n",
            "Epoch 2769/4000\n",
            "1/1 [==============================] - 0s 53ms/step - loss: 5.9460e-04 - accuracy: 1.0000 - val_loss: 0.4414 - val_accuracy: 0.9286\n",
            "Epoch 2770/4000\n",
            "1/1 [==============================] - 0s 37ms/step - loss: 5.9397e-04 - accuracy: 1.0000 - val_loss: 0.4415 - val_accuracy: 0.9286\n",
            "Epoch 2771/4000\n",
            "1/1 [==============================] - 0s 46ms/step - loss: 5.9332e-04 - accuracy: 1.0000 - val_loss: 0.4415 - val_accuracy: 0.9286\n",
            "Epoch 2772/4000\n",
            "1/1 [==============================] - 0s 34ms/step - loss: 5.9272e-04 - accuracy: 1.0000 - val_loss: 0.4416 - val_accuracy: 0.9286\n",
            "Epoch 2773/4000\n",
            "1/1 [==============================] - 0s 47ms/step - loss: 5.9211e-04 - accuracy: 1.0000 - val_loss: 0.4417 - val_accuracy: 0.9286\n",
            "Epoch 2774/4000\n",
            "1/1 [==============================] - 0s 39ms/step - loss: 5.9149e-04 - accuracy: 1.0000 - val_loss: 0.4417 - val_accuracy: 0.9286\n",
            "Epoch 2775/4000\n",
            "1/1 [==============================] - 0s 55ms/step - loss: 5.9087e-04 - accuracy: 1.0000 - val_loss: 0.4418 - val_accuracy: 0.9286\n",
            "Epoch 2776/4000\n",
            "1/1 [==============================] - 0s 38ms/step - loss: 5.9026e-04 - accuracy: 1.0000 - val_loss: 0.4419 - val_accuracy: 0.9286\n",
            "Epoch 2777/4000\n",
            "1/1 [==============================] - 0s 49ms/step - loss: 5.8966e-04 - accuracy: 1.0000 - val_loss: 0.4419 - val_accuracy: 0.9286\n",
            "Epoch 2778/4000\n",
            "1/1 [==============================] - 0s 42ms/step - loss: 5.8904e-04 - accuracy: 1.0000 - val_loss: 0.4420 - val_accuracy: 0.9286\n",
            "Epoch 2779/4000\n",
            "1/1 [==============================] - 0s 47ms/step - loss: 5.8846e-04 - accuracy: 1.0000 - val_loss: 0.4421 - val_accuracy: 0.9286\n",
            "Epoch 2780/4000\n",
            "1/1 [==============================] - 0s 49ms/step - loss: 5.8782e-04 - accuracy: 1.0000 - val_loss: 0.4421 - val_accuracy: 0.9286\n",
            "Epoch 2781/4000\n",
            "1/1 [==============================] - 0s 38ms/step - loss: 5.8721e-04 - accuracy: 1.0000 - val_loss: 0.4422 - val_accuracy: 0.9286\n",
            "Epoch 2782/4000\n",
            "1/1 [==============================] - 0s 46ms/step - loss: 5.8662e-04 - accuracy: 1.0000 - val_loss: 0.4423 - val_accuracy: 0.9286\n",
            "Epoch 2783/4000\n",
            "1/1 [==============================] - 0s 35ms/step - loss: 5.8600e-04 - accuracy: 1.0000 - val_loss: 0.4423 - val_accuracy: 0.9286\n",
            "Epoch 2784/4000\n",
            "1/1 [==============================] - 0s 48ms/step - loss: 5.8540e-04 - accuracy: 1.0000 - val_loss: 0.4424 - val_accuracy: 0.9286\n",
            "Epoch 2785/4000\n",
            "1/1 [==============================] - 0s 45ms/step - loss: 5.8479e-04 - accuracy: 1.0000 - val_loss: 0.4425 - val_accuracy: 0.9286\n",
            "Epoch 2786/4000\n",
            "1/1 [==============================] - 0s 52ms/step - loss: 5.8417e-04 - accuracy: 1.0000 - val_loss: 0.4425 - val_accuracy: 0.9286\n",
            "Epoch 2787/4000\n",
            "1/1 [==============================] - 0s 51ms/step - loss: 5.8359e-04 - accuracy: 1.0000 - val_loss: 0.4426 - val_accuracy: 0.9286\n",
            "Epoch 2788/4000\n",
            "1/1 [==============================] - 0s 35ms/step - loss: 5.8298e-04 - accuracy: 1.0000 - val_loss: 0.4427 - val_accuracy: 0.9286\n",
            "Epoch 2789/4000\n",
            "1/1 [==============================] - 0s 52ms/step - loss: 5.8239e-04 - accuracy: 1.0000 - val_loss: 0.4427 - val_accuracy: 0.9286\n",
            "Epoch 2790/4000\n",
            "1/1 [==============================] - 0s 78ms/step - loss: 5.8179e-04 - accuracy: 1.0000 - val_loss: 0.4428 - val_accuracy: 0.9286\n",
            "Epoch 2791/4000\n",
            "1/1 [==============================] - 0s 54ms/step - loss: 5.8118e-04 - accuracy: 1.0000 - val_loss: 0.4429 - val_accuracy: 0.9286\n",
            "Epoch 2792/4000\n",
            "1/1 [==============================] - 0s 57ms/step - loss: 5.8057e-04 - accuracy: 1.0000 - val_loss: 0.4429 - val_accuracy: 0.9286\n",
            "Epoch 2793/4000\n",
            "1/1 [==============================] - 0s 54ms/step - loss: 5.7999e-04 - accuracy: 1.0000 - val_loss: 0.4430 - val_accuracy: 0.9286\n",
            "Epoch 2794/4000\n",
            "1/1 [==============================] - 0s 48ms/step - loss: 5.7940e-04 - accuracy: 1.0000 - val_loss: 0.4431 - val_accuracy: 0.9286\n",
            "Epoch 2795/4000\n",
            "1/1 [==============================] - 0s 50ms/step - loss: 5.7880e-04 - accuracy: 1.0000 - val_loss: 0.4431 - val_accuracy: 0.9286\n",
            "Epoch 2796/4000\n",
            "1/1 [==============================] - 0s 44ms/step - loss: 5.7821e-04 - accuracy: 1.0000 - val_loss: 0.4432 - val_accuracy: 0.9286\n",
            "Epoch 2797/4000\n",
            "1/1 [==============================] - 0s 36ms/step - loss: 5.7762e-04 - accuracy: 1.0000 - val_loss: 0.4433 - val_accuracy: 0.9286\n",
            "Epoch 2798/4000\n",
            "1/1 [==============================] - 0s 47ms/step - loss: 5.7700e-04 - accuracy: 1.0000 - val_loss: 0.4433 - val_accuracy: 0.9286\n",
            "Epoch 2799/4000\n",
            "1/1 [==============================] - 0s 47ms/step - loss: 5.7642e-04 - accuracy: 1.0000 - val_loss: 0.4434 - val_accuracy: 0.9286\n",
            "Epoch 2800/4000\n",
            "1/1 [==============================] - 0s 49ms/step - loss: 5.7581e-04 - accuracy: 1.0000 - val_loss: 0.4435 - val_accuracy: 0.9286\n",
            "Epoch 2801/4000\n",
            "1/1 [==============================] - 0s 48ms/step - loss: 5.7520e-04 - accuracy: 1.0000 - val_loss: 0.4435 - val_accuracy: 0.9286\n",
            "Epoch 2802/4000\n",
            "1/1 [==============================] - 0s 46ms/step - loss: 5.7460e-04 - accuracy: 1.0000 - val_loss: 0.4436 - val_accuracy: 0.9286\n",
            "Epoch 2803/4000\n",
            "1/1 [==============================] - 0s 50ms/step - loss: 5.7403e-04 - accuracy: 1.0000 - val_loss: 0.4437 - val_accuracy: 0.9286\n",
            "Epoch 2804/4000\n",
            "1/1 [==============================] - 0s 32ms/step - loss: 5.7346e-04 - accuracy: 1.0000 - val_loss: 0.4438 - val_accuracy: 0.9286\n",
            "Epoch 2805/4000\n",
            "1/1 [==============================] - 0s 53ms/step - loss: 5.7288e-04 - accuracy: 1.0000 - val_loss: 0.4438 - val_accuracy: 0.9286\n",
            "Epoch 2806/4000\n",
            "1/1 [==============================] - 0s 50ms/step - loss: 5.7226e-04 - accuracy: 1.0000 - val_loss: 0.4439 - val_accuracy: 0.9286\n",
            "Epoch 2807/4000\n",
            "1/1 [==============================] - 0s 47ms/step - loss: 5.7165e-04 - accuracy: 1.0000 - val_loss: 0.4440 - val_accuracy: 0.9286\n",
            "Epoch 2808/4000\n",
            "1/1 [==============================] - 0s 36ms/step - loss: 5.7107e-04 - accuracy: 1.0000 - val_loss: 0.4440 - val_accuracy: 0.9286\n",
            "Epoch 2809/4000\n",
            "1/1 [==============================] - 0s 46ms/step - loss: 5.7047e-04 - accuracy: 1.0000 - val_loss: 0.4441 - val_accuracy: 0.9286\n",
            "Epoch 2810/4000\n",
            "1/1 [==============================] - 0s 54ms/step - loss: 5.6988e-04 - accuracy: 1.0000 - val_loss: 0.4442 - val_accuracy: 0.9286\n",
            "Epoch 2811/4000\n",
            "1/1 [==============================] - 0s 50ms/step - loss: 5.6932e-04 - accuracy: 1.0000 - val_loss: 0.4442 - val_accuracy: 0.9286\n",
            "Epoch 2812/4000\n",
            "1/1 [==============================] - 0s 51ms/step - loss: 5.6872e-04 - accuracy: 1.0000 - val_loss: 0.4443 - val_accuracy: 0.9286\n",
            "Epoch 2813/4000\n",
            "1/1 [==============================] - 0s 53ms/step - loss: 5.6811e-04 - accuracy: 1.0000 - val_loss: 0.4444 - val_accuracy: 0.9286\n",
            "Epoch 2814/4000\n",
            "1/1 [==============================] - 0s 48ms/step - loss: 5.6753e-04 - accuracy: 1.0000 - val_loss: 0.4444 - val_accuracy: 0.9286\n",
            "Epoch 2815/4000\n",
            "1/1 [==============================] - 0s 50ms/step - loss: 5.6695e-04 - accuracy: 1.0000 - val_loss: 0.4445 - val_accuracy: 0.9286\n",
            "Epoch 2816/4000\n",
            "1/1 [==============================] - 0s 48ms/step - loss: 5.6636e-04 - accuracy: 1.0000 - val_loss: 0.4446 - val_accuracy: 0.9286\n",
            "Epoch 2817/4000\n",
            "1/1 [==============================] - 0s 51ms/step - loss: 5.6574e-04 - accuracy: 1.0000 - val_loss: 0.4446 - val_accuracy: 0.9286\n",
            "Epoch 2818/4000\n",
            "1/1 [==============================] - 0s 47ms/step - loss: 5.6516e-04 - accuracy: 1.0000 - val_loss: 0.4447 - val_accuracy: 0.9286\n",
            "Epoch 2819/4000\n",
            "1/1 [==============================] - 0s 34ms/step - loss: 5.6460e-04 - accuracy: 1.0000 - val_loss: 0.4448 - val_accuracy: 0.9286\n",
            "Epoch 2820/4000\n",
            "1/1 [==============================] - 0s 33ms/step - loss: 5.6404e-04 - accuracy: 1.0000 - val_loss: 0.4448 - val_accuracy: 0.9286\n",
            "Epoch 2821/4000\n",
            "1/1 [==============================] - 0s 37ms/step - loss: 5.6344e-04 - accuracy: 1.0000 - val_loss: 0.4449 - val_accuracy: 0.9286\n",
            "Epoch 2822/4000\n",
            "1/1 [==============================] - 0s 48ms/step - loss: 5.6288e-04 - accuracy: 1.0000 - val_loss: 0.4450 - val_accuracy: 0.9286\n",
            "Epoch 2823/4000\n",
            "1/1 [==============================] - 0s 50ms/step - loss: 5.6232e-04 - accuracy: 1.0000 - val_loss: 0.4450 - val_accuracy: 0.9286\n",
            "Epoch 2824/4000\n",
            "1/1 [==============================] - 0s 49ms/step - loss: 5.6173e-04 - accuracy: 1.0000 - val_loss: 0.4451 - val_accuracy: 0.9286\n",
            "Epoch 2825/4000\n",
            "1/1 [==============================] - 0s 42ms/step - loss: 5.6113e-04 - accuracy: 1.0000 - val_loss: 0.4452 - val_accuracy: 0.9286\n",
            "Epoch 2826/4000\n",
            "1/1 [==============================] - 0s 55ms/step - loss: 5.6056e-04 - accuracy: 1.0000 - val_loss: 0.4452 - val_accuracy: 0.9286\n",
            "Epoch 2827/4000\n",
            "1/1 [==============================] - 0s 46ms/step - loss: 5.5999e-04 - accuracy: 1.0000 - val_loss: 0.4453 - val_accuracy: 0.9286\n",
            "Epoch 2828/4000\n",
            "1/1 [==============================] - 0s 34ms/step - loss: 5.5942e-04 - accuracy: 1.0000 - val_loss: 0.4453 - val_accuracy: 0.9286\n",
            "Epoch 2829/4000\n",
            "1/1 [==============================] - 0s 47ms/step - loss: 5.5884e-04 - accuracy: 1.0000 - val_loss: 0.4454 - val_accuracy: 0.9286\n",
            "Epoch 2830/4000\n",
            "1/1 [==============================] - 0s 40ms/step - loss: 5.5827e-04 - accuracy: 1.0000 - val_loss: 0.4455 - val_accuracy: 0.9286\n",
            "Epoch 2831/4000\n",
            "1/1 [==============================] - 0s 55ms/step - loss: 5.5771e-04 - accuracy: 1.0000 - val_loss: 0.4456 - val_accuracy: 0.9286\n",
            "Epoch 2832/4000\n",
            "1/1 [==============================] - 0s 44ms/step - loss: 5.5713e-04 - accuracy: 1.0000 - val_loss: 0.4456 - val_accuracy: 0.9286\n",
            "Epoch 2833/4000\n",
            "1/1 [==============================] - 0s 48ms/step - loss: 5.5655e-04 - accuracy: 1.0000 - val_loss: 0.4457 - val_accuracy: 0.9286\n",
            "Epoch 2834/4000\n",
            "1/1 [==============================] - 0s 49ms/step - loss: 5.5601e-04 - accuracy: 1.0000 - val_loss: 0.4458 - val_accuracy: 0.9286\n",
            "Epoch 2835/4000\n",
            "1/1 [==============================] - 0s 46ms/step - loss: 5.5544e-04 - accuracy: 1.0000 - val_loss: 0.4458 - val_accuracy: 0.9286\n",
            "Epoch 2836/4000\n",
            "1/1 [==============================] - 0s 43ms/step - loss: 5.5485e-04 - accuracy: 1.0000 - val_loss: 0.4459 - val_accuracy: 0.9286\n",
            "Epoch 2837/4000\n",
            "1/1 [==============================] - 0s 53ms/step - loss: 5.5427e-04 - accuracy: 1.0000 - val_loss: 0.4460 - val_accuracy: 0.9286\n",
            "Epoch 2838/4000\n",
            "1/1 [==============================] - 0s 51ms/step - loss: 5.5371e-04 - accuracy: 1.0000 - val_loss: 0.4460 - val_accuracy: 0.9286\n",
            "Epoch 2839/4000\n",
            "1/1 [==============================] - 0s 56ms/step - loss: 5.5316e-04 - accuracy: 1.0000 - val_loss: 0.4461 - val_accuracy: 0.9286\n",
            "Epoch 2840/4000\n",
            "1/1 [==============================] - 0s 51ms/step - loss: 5.5259e-04 - accuracy: 1.0000 - val_loss: 0.4462 - val_accuracy: 0.9286\n",
            "Epoch 2841/4000\n",
            "1/1 [==============================] - 0s 49ms/step - loss: 5.5201e-04 - accuracy: 1.0000 - val_loss: 0.4463 - val_accuracy: 0.9286\n",
            "Epoch 2842/4000\n",
            "1/1 [==============================] - 0s 46ms/step - loss: 5.5147e-04 - accuracy: 1.0000 - val_loss: 0.4463 - val_accuracy: 0.9286\n",
            "Epoch 2843/4000\n",
            "1/1 [==============================] - 0s 50ms/step - loss: 5.5091e-04 - accuracy: 1.0000 - val_loss: 0.4464 - val_accuracy: 0.9286\n",
            "Epoch 2844/4000\n",
            "1/1 [==============================] - 0s 50ms/step - loss: 5.5034e-04 - accuracy: 1.0000 - val_loss: 0.4465 - val_accuracy: 0.9286\n",
            "Epoch 2845/4000\n",
            "1/1 [==============================] - 0s 49ms/step - loss: 5.4976e-04 - accuracy: 1.0000 - val_loss: 0.4465 - val_accuracy: 0.9286\n",
            "Epoch 2846/4000\n",
            "1/1 [==============================] - 0s 42ms/step - loss: 5.4919e-04 - accuracy: 1.0000 - val_loss: 0.4466 - val_accuracy: 0.9286\n",
            "Epoch 2847/4000\n",
            "1/1 [==============================] - 0s 37ms/step - loss: 5.4865e-04 - accuracy: 1.0000 - val_loss: 0.4467 - val_accuracy: 0.9286\n",
            "Epoch 2848/4000\n",
            "1/1 [==============================] - 0s 48ms/step - loss: 5.4809e-04 - accuracy: 1.0000 - val_loss: 0.4467 - val_accuracy: 0.9286\n",
            "Epoch 2849/4000\n",
            "1/1 [==============================] - 0s 33ms/step - loss: 5.4752e-04 - accuracy: 1.0000 - val_loss: 0.4468 - val_accuracy: 0.9286\n",
            "Epoch 2850/4000\n",
            "1/1 [==============================] - 0s 33ms/step - loss: 5.4697e-04 - accuracy: 1.0000 - val_loss: 0.4469 - val_accuracy: 0.9286\n",
            "Epoch 2851/4000\n",
            "1/1 [==============================] - 0s 54ms/step - loss: 5.4642e-04 - accuracy: 1.0000 - val_loss: 0.4469 - val_accuracy: 0.9286\n",
            "Epoch 2852/4000\n",
            "1/1 [==============================] - 0s 37ms/step - loss: 5.4586e-04 - accuracy: 1.0000 - val_loss: 0.4470 - val_accuracy: 0.9286\n",
            "Epoch 2853/4000\n",
            "1/1 [==============================] - 0s 48ms/step - loss: 5.4528e-04 - accuracy: 1.0000 - val_loss: 0.4470 - val_accuracy: 0.9286\n",
            "Epoch 2854/4000\n",
            "1/1 [==============================] - 0s 39ms/step - loss: 5.4474e-04 - accuracy: 1.0000 - val_loss: 0.4471 - val_accuracy: 0.9286\n",
            "Epoch 2855/4000\n",
            "1/1 [==============================] - 0s 48ms/step - loss: 5.4423e-04 - accuracy: 1.0000 - val_loss: 0.4472 - val_accuracy: 0.9286\n",
            "Epoch 2856/4000\n",
            "1/1 [==============================] - 0s 46ms/step - loss: 5.4369e-04 - accuracy: 1.0000 - val_loss: 0.4472 - val_accuracy: 0.9286\n",
            "Epoch 2857/4000\n",
            "1/1 [==============================] - 0s 40ms/step - loss: 5.4311e-04 - accuracy: 1.0000 - val_loss: 0.4473 - val_accuracy: 0.9286\n",
            "Epoch 2858/4000\n",
            "1/1 [==============================] - 0s 35ms/step - loss: 5.4253e-04 - accuracy: 1.0000 - val_loss: 0.4474 - val_accuracy: 0.9286\n",
            "Epoch 2859/4000\n",
            "1/1 [==============================] - 0s 52ms/step - loss: 5.4199e-04 - accuracy: 1.0000 - val_loss: 0.4474 - val_accuracy: 0.9286\n",
            "Epoch 2860/4000\n",
            "1/1 [==============================] - 0s 51ms/step - loss: 5.4143e-04 - accuracy: 1.0000 - val_loss: 0.4475 - val_accuracy: 0.9286\n",
            "Epoch 2861/4000\n",
            "1/1 [==============================] - 0s 50ms/step - loss: 5.4087e-04 - accuracy: 1.0000 - val_loss: 0.4476 - val_accuracy: 0.9286\n",
            "Epoch 2862/4000\n",
            "1/1 [==============================] - 0s 41ms/step - loss: 5.4034e-04 - accuracy: 1.0000 - val_loss: 0.4476 - val_accuracy: 0.9286\n",
            "Epoch 2863/4000\n",
            "1/1 [==============================] - 0s 54ms/step - loss: 5.3980e-04 - accuracy: 1.0000 - val_loss: 0.4477 - val_accuracy: 0.9286\n",
            "Epoch 2864/4000\n",
            "1/1 [==============================] - 0s 53ms/step - loss: 5.3924e-04 - accuracy: 1.0000 - val_loss: 0.4478 - val_accuracy: 0.9286\n",
            "Epoch 2865/4000\n",
            "1/1 [==============================] - 0s 50ms/step - loss: 5.3871e-04 - accuracy: 1.0000 - val_loss: 0.4478 - val_accuracy: 0.9286\n",
            "Epoch 2866/4000\n",
            "1/1 [==============================] - 0s 37ms/step - loss: 5.3817e-04 - accuracy: 1.0000 - val_loss: 0.4479 - val_accuracy: 0.9286\n",
            "Epoch 2867/4000\n",
            "1/1 [==============================] - 0s 50ms/step - loss: 5.3764e-04 - accuracy: 1.0000 - val_loss: 0.4479 - val_accuracy: 0.9286\n",
            "Epoch 2868/4000\n",
            "1/1 [==============================] - 0s 36ms/step - loss: 5.3708e-04 - accuracy: 1.0000 - val_loss: 0.4480 - val_accuracy: 0.9286\n",
            "Epoch 2869/4000\n",
            "1/1 [==============================] - 0s 56ms/step - loss: 5.3652e-04 - accuracy: 1.0000 - val_loss: 0.4481 - val_accuracy: 0.9286\n",
            "Epoch 2870/4000\n",
            "1/1 [==============================] - 0s 34ms/step - loss: 5.3597e-04 - accuracy: 1.0000 - val_loss: 0.4481 - val_accuracy: 0.9286\n",
            "Epoch 2871/4000\n",
            "1/1 [==============================] - 0s 47ms/step - loss: 5.3544e-04 - accuracy: 1.0000 - val_loss: 0.4482 - val_accuracy: 0.9286\n",
            "Epoch 2872/4000\n",
            "1/1 [==============================] - 0s 47ms/step - loss: 5.3490e-04 - accuracy: 1.0000 - val_loss: 0.4483 - val_accuracy: 0.9286\n",
            "Epoch 2873/4000\n",
            "1/1 [==============================] - 0s 35ms/step - loss: 5.3434e-04 - accuracy: 1.0000 - val_loss: 0.4483 - val_accuracy: 0.9286\n",
            "Epoch 2874/4000\n",
            "1/1 [==============================] - 0s 47ms/step - loss: 5.3382e-04 - accuracy: 1.0000 - val_loss: 0.4484 - val_accuracy: 0.9286\n",
            "Epoch 2875/4000\n",
            "1/1 [==============================] - 0s 41ms/step - loss: 5.3329e-04 - accuracy: 1.0000 - val_loss: 0.4485 - val_accuracy: 0.9286\n",
            "Epoch 2876/4000\n",
            "1/1 [==============================] - 0s 33ms/step - loss: 5.3275e-04 - accuracy: 1.0000 - val_loss: 0.4485 - val_accuracy: 0.9286\n",
            "Epoch 2877/4000\n",
            "1/1 [==============================] - 0s 51ms/step - loss: 5.3221e-04 - accuracy: 1.0000 - val_loss: 0.4486 - val_accuracy: 0.9286\n",
            "Epoch 2878/4000\n",
            "1/1 [==============================] - 0s 48ms/step - loss: 5.3169e-04 - accuracy: 1.0000 - val_loss: 0.4486 - val_accuracy: 0.9286\n",
            "Epoch 2879/4000\n",
            "1/1 [==============================] - 0s 39ms/step - loss: 5.3114e-04 - accuracy: 1.0000 - val_loss: 0.4487 - val_accuracy: 0.9286\n",
            "Epoch 2880/4000\n",
            "1/1 [==============================] - 0s 41ms/step - loss: 5.3057e-04 - accuracy: 1.0000 - val_loss: 0.4488 - val_accuracy: 0.9286\n",
            "Epoch 2881/4000\n",
            "1/1 [==============================] - 0s 47ms/step - loss: 5.3006e-04 - accuracy: 1.0000 - val_loss: 0.4488 - val_accuracy: 0.9286\n",
            "Epoch 2882/4000\n",
            "1/1 [==============================] - 0s 51ms/step - loss: 5.2953e-04 - accuracy: 1.0000 - val_loss: 0.4489 - val_accuracy: 0.9286\n",
            "Epoch 2883/4000\n",
            "1/1 [==============================] - 0s 33ms/step - loss: 5.2900e-04 - accuracy: 1.0000 - val_loss: 0.4490 - val_accuracy: 0.9286\n",
            "Epoch 2884/4000\n",
            "1/1 [==============================] - 0s 48ms/step - loss: 5.2845e-04 - accuracy: 1.0000 - val_loss: 0.4490 - val_accuracy: 0.9286\n",
            "Epoch 2885/4000\n",
            "1/1 [==============================] - 0s 46ms/step - loss: 5.2790e-04 - accuracy: 1.0000 - val_loss: 0.4491 - val_accuracy: 0.9286\n",
            "Epoch 2886/4000\n",
            "1/1 [==============================] - 0s 55ms/step - loss: 5.2737e-04 - accuracy: 1.0000 - val_loss: 0.4492 - val_accuracy: 0.9286\n",
            "Epoch 2887/4000\n",
            "1/1 [==============================] - 0s 48ms/step - loss: 5.2685e-04 - accuracy: 1.0000 - val_loss: 0.4492 - val_accuracy: 0.9286\n",
            "Epoch 2888/4000\n",
            "1/1 [==============================] - 0s 54ms/step - loss: 5.2633e-04 - accuracy: 1.0000 - val_loss: 0.4493 - val_accuracy: 0.9286\n",
            "Epoch 2889/4000\n",
            "1/1 [==============================] - 0s 46ms/step - loss: 5.2578e-04 - accuracy: 1.0000 - val_loss: 0.4494 - val_accuracy: 0.9286\n",
            "Epoch 2890/4000\n",
            "1/1 [==============================] - 0s 55ms/step - loss: 5.2525e-04 - accuracy: 1.0000 - val_loss: 0.4494 - val_accuracy: 0.9286\n",
            "Epoch 2891/4000\n",
            "1/1 [==============================] - 0s 47ms/step - loss: 5.2476e-04 - accuracy: 1.0000 - val_loss: 0.4495 - val_accuracy: 0.9286\n",
            "Epoch 2892/4000\n",
            "1/1 [==============================] - 0s 59ms/step - loss: 5.2425e-04 - accuracy: 1.0000 - val_loss: 0.4496 - val_accuracy: 0.9286\n",
            "Epoch 2893/4000\n",
            "1/1 [==============================] - 0s 51ms/step - loss: 5.2373e-04 - accuracy: 1.0000 - val_loss: 0.4496 - val_accuracy: 0.9286\n",
            "Epoch 2894/4000\n",
            "1/1 [==============================] - 0s 48ms/step - loss: 5.2318e-04 - accuracy: 1.0000 - val_loss: 0.4497 - val_accuracy: 0.9286\n",
            "Epoch 2895/4000\n",
            "1/1 [==============================] - 0s 47ms/step - loss: 5.2266e-04 - accuracy: 1.0000 - val_loss: 0.4497 - val_accuracy: 0.9286\n",
            "Epoch 2896/4000\n",
            "1/1 [==============================] - 0s 57ms/step - loss: 5.2216e-04 - accuracy: 1.0000 - val_loss: 0.4498 - val_accuracy: 0.9286\n",
            "Epoch 2897/4000\n",
            "1/1 [==============================] - 0s 49ms/step - loss: 5.2162e-04 - accuracy: 1.0000 - val_loss: 0.4499 - val_accuracy: 0.9286\n",
            "Epoch 2898/4000\n",
            "1/1 [==============================] - 0s 41ms/step - loss: 5.2109e-04 - accuracy: 1.0000 - val_loss: 0.4499 - val_accuracy: 0.9286\n",
            "Epoch 2899/4000\n",
            "1/1 [==============================] - 0s 35ms/step - loss: 5.2057e-04 - accuracy: 1.0000 - val_loss: 0.4500 - val_accuracy: 0.9286\n",
            "Epoch 2900/4000\n",
            "1/1 [==============================] - 0s 40ms/step - loss: 5.2005e-04 - accuracy: 1.0000 - val_loss: 0.4501 - val_accuracy: 0.9286\n",
            "Epoch 2901/4000\n",
            "1/1 [==============================] - 0s 51ms/step - loss: 5.1952e-04 - accuracy: 1.0000 - val_loss: 0.4501 - val_accuracy: 0.9286\n",
            "Epoch 2902/4000\n",
            "1/1 [==============================] - 0s 47ms/step - loss: 5.1899e-04 - accuracy: 1.0000 - val_loss: 0.4502 - val_accuracy: 0.9286\n",
            "Epoch 2903/4000\n",
            "1/1 [==============================] - 0s 33ms/step - loss: 5.1845e-04 - accuracy: 1.0000 - val_loss: 0.4503 - val_accuracy: 0.9286\n",
            "Epoch 2904/4000\n",
            "1/1 [==============================] - 0s 46ms/step - loss: 5.1793e-04 - accuracy: 1.0000 - val_loss: 0.4503 - val_accuracy: 0.9286\n",
            "Epoch 2905/4000\n",
            "1/1 [==============================] - 0s 44ms/step - loss: 5.1744e-04 - accuracy: 1.0000 - val_loss: 0.4504 - val_accuracy: 0.9286\n",
            "Epoch 2906/4000\n",
            "1/1 [==============================] - 0s 33ms/step - loss: 5.1692e-04 - accuracy: 1.0000 - val_loss: 0.4504 - val_accuracy: 0.9286\n",
            "Epoch 2907/4000\n",
            "1/1 [==============================] - 0s 49ms/step - loss: 5.1638e-04 - accuracy: 1.0000 - val_loss: 0.4505 - val_accuracy: 0.9286\n",
            "Epoch 2908/4000\n",
            "1/1 [==============================] - 0s 47ms/step - loss: 5.1586e-04 - accuracy: 1.0000 - val_loss: 0.4506 - val_accuracy: 0.9286\n",
            "Epoch 2909/4000\n",
            "1/1 [==============================] - 0s 54ms/step - loss: 5.1538e-04 - accuracy: 1.0000 - val_loss: 0.4506 - val_accuracy: 0.9286\n",
            "Epoch 2910/4000\n",
            "1/1 [==============================] - 0s 36ms/step - loss: 5.1486e-04 - accuracy: 1.0000 - val_loss: 0.4507 - val_accuracy: 0.9286\n",
            "Epoch 2911/4000\n",
            "1/1 [==============================] - 0s 48ms/step - loss: 5.1434e-04 - accuracy: 1.0000 - val_loss: 0.4508 - val_accuracy: 0.9286\n",
            "Epoch 2912/4000\n",
            "1/1 [==============================] - 0s 46ms/step - loss: 5.1379e-04 - accuracy: 1.0000 - val_loss: 0.4508 - val_accuracy: 0.9286\n",
            "Epoch 2913/4000\n",
            "1/1 [==============================] - 0s 54ms/step - loss: 5.1329e-04 - accuracy: 1.0000 - val_loss: 0.4509 - val_accuracy: 0.9286\n",
            "Epoch 2914/4000\n",
            "1/1 [==============================] - 0s 37ms/step - loss: 5.1281e-04 - accuracy: 1.0000 - val_loss: 0.4510 - val_accuracy: 0.9286\n",
            "Epoch 2915/4000\n",
            "1/1 [==============================] - 0s 45ms/step - loss: 5.1230e-04 - accuracy: 1.0000 - val_loss: 0.4510 - val_accuracy: 0.9286\n",
            "Epoch 2916/4000\n",
            "1/1 [==============================] - 0s 46ms/step - loss: 5.1177e-04 - accuracy: 1.0000 - val_loss: 0.4511 - val_accuracy: 0.9286\n",
            "Epoch 2917/4000\n",
            "1/1 [==============================] - 0s 46ms/step - loss: 5.1124e-04 - accuracy: 1.0000 - val_loss: 0.4511 - val_accuracy: 0.9286\n",
            "Epoch 2918/4000\n",
            "1/1 [==============================] - 0s 47ms/step - loss: 5.1076e-04 - accuracy: 1.0000 - val_loss: 0.4512 - val_accuracy: 0.9286\n",
            "Epoch 2919/4000\n",
            "1/1 [==============================] - 0s 66ms/step - loss: 5.1026e-04 - accuracy: 1.0000 - val_loss: 0.4513 - val_accuracy: 0.9286\n",
            "Epoch 2920/4000\n",
            "1/1 [==============================] - 0s 35ms/step - loss: 5.0975e-04 - accuracy: 1.0000 - val_loss: 0.4513 - val_accuracy: 0.9286\n",
            "Epoch 2921/4000\n",
            "1/1 [==============================] - 0s 47ms/step - loss: 5.0922e-04 - accuracy: 1.0000 - val_loss: 0.4514 - val_accuracy: 0.9286\n",
            "Epoch 2922/4000\n",
            "1/1 [==============================] - 0s 50ms/step - loss: 5.0870e-04 - accuracy: 1.0000 - val_loss: 0.4515 - val_accuracy: 0.9286\n",
            "Epoch 2923/4000\n",
            "1/1 [==============================] - 0s 36ms/step - loss: 5.0824e-04 - accuracy: 1.0000 - val_loss: 0.4515 - val_accuracy: 0.9286\n",
            "Epoch 2924/4000\n",
            "1/1 [==============================] - 0s 32ms/step - loss: 5.0773e-04 - accuracy: 1.0000 - val_loss: 0.4516 - val_accuracy: 0.9286\n",
            "Epoch 2925/4000\n",
            "1/1 [==============================] - 0s 47ms/step - loss: 5.0720e-04 - accuracy: 1.0000 - val_loss: 0.4517 - val_accuracy: 0.9286\n",
            "Epoch 2926/4000\n",
            "1/1 [==============================] - 0s 48ms/step - loss: 5.0672e-04 - accuracy: 1.0000 - val_loss: 0.4517 - val_accuracy: 0.9286\n",
            "Epoch 2927/4000\n",
            "1/1 [==============================] - 0s 35ms/step - loss: 5.0622e-04 - accuracy: 1.0000 - val_loss: 0.4518 - val_accuracy: 0.9286\n",
            "Epoch 2928/4000\n",
            "1/1 [==============================] - 0s 51ms/step - loss: 5.0571e-04 - accuracy: 1.0000 - val_loss: 0.4519 - val_accuracy: 0.9286\n",
            "Epoch 2929/4000\n",
            "1/1 [==============================] - 0s 40ms/step - loss: 5.0519e-04 - accuracy: 1.0000 - val_loss: 0.4519 - val_accuracy: 0.9286\n",
            "Epoch 2930/4000\n",
            "1/1 [==============================] - 0s 40ms/step - loss: 5.0468e-04 - accuracy: 1.0000 - val_loss: 0.4520 - val_accuracy: 0.9286\n",
            "Epoch 2931/4000\n",
            "1/1 [==============================] - 0s 48ms/step - loss: 5.0419e-04 - accuracy: 1.0000 - val_loss: 0.4520 - val_accuracy: 0.9286\n",
            "Epoch 2932/4000\n",
            "1/1 [==============================] - 0s 47ms/step - loss: 5.0371e-04 - accuracy: 1.0000 - val_loss: 0.4521 - val_accuracy: 0.9286\n",
            "Epoch 2933/4000\n",
            "1/1 [==============================] - 0s 35ms/step - loss: 5.0320e-04 - accuracy: 1.0000 - val_loss: 0.4522 - val_accuracy: 0.9286\n",
            "Epoch 2934/4000\n",
            "1/1 [==============================] - 0s 48ms/step - loss: 5.0270e-04 - accuracy: 1.0000 - val_loss: 0.4522 - val_accuracy: 0.9286\n",
            "Epoch 2935/4000\n",
            "1/1 [==============================] - 0s 42ms/step - loss: 5.0219e-04 - accuracy: 1.0000 - val_loss: 0.4523 - val_accuracy: 0.9286\n",
            "Epoch 2936/4000\n",
            "1/1 [==============================] - 0s 46ms/step - loss: 5.0170e-04 - accuracy: 1.0000 - val_loss: 0.4524 - val_accuracy: 0.9286\n",
            "Epoch 2937/4000\n",
            "1/1 [==============================] - 0s 38ms/step - loss: 5.0118e-04 - accuracy: 1.0000 - val_loss: 0.4524 - val_accuracy: 0.9286\n",
            "Epoch 2938/4000\n",
            "1/1 [==============================] - 0s 59ms/step - loss: 5.0069e-04 - accuracy: 1.0000 - val_loss: 0.4525 - val_accuracy: 0.9286\n",
            "Epoch 2939/4000\n",
            "1/1 [==============================] - 0s 51ms/step - loss: 5.0022e-04 - accuracy: 1.0000 - val_loss: 0.4526 - val_accuracy: 0.9286\n",
            "Epoch 2940/4000\n",
            "1/1 [==============================] - 0s 49ms/step - loss: 4.9971e-04 - accuracy: 1.0000 - val_loss: 0.4526 - val_accuracy: 0.9286\n",
            "Epoch 2941/4000\n",
            "1/1 [==============================] - 0s 33ms/step - loss: 4.9924e-04 - accuracy: 1.0000 - val_loss: 0.4527 - val_accuracy: 0.9286\n",
            "Epoch 2942/4000\n",
            "1/1 [==============================] - 0s 49ms/step - loss: 4.9874e-04 - accuracy: 1.0000 - val_loss: 0.4527 - val_accuracy: 0.9286\n",
            "Epoch 2943/4000\n",
            "1/1 [==============================] - 0s 52ms/step - loss: 4.9825e-04 - accuracy: 1.0000 - val_loss: 0.4528 - val_accuracy: 0.9286\n",
            "Epoch 2944/4000\n",
            "1/1 [==============================] - 0s 46ms/step - loss: 4.9777e-04 - accuracy: 1.0000 - val_loss: 0.4529 - val_accuracy: 0.9286\n",
            "Epoch 2945/4000\n",
            "1/1 [==============================] - 0s 33ms/step - loss: 4.9726e-04 - accuracy: 1.0000 - val_loss: 0.4529 - val_accuracy: 0.9286\n",
            "Epoch 2946/4000\n",
            "1/1 [==============================] - 0s 47ms/step - loss: 4.9674e-04 - accuracy: 1.0000 - val_loss: 0.4530 - val_accuracy: 0.9286\n",
            "Epoch 2947/4000\n",
            "1/1 [==============================] - 0s 43ms/step - loss: 4.9629e-04 - accuracy: 1.0000 - val_loss: 0.4531 - val_accuracy: 0.9286\n",
            "Epoch 2948/4000\n",
            "1/1 [==============================] - 0s 48ms/step - loss: 4.9581e-04 - accuracy: 1.0000 - val_loss: 0.4531 - val_accuracy: 0.9286\n",
            "Epoch 2949/4000\n",
            "1/1 [==============================] - 0s 55ms/step - loss: 4.9529e-04 - accuracy: 1.0000 - val_loss: 0.4532 - val_accuracy: 0.9286\n",
            "Epoch 2950/4000\n",
            "1/1 [==============================] - 0s 50ms/step - loss: 4.9479e-04 - accuracy: 1.0000 - val_loss: 0.4533 - val_accuracy: 0.9286\n",
            "Epoch 2951/4000\n",
            "1/1 [==============================] - 0s 49ms/step - loss: 4.9432e-04 - accuracy: 1.0000 - val_loss: 0.4533 - val_accuracy: 0.9286\n",
            "Epoch 2952/4000\n",
            "1/1 [==============================] - 0s 55ms/step - loss: 4.9385e-04 - accuracy: 1.0000 - val_loss: 0.4534 - val_accuracy: 0.9286\n",
            "Epoch 2953/4000\n",
            "1/1 [==============================] - 0s 55ms/step - loss: 4.9337e-04 - accuracy: 1.0000 - val_loss: 0.4534 - val_accuracy: 0.9286\n",
            "Epoch 2954/4000\n",
            "1/1 [==============================] - 0s 63ms/step - loss: 4.9287e-04 - accuracy: 1.0000 - val_loss: 0.4535 - val_accuracy: 0.9286\n",
            "Epoch 2955/4000\n",
            "1/1 [==============================] - 0s 50ms/step - loss: 4.9237e-04 - accuracy: 1.0000 - val_loss: 0.4536 - val_accuracy: 0.9286\n",
            "Epoch 2956/4000\n",
            "1/1 [==============================] - 0s 56ms/step - loss: 4.9191e-04 - accuracy: 1.0000 - val_loss: 0.4536 - val_accuracy: 0.9286\n",
            "Epoch 2957/4000\n",
            "1/1 [==============================] - 0s 50ms/step - loss: 4.9142e-04 - accuracy: 1.0000 - val_loss: 0.4537 - val_accuracy: 0.9286\n",
            "Epoch 2958/4000\n",
            "1/1 [==============================] - 0s 49ms/step - loss: 4.9093e-04 - accuracy: 1.0000 - val_loss: 0.4538 - val_accuracy: 0.9286\n",
            "Epoch 2959/4000\n",
            "1/1 [==============================] - 0s 51ms/step - loss: 4.9043e-04 - accuracy: 1.0000 - val_loss: 0.4538 - val_accuracy: 0.9286\n",
            "Epoch 2960/4000\n",
            "1/1 [==============================] - 0s 48ms/step - loss: 4.8994e-04 - accuracy: 1.0000 - val_loss: 0.4539 - val_accuracy: 0.9286\n",
            "Epoch 2961/4000\n",
            "1/1 [==============================] - 0s 52ms/step - loss: 4.8946e-04 - accuracy: 1.0000 - val_loss: 0.4539 - val_accuracy: 0.9286\n",
            "Epoch 2962/4000\n",
            "1/1 [==============================] - 0s 37ms/step - loss: 4.8898e-04 - accuracy: 1.0000 - val_loss: 0.4540 - val_accuracy: 0.9286\n",
            "Epoch 2963/4000\n",
            "1/1 [==============================] - 0s 48ms/step - loss: 4.8851e-04 - accuracy: 1.0000 - val_loss: 0.4541 - val_accuracy: 0.9286\n",
            "Epoch 2964/4000\n",
            "1/1 [==============================] - 0s 36ms/step - loss: 4.8803e-04 - accuracy: 1.0000 - val_loss: 0.4542 - val_accuracy: 0.9286\n",
            "Epoch 2965/4000\n",
            "1/1 [==============================] - 0s 49ms/step - loss: 4.8752e-04 - accuracy: 1.0000 - val_loss: 0.4542 - val_accuracy: 0.9286\n",
            "Epoch 2966/4000\n",
            "1/1 [==============================] - 0s 52ms/step - loss: 4.8705e-04 - accuracy: 1.0000 - val_loss: 0.4543 - val_accuracy: 0.9286\n",
            "Epoch 2967/4000\n",
            "1/1 [==============================] - 0s 49ms/step - loss: 4.8660e-04 - accuracy: 1.0000 - val_loss: 0.4543 - val_accuracy: 0.9286\n",
            "Epoch 2968/4000\n",
            "1/1 [==============================] - 0s 50ms/step - loss: 4.8614e-04 - accuracy: 1.0000 - val_loss: 0.4544 - val_accuracy: 0.9286\n",
            "Epoch 2969/4000\n",
            "1/1 [==============================] - 0s 40ms/step - loss: 4.8565e-04 - accuracy: 1.0000 - val_loss: 0.4544 - val_accuracy: 0.9286\n",
            "Epoch 2970/4000\n",
            "1/1 [==============================] - 0s 62ms/step - loss: 4.8515e-04 - accuracy: 1.0000 - val_loss: 0.4545 - val_accuracy: 0.9286\n",
            "Epoch 2971/4000\n",
            "1/1 [==============================] - 0s 36ms/step - loss: 4.8467e-04 - accuracy: 1.0000 - val_loss: 0.4546 - val_accuracy: 0.9286\n",
            "Epoch 2972/4000\n",
            "1/1 [==============================] - 0s 47ms/step - loss: 4.8420e-04 - accuracy: 1.0000 - val_loss: 0.4546 - val_accuracy: 0.9286\n",
            "Epoch 2973/4000\n",
            "1/1 [==============================] - 0s 40ms/step - loss: 4.8375e-04 - accuracy: 1.0000 - val_loss: 0.4547 - val_accuracy: 0.9286\n",
            "Epoch 2974/4000\n",
            "1/1 [==============================] - 0s 51ms/step - loss: 4.8330e-04 - accuracy: 1.0000 - val_loss: 0.4548 - val_accuracy: 0.9286\n",
            "Epoch 2975/4000\n",
            "1/1 [==============================] - 0s 54ms/step - loss: 4.8280e-04 - accuracy: 1.0000 - val_loss: 0.4548 - val_accuracy: 0.9286\n",
            "Epoch 2976/4000\n",
            "1/1 [==============================] - 0s 47ms/step - loss: 4.8232e-04 - accuracy: 1.0000 - val_loss: 0.4549 - val_accuracy: 0.9286\n",
            "Epoch 2977/4000\n",
            "1/1 [==============================] - 0s 33ms/step - loss: 4.8183e-04 - accuracy: 1.0000 - val_loss: 0.4550 - val_accuracy: 0.9286\n",
            "Epoch 2978/4000\n",
            "1/1 [==============================] - 0s 39ms/step - loss: 4.8139e-04 - accuracy: 1.0000 - val_loss: 0.4550 - val_accuracy: 0.9286\n",
            "Epoch 2979/4000\n",
            "1/1 [==============================] - 0s 33ms/step - loss: 4.8092e-04 - accuracy: 1.0000 - val_loss: 0.4551 - val_accuracy: 0.9286\n",
            "Epoch 2980/4000\n",
            "1/1 [==============================] - 0s 45ms/step - loss: 4.8043e-04 - accuracy: 1.0000 - val_loss: 0.4552 - val_accuracy: 0.9143\n",
            "Epoch 2981/4000\n",
            "1/1 [==============================] - 0s 33ms/step - loss: 4.7997e-04 - accuracy: 1.0000 - val_loss: 0.4552 - val_accuracy: 0.9143\n",
            "Epoch 2982/4000\n",
            "1/1 [==============================] - 0s 34ms/step - loss: 4.7952e-04 - accuracy: 1.0000 - val_loss: 0.4553 - val_accuracy: 0.9143\n",
            "Epoch 2983/4000\n",
            "1/1 [==============================] - 0s 48ms/step - loss: 4.7906e-04 - accuracy: 1.0000 - val_loss: 0.4553 - val_accuracy: 0.9143\n",
            "Epoch 2984/4000\n",
            "1/1 [==============================] - 0s 38ms/step - loss: 4.7856e-04 - accuracy: 1.0000 - val_loss: 0.4554 - val_accuracy: 0.9143\n",
            "Epoch 2985/4000\n",
            "1/1 [==============================] - 0s 47ms/step - loss: 4.7808e-04 - accuracy: 1.0000 - val_loss: 0.4555 - val_accuracy: 0.9143\n",
            "Epoch 2986/4000\n",
            "1/1 [==============================] - 0s 49ms/step - loss: 4.7765e-04 - accuracy: 1.0000 - val_loss: 0.4555 - val_accuracy: 0.9143\n",
            "Epoch 2987/4000\n",
            "1/1 [==============================] - 0s 42ms/step - loss: 4.7721e-04 - accuracy: 1.0000 - val_loss: 0.4556 - val_accuracy: 0.9143\n",
            "Epoch 2988/4000\n",
            "1/1 [==============================] - 0s 38ms/step - loss: 4.7672e-04 - accuracy: 1.0000 - val_loss: 0.4557 - val_accuracy: 0.9143\n",
            "Epoch 2989/4000\n",
            "1/1 [==============================] - 0s 52ms/step - loss: 4.7623e-04 - accuracy: 1.0000 - val_loss: 0.4557 - val_accuracy: 0.9143\n",
            "Epoch 2990/4000\n",
            "1/1 [==============================] - 0s 55ms/step - loss: 4.7576e-04 - accuracy: 1.0000 - val_loss: 0.4558 - val_accuracy: 0.9143\n",
            "Epoch 2991/4000\n",
            "1/1 [==============================] - 0s 38ms/step - loss: 4.7530e-04 - accuracy: 1.0000 - val_loss: 0.4559 - val_accuracy: 0.9143\n",
            "Epoch 2992/4000\n",
            "1/1 [==============================] - 0s 38ms/step - loss: 4.7485e-04 - accuracy: 1.0000 - val_loss: 0.4559 - val_accuracy: 0.9143\n",
            "Epoch 2993/4000\n",
            "1/1 [==============================] - 0s 51ms/step - loss: 4.7439e-04 - accuracy: 1.0000 - val_loss: 0.4560 - val_accuracy: 0.9143\n",
            "Epoch 2994/4000\n",
            "1/1 [==============================] - 0s 48ms/step - loss: 4.7392e-04 - accuracy: 1.0000 - val_loss: 0.4560 - val_accuracy: 0.9143\n",
            "Epoch 2995/4000\n",
            "1/1 [==============================] - 0s 56ms/step - loss: 4.7345e-04 - accuracy: 1.0000 - val_loss: 0.4561 - val_accuracy: 0.9143\n",
            "Epoch 2996/4000\n",
            "1/1 [==============================] - 0s 50ms/step - loss: 4.7297e-04 - accuracy: 1.0000 - val_loss: 0.4562 - val_accuracy: 0.9143\n",
            "Epoch 2997/4000\n",
            "1/1 [==============================] - 0s 47ms/step - loss: 4.7251e-04 - accuracy: 1.0000 - val_loss: 0.4562 - val_accuracy: 0.9143\n",
            "Epoch 2998/4000\n",
            "1/1 [==============================] - 0s 33ms/step - loss: 4.7207e-04 - accuracy: 1.0000 - val_loss: 0.4563 - val_accuracy: 0.9143\n",
            "Epoch 2999/4000\n",
            "1/1 [==============================] - 0s 48ms/step - loss: 4.7159e-04 - accuracy: 1.0000 - val_loss: 0.4564 - val_accuracy: 0.9143\n",
            "Epoch 3000/4000\n",
            "1/1 [==============================] - 0s 35ms/step - loss: 4.7114e-04 - accuracy: 1.0000 - val_loss: 0.4564 - val_accuracy: 0.9143\n",
            "Epoch 3001/4000\n",
            "1/1 [==============================] - 0s 47ms/step - loss: 4.7070e-04 - accuracy: 1.0000 - val_loss: 0.4565 - val_accuracy: 0.9143\n",
            "Epoch 3002/4000\n",
            "1/1 [==============================] - 0s 48ms/step - loss: 4.7024e-04 - accuracy: 1.0000 - val_loss: 0.4565 - val_accuracy: 0.9143\n",
            "Epoch 3003/4000\n",
            "1/1 [==============================] - 0s 50ms/step - loss: 4.6978e-04 - accuracy: 1.0000 - val_loss: 0.4566 - val_accuracy: 0.9143\n",
            "Epoch 3004/4000\n",
            "1/1 [==============================] - 0s 50ms/step - loss: 4.6932e-04 - accuracy: 1.0000 - val_loss: 0.4567 - val_accuracy: 0.9143\n",
            "Epoch 3005/4000\n",
            "1/1 [==============================] - 0s 41ms/step - loss: 4.6887e-04 - accuracy: 1.0000 - val_loss: 0.4567 - val_accuracy: 0.9143\n",
            "Epoch 3006/4000\n",
            "1/1 [==============================] - 0s 50ms/step - loss: 4.6840e-04 - accuracy: 1.0000 - val_loss: 0.4568 - val_accuracy: 0.9143\n",
            "Epoch 3007/4000\n",
            "1/1 [==============================] - 0s 49ms/step - loss: 4.6796e-04 - accuracy: 1.0000 - val_loss: 0.4569 - val_accuracy: 0.9143\n",
            "Epoch 3008/4000\n",
            "1/1 [==============================] - 0s 48ms/step - loss: 4.6750e-04 - accuracy: 1.0000 - val_loss: 0.4569 - val_accuracy: 0.9143\n",
            "Epoch 3009/4000\n",
            "1/1 [==============================] - 0s 33ms/step - loss: 4.6704e-04 - accuracy: 1.0000 - val_loss: 0.4570 - val_accuracy: 0.9143\n",
            "Epoch 3010/4000\n",
            "1/1 [==============================] - 0s 47ms/step - loss: 4.6659e-04 - accuracy: 1.0000 - val_loss: 0.4570 - val_accuracy: 0.9143\n",
            "Epoch 3011/4000\n",
            "1/1 [==============================] - 0s 50ms/step - loss: 4.6612e-04 - accuracy: 1.0000 - val_loss: 0.4571 - val_accuracy: 0.9143\n",
            "Epoch 3012/4000\n",
            "1/1 [==============================] - 0s 49ms/step - loss: 4.6567e-04 - accuracy: 1.0000 - val_loss: 0.4572 - val_accuracy: 0.9143\n",
            "Epoch 3013/4000\n",
            "1/1 [==============================] - 0s 53ms/step - loss: 4.6522e-04 - accuracy: 1.0000 - val_loss: 0.4572 - val_accuracy: 0.9143\n",
            "Epoch 3014/4000\n",
            "1/1 [==============================] - 0s 40ms/step - loss: 4.6476e-04 - accuracy: 1.0000 - val_loss: 0.4573 - val_accuracy: 0.9143\n",
            "Epoch 3015/4000\n",
            "1/1 [==============================] - 0s 48ms/step - loss: 4.6431e-04 - accuracy: 1.0000 - val_loss: 0.4574 - val_accuracy: 0.9143\n",
            "Epoch 3016/4000\n",
            "1/1 [==============================] - 0s 51ms/step - loss: 4.6387e-04 - accuracy: 1.0000 - val_loss: 0.4574 - val_accuracy: 0.9143\n",
            "Epoch 3017/4000\n",
            "1/1 [==============================] - 0s 39ms/step - loss: 4.6342e-04 - accuracy: 1.0000 - val_loss: 0.4575 - val_accuracy: 0.9143\n",
            "Epoch 3018/4000\n",
            "1/1 [==============================] - 0s 61ms/step - loss: 4.6296e-04 - accuracy: 1.0000 - val_loss: 0.4575 - val_accuracy: 0.9143\n",
            "Epoch 3019/4000\n",
            "1/1 [==============================] - 0s 56ms/step - loss: 4.6251e-04 - accuracy: 1.0000 - val_loss: 0.4576 - val_accuracy: 0.9143\n",
            "Epoch 3020/4000\n",
            "1/1 [==============================] - 0s 33ms/step - loss: 4.6204e-04 - accuracy: 1.0000 - val_loss: 0.4577 - val_accuracy: 0.9143\n",
            "Epoch 3021/4000\n",
            "1/1 [==============================] - 0s 47ms/step - loss: 4.6162e-04 - accuracy: 1.0000 - val_loss: 0.4577 - val_accuracy: 0.9143\n",
            "Epoch 3022/4000\n",
            "1/1 [==============================] - 0s 48ms/step - loss: 4.6120e-04 - accuracy: 1.0000 - val_loss: 0.4578 - val_accuracy: 0.9143\n",
            "Epoch 3023/4000\n",
            "1/1 [==============================] - 0s 49ms/step - loss: 4.6073e-04 - accuracy: 1.0000 - val_loss: 0.4578 - val_accuracy: 0.9143\n",
            "Epoch 3024/4000\n",
            "1/1 [==============================] - 0s 52ms/step - loss: 4.6026e-04 - accuracy: 1.0000 - val_loss: 0.4579 - val_accuracy: 0.9143\n",
            "Epoch 3025/4000\n",
            "1/1 [==============================] - 0s 58ms/step - loss: 4.5983e-04 - accuracy: 1.0000 - val_loss: 0.4580 - val_accuracy: 0.9143\n",
            "Epoch 3026/4000\n",
            "1/1 [==============================] - 0s 50ms/step - loss: 4.5940e-04 - accuracy: 1.0000 - val_loss: 0.4581 - val_accuracy: 0.9143\n",
            "Epoch 3027/4000\n",
            "1/1 [==============================] - 0s 51ms/step - loss: 4.5896e-04 - accuracy: 1.0000 - val_loss: 0.4581 - val_accuracy: 0.9143\n",
            "Epoch 3028/4000\n",
            "1/1 [==============================] - 0s 49ms/step - loss: 4.5850e-04 - accuracy: 1.0000 - val_loss: 0.4582 - val_accuracy: 0.9143\n",
            "Epoch 3029/4000\n",
            "1/1 [==============================] - 0s 46ms/step - loss: 4.5804e-04 - accuracy: 1.0000 - val_loss: 0.4582 - val_accuracy: 0.9143\n",
            "Epoch 3030/4000\n",
            "1/1 [==============================] - 0s 48ms/step - loss: 4.5763e-04 - accuracy: 1.0000 - val_loss: 0.4583 - val_accuracy: 0.9143\n",
            "Epoch 3031/4000\n",
            "1/1 [==============================] - 0s 89ms/step - loss: 4.5720e-04 - accuracy: 1.0000 - val_loss: 0.4584 - val_accuracy: 0.9143\n",
            "Epoch 3032/4000\n",
            "1/1 [==============================] - 0s 56ms/step - loss: 4.5674e-04 - accuracy: 1.0000 - val_loss: 0.4584 - val_accuracy: 0.9143\n",
            "Epoch 3033/4000\n",
            "1/1 [==============================] - 0s 48ms/step - loss: 4.5628e-04 - accuracy: 1.0000 - val_loss: 0.4585 - val_accuracy: 0.9143\n",
            "Epoch 3034/4000\n",
            "1/1 [==============================] - 0s 48ms/step - loss: 4.5586e-04 - accuracy: 1.0000 - val_loss: 0.4585 - val_accuracy: 0.9143\n",
            "Epoch 3035/4000\n",
            "1/1 [==============================] - 0s 47ms/step - loss: 4.5543e-04 - accuracy: 1.0000 - val_loss: 0.4586 - val_accuracy: 0.9143\n",
            "Epoch 3036/4000\n",
            "1/1 [==============================] - 0s 40ms/step - loss: 4.5500e-04 - accuracy: 1.0000 - val_loss: 0.4587 - val_accuracy: 0.9143\n",
            "Epoch 3037/4000\n",
            "1/1 [==============================] - 0s 46ms/step - loss: 4.5455e-04 - accuracy: 1.0000 - val_loss: 0.4587 - val_accuracy: 0.9143\n",
            "Epoch 3038/4000\n",
            "1/1 [==============================] - 0s 49ms/step - loss: 4.5410e-04 - accuracy: 1.0000 - val_loss: 0.4588 - val_accuracy: 0.9143\n",
            "Epoch 3039/4000\n",
            "1/1 [==============================] - 0s 48ms/step - loss: 4.5369e-04 - accuracy: 1.0000 - val_loss: 0.4589 - val_accuracy: 0.9143\n",
            "Epoch 3040/4000\n",
            "1/1 [==============================] - 0s 35ms/step - loss: 4.5326e-04 - accuracy: 1.0000 - val_loss: 0.4589 - val_accuracy: 0.9143\n",
            "Epoch 3041/4000\n",
            "1/1 [==============================] - 0s 50ms/step - loss: 4.5281e-04 - accuracy: 1.0000 - val_loss: 0.4590 - val_accuracy: 0.9143\n",
            "Epoch 3042/4000\n",
            "1/1 [==============================] - 0s 48ms/step - loss: 4.5236e-04 - accuracy: 1.0000 - val_loss: 0.4591 - val_accuracy: 0.9143\n",
            "Epoch 3043/4000\n",
            "1/1 [==============================] - 0s 51ms/step - loss: 4.5193e-04 - accuracy: 1.0000 - val_loss: 0.4591 - val_accuracy: 0.9143\n",
            "Epoch 3044/4000\n",
            "1/1 [==============================] - 0s 50ms/step - loss: 4.5149e-04 - accuracy: 1.0000 - val_loss: 0.4592 - val_accuracy: 0.9143\n",
            "Epoch 3045/4000\n",
            "1/1 [==============================] - 0s 48ms/step - loss: 4.5107e-04 - accuracy: 1.0000 - val_loss: 0.4592 - val_accuracy: 0.9143\n",
            "Epoch 3046/4000\n",
            "1/1 [==============================] - 0s 48ms/step - loss: 4.5064e-04 - accuracy: 1.0000 - val_loss: 0.4593 - val_accuracy: 0.9143\n",
            "Epoch 3047/4000\n",
            "1/1 [==============================] - 0s 90ms/step - loss: 4.5020e-04 - accuracy: 1.0000 - val_loss: 0.4594 - val_accuracy: 0.9143\n",
            "Epoch 3048/4000\n",
            "1/1 [==============================] - 0s 35ms/step - loss: 4.4978e-04 - accuracy: 1.0000 - val_loss: 0.4594 - val_accuracy: 0.9143\n",
            "Epoch 3049/4000\n",
            "1/1 [==============================] - 0s 42ms/step - loss: 4.4935e-04 - accuracy: 1.0000 - val_loss: 0.4595 - val_accuracy: 0.9143\n",
            "Epoch 3050/4000\n",
            "1/1 [==============================] - 0s 33ms/step - loss: 4.4889e-04 - accuracy: 1.0000 - val_loss: 0.4595 - val_accuracy: 0.9143\n",
            "Epoch 3051/4000\n",
            "1/1 [==============================] - 0s 48ms/step - loss: 4.4848e-04 - accuracy: 1.0000 - val_loss: 0.4596 - val_accuracy: 0.9143\n",
            "Epoch 3052/4000\n",
            "1/1 [==============================] - 0s 51ms/step - loss: 4.4808e-04 - accuracy: 1.0000 - val_loss: 0.4597 - val_accuracy: 0.9143\n",
            "Epoch 3053/4000\n",
            "1/1 [==============================] - 0s 35ms/step - loss: 4.4765e-04 - accuracy: 1.0000 - val_loss: 0.4597 - val_accuracy: 0.9143\n",
            "Epoch 3054/4000\n",
            "1/1 [==============================] - 0s 64ms/step - loss: 4.4719e-04 - accuracy: 1.0000 - val_loss: 0.4598 - val_accuracy: 0.9143\n",
            "Epoch 3055/4000\n",
            "1/1 [==============================] - 0s 53ms/step - loss: 4.4675e-04 - accuracy: 1.0000 - val_loss: 0.4599 - val_accuracy: 0.9143\n",
            "Epoch 3056/4000\n",
            "1/1 [==============================] - 0s 33ms/step - loss: 4.4630e-04 - accuracy: 1.0000 - val_loss: 0.4599 - val_accuracy: 0.9143\n",
            "Epoch 3057/4000\n",
            "1/1 [==============================] - 0s 48ms/step - loss: 4.4591e-04 - accuracy: 1.0000 - val_loss: 0.4600 - val_accuracy: 0.9143\n",
            "Epoch 3058/4000\n",
            "1/1 [==============================] - 0s 57ms/step - loss: 4.4549e-04 - accuracy: 1.0000 - val_loss: 0.4600 - val_accuracy: 0.9143\n",
            "Epoch 3059/4000\n",
            "1/1 [==============================] - 0s 47ms/step - loss: 4.4506e-04 - accuracy: 1.0000 - val_loss: 0.4601 - val_accuracy: 0.9143\n",
            "Epoch 3060/4000\n",
            "1/1 [==============================] - 0s 32ms/step - loss: 4.4461e-04 - accuracy: 1.0000 - val_loss: 0.4602 - val_accuracy: 0.9143\n",
            "Epoch 3061/4000\n",
            "1/1 [==============================] - 0s 37ms/step - loss: 4.4418e-04 - accuracy: 1.0000 - val_loss: 0.4602 - val_accuracy: 0.9143\n",
            "Epoch 3062/4000\n",
            "1/1 [==============================] - 0s 50ms/step - loss: 4.4374e-04 - accuracy: 1.0000 - val_loss: 0.4603 - val_accuracy: 0.9143\n",
            "Epoch 3063/4000\n",
            "1/1 [==============================] - 0s 47ms/step - loss: 4.4335e-04 - accuracy: 1.0000 - val_loss: 0.4604 - val_accuracy: 0.9143\n",
            "Epoch 3064/4000\n",
            "1/1 [==============================] - 0s 37ms/step - loss: 4.4293e-04 - accuracy: 1.0000 - val_loss: 0.4604 - val_accuracy: 0.9143\n",
            "Epoch 3065/4000\n",
            "1/1 [==============================] - 0s 49ms/step - loss: 4.4248e-04 - accuracy: 1.0000 - val_loss: 0.4605 - val_accuracy: 0.9143\n",
            "Epoch 3066/4000\n",
            "1/1 [==============================] - 0s 53ms/step - loss: 4.4206e-04 - accuracy: 1.0000 - val_loss: 0.4605 - val_accuracy: 0.9143\n",
            "Epoch 3067/4000\n",
            "1/1 [==============================] - 0s 47ms/step - loss: 4.4164e-04 - accuracy: 1.0000 - val_loss: 0.4606 - val_accuracy: 0.9143\n",
            "Epoch 3068/4000\n",
            "1/1 [==============================] - 0s 51ms/step - loss: 4.4121e-04 - accuracy: 1.0000 - val_loss: 0.4607 - val_accuracy: 0.9143\n",
            "Epoch 3069/4000\n",
            "1/1 [==============================] - 0s 51ms/step - loss: 4.4080e-04 - accuracy: 1.0000 - val_loss: 0.4607 - val_accuracy: 0.9143\n",
            "Epoch 3070/4000\n",
            "1/1 [==============================] - 0s 41ms/step - loss: 4.4037e-04 - accuracy: 1.0000 - val_loss: 0.4608 - val_accuracy: 0.9143\n",
            "Epoch 3071/4000\n",
            "1/1 [==============================] - 0s 39ms/step - loss: 4.3996e-04 - accuracy: 1.0000 - val_loss: 0.4609 - val_accuracy: 0.9143\n",
            "Epoch 3072/4000\n",
            "1/1 [==============================] - 0s 48ms/step - loss: 4.3954e-04 - accuracy: 1.0000 - val_loss: 0.4609 - val_accuracy: 0.9143\n",
            "Epoch 3073/4000\n",
            "1/1 [==============================] - 0s 51ms/step - loss: 4.3913e-04 - accuracy: 1.0000 - val_loss: 0.4610 - val_accuracy: 0.9143\n",
            "Epoch 3074/4000\n",
            "1/1 [==============================] - 0s 50ms/step - loss: 4.3870e-04 - accuracy: 1.0000 - val_loss: 0.4610 - val_accuracy: 0.9143\n",
            "Epoch 3075/4000\n",
            "1/1 [==============================] - 0s 50ms/step - loss: 4.3827e-04 - accuracy: 1.0000 - val_loss: 0.4611 - val_accuracy: 0.9143\n",
            "Epoch 3076/4000\n",
            "1/1 [==============================] - 0s 34ms/step - loss: 4.3787e-04 - accuracy: 1.0000 - val_loss: 0.4612 - val_accuracy: 0.9143\n",
            "Epoch 3077/4000\n",
            "1/1 [==============================] - 0s 53ms/step - loss: 4.3744e-04 - accuracy: 1.0000 - val_loss: 0.4612 - val_accuracy: 0.9143\n",
            "Epoch 3078/4000\n",
            "1/1 [==============================] - 0s 52ms/step - loss: 4.3703e-04 - accuracy: 1.0000 - val_loss: 0.4613 - val_accuracy: 0.9143\n",
            "Epoch 3079/4000\n",
            "1/1 [==============================] - 0s 51ms/step - loss: 4.3662e-04 - accuracy: 1.0000 - val_loss: 0.4613 - val_accuracy: 0.9143\n",
            "Epoch 3080/4000\n",
            "1/1 [==============================] - 0s 49ms/step - loss: 4.3620e-04 - accuracy: 1.0000 - val_loss: 0.4614 - val_accuracy: 0.9143\n",
            "Epoch 3081/4000\n",
            "1/1 [==============================] - 0s 54ms/step - loss: 4.3578e-04 - accuracy: 1.0000 - val_loss: 0.4615 - val_accuracy: 0.9143\n",
            "Epoch 3082/4000\n",
            "1/1 [==============================] - 0s 35ms/step - loss: 4.3537e-04 - accuracy: 1.0000 - val_loss: 0.4615 - val_accuracy: 0.9143\n",
            "Epoch 3083/4000\n",
            "1/1 [==============================] - 0s 47ms/step - loss: 4.3496e-04 - accuracy: 1.0000 - val_loss: 0.4616 - val_accuracy: 0.9143\n",
            "Epoch 3084/4000\n",
            "1/1 [==============================] - 0s 54ms/step - loss: 4.3456e-04 - accuracy: 1.0000 - val_loss: 0.4617 - val_accuracy: 0.9143\n",
            "Epoch 3085/4000\n",
            "1/1 [==============================] - 0s 46ms/step - loss: 4.3414e-04 - accuracy: 1.0000 - val_loss: 0.4617 - val_accuracy: 0.9143\n",
            "Epoch 3086/4000\n",
            "1/1 [==============================] - 0s 39ms/step - loss: 4.3371e-04 - accuracy: 1.0000 - val_loss: 0.4618 - val_accuracy: 0.9143\n",
            "Epoch 3087/4000\n",
            "1/1 [==============================] - 0s 37ms/step - loss: 4.3331e-04 - accuracy: 1.0000 - val_loss: 0.4618 - val_accuracy: 0.9143\n",
            "Epoch 3088/4000\n",
            "1/1 [==============================] - 0s 47ms/step - loss: 4.3293e-04 - accuracy: 1.0000 - val_loss: 0.4619 - val_accuracy: 0.9143\n",
            "Epoch 3089/4000\n",
            "1/1 [==============================] - 0s 47ms/step - loss: 4.3252e-04 - accuracy: 1.0000 - val_loss: 0.4620 - val_accuracy: 0.9143\n",
            "Epoch 3090/4000\n",
            "1/1 [==============================] - 0s 47ms/step - loss: 4.3209e-04 - accuracy: 1.0000 - val_loss: 0.4620 - val_accuracy: 0.9143\n",
            "Epoch 3091/4000\n",
            "1/1 [==============================] - 0s 47ms/step - loss: 4.3165e-04 - accuracy: 1.0000 - val_loss: 0.4621 - val_accuracy: 0.9143\n",
            "Epoch 3092/4000\n",
            "1/1 [==============================] - 0s 50ms/step - loss: 4.3127e-04 - accuracy: 1.0000 - val_loss: 0.4621 - val_accuracy: 0.9143\n",
            "Epoch 3093/4000\n",
            "1/1 [==============================] - 0s 47ms/step - loss: 4.3087e-04 - accuracy: 1.0000 - val_loss: 0.4622 - val_accuracy: 0.9143\n",
            "Epoch 3094/4000\n",
            "1/1 [==============================] - 0s 46ms/step - loss: 4.3047e-04 - accuracy: 1.0000 - val_loss: 0.4623 - val_accuracy: 0.9143\n",
            "Epoch 3095/4000\n",
            "1/1 [==============================] - 0s 52ms/step - loss: 4.3005e-04 - accuracy: 1.0000 - val_loss: 0.4623 - val_accuracy: 0.9143\n",
            "Epoch 3096/4000\n",
            "1/1 [==============================] - 0s 48ms/step - loss: 4.2962e-04 - accuracy: 1.0000 - val_loss: 0.4624 - val_accuracy: 0.9143\n",
            "Epoch 3097/4000\n",
            "1/1 [==============================] - 0s 49ms/step - loss: 4.2922e-04 - accuracy: 1.0000 - val_loss: 0.4625 - val_accuracy: 0.9143\n",
            "Epoch 3098/4000\n",
            "1/1 [==============================] - 0s 46ms/step - loss: 4.2883e-04 - accuracy: 1.0000 - val_loss: 0.4625 - val_accuracy: 0.9143\n",
            "Epoch 3099/4000\n",
            "1/1 [==============================] - 0s 38ms/step - loss: 4.2844e-04 - accuracy: 1.0000 - val_loss: 0.4626 - val_accuracy: 0.9143\n",
            "Epoch 3100/4000\n",
            "1/1 [==============================] - 0s 47ms/step - loss: 4.2801e-04 - accuracy: 1.0000 - val_loss: 0.4626 - val_accuracy: 0.9143\n",
            "Epoch 3101/4000\n",
            "1/1 [==============================] - 0s 47ms/step - loss: 4.2757e-04 - accuracy: 1.0000 - val_loss: 0.4627 - val_accuracy: 0.9143\n",
            "Epoch 3102/4000\n",
            "1/1 [==============================] - 0s 47ms/step - loss: 4.2718e-04 - accuracy: 1.0000 - val_loss: 0.4628 - val_accuracy: 0.9143\n",
            "Epoch 3103/4000\n",
            "1/1 [==============================] - 0s 48ms/step - loss: 4.2678e-04 - accuracy: 1.0000 - val_loss: 0.4628 - val_accuracy: 0.9143\n",
            "Epoch 3104/4000\n",
            "1/1 [==============================] - 0s 55ms/step - loss: 4.2637e-04 - accuracy: 1.0000 - val_loss: 0.4629 - val_accuracy: 0.9143\n",
            "Epoch 3105/4000\n",
            "1/1 [==============================] - 0s 47ms/step - loss: 4.2598e-04 - accuracy: 1.0000 - val_loss: 0.4629 - val_accuracy: 0.9143\n",
            "Epoch 3106/4000\n",
            "1/1 [==============================] - 0s 50ms/step - loss: 4.2556e-04 - accuracy: 1.0000 - val_loss: 0.4630 - val_accuracy: 0.9143\n",
            "Epoch 3107/4000\n",
            "1/1 [==============================] - 0s 46ms/step - loss: 4.2515e-04 - accuracy: 1.0000 - val_loss: 0.4631 - val_accuracy: 0.9143\n",
            "Epoch 3108/4000\n",
            "1/1 [==============================] - 0s 32ms/step - loss: 4.2475e-04 - accuracy: 1.0000 - val_loss: 0.4631 - val_accuracy: 0.9143\n",
            "Epoch 3109/4000\n",
            "1/1 [==============================] - 0s 48ms/step - loss: 4.2436e-04 - accuracy: 1.0000 - val_loss: 0.4632 - val_accuracy: 0.9143\n",
            "Epoch 3110/4000\n",
            "1/1 [==============================] - 0s 49ms/step - loss: 4.2397e-04 - accuracy: 1.0000 - val_loss: 0.4633 - val_accuracy: 0.9143\n",
            "Epoch 3111/4000\n",
            "1/1 [==============================] - 0s 50ms/step - loss: 4.2356e-04 - accuracy: 1.0000 - val_loss: 0.4633 - val_accuracy: 0.9143\n",
            "Epoch 3112/4000\n",
            "1/1 [==============================] - 0s 48ms/step - loss: 4.2316e-04 - accuracy: 1.0000 - val_loss: 0.4634 - val_accuracy: 0.9143\n",
            "Epoch 3113/4000\n",
            "1/1 [==============================] - 0s 48ms/step - loss: 4.2276e-04 - accuracy: 1.0000 - val_loss: 0.4634 - val_accuracy: 0.9143\n",
            "Epoch 3114/4000\n",
            "1/1 [==============================] - 0s 51ms/step - loss: 4.2237e-04 - accuracy: 1.0000 - val_loss: 0.4635 - val_accuracy: 0.9143\n",
            "Epoch 3115/4000\n",
            "1/1 [==============================] - 0s 60ms/step - loss: 4.2196e-04 - accuracy: 1.0000 - val_loss: 0.4636 - val_accuracy: 0.9143\n",
            "Epoch 3116/4000\n",
            "1/1 [==============================] - 0s 36ms/step - loss: 4.2157e-04 - accuracy: 1.0000 - val_loss: 0.4636 - val_accuracy: 0.9143\n",
            "Epoch 3117/4000\n",
            "1/1 [==============================] - 0s 47ms/step - loss: 4.2117e-04 - accuracy: 1.0000 - val_loss: 0.4637 - val_accuracy: 0.9143\n",
            "Epoch 3118/4000\n",
            "1/1 [==============================] - 0s 37ms/step - loss: 4.2077e-04 - accuracy: 1.0000 - val_loss: 0.4637 - val_accuracy: 0.9143\n",
            "Epoch 3119/4000\n",
            "1/1 [==============================] - 0s 46ms/step - loss: 4.2039e-04 - accuracy: 1.0000 - val_loss: 0.4638 - val_accuracy: 0.9143\n",
            "Epoch 3120/4000\n",
            "1/1 [==============================] - 0s 59ms/step - loss: 4.1999e-04 - accuracy: 1.0000 - val_loss: 0.4639 - val_accuracy: 0.9143\n",
            "Epoch 3121/4000\n",
            "1/1 [==============================] - 0s 47ms/step - loss: 4.1959e-04 - accuracy: 1.0000 - val_loss: 0.4639 - val_accuracy: 0.9143\n",
            "Epoch 3122/4000\n",
            "1/1 [==============================] - 0s 36ms/step - loss: 4.1919e-04 - accuracy: 1.0000 - val_loss: 0.4640 - val_accuracy: 0.9143\n",
            "Epoch 3123/4000\n",
            "1/1 [==============================] - 0s 36ms/step - loss: 4.1880e-04 - accuracy: 1.0000 - val_loss: 0.4641 - val_accuracy: 0.9143\n",
            "Epoch 3124/4000\n",
            "1/1 [==============================] - 0s 47ms/step - loss: 4.1840e-04 - accuracy: 1.0000 - val_loss: 0.4641 - val_accuracy: 0.9143\n",
            "Epoch 3125/4000\n",
            "1/1 [==============================] - 0s 53ms/step - loss: 4.1801e-04 - accuracy: 1.0000 - val_loss: 0.4642 - val_accuracy: 0.9143\n",
            "Epoch 3126/4000\n",
            "1/1 [==============================] - 0s 48ms/step - loss: 4.1764e-04 - accuracy: 1.0000 - val_loss: 0.4642 - val_accuracy: 0.9143\n",
            "Epoch 3127/4000\n",
            "1/1 [==============================] - 0s 48ms/step - loss: 4.1723e-04 - accuracy: 1.0000 - val_loss: 0.4643 - val_accuracy: 0.9143\n",
            "Epoch 3128/4000\n",
            "1/1 [==============================] - 0s 35ms/step - loss: 4.1682e-04 - accuracy: 1.0000 - val_loss: 0.4644 - val_accuracy: 0.9143\n",
            "Epoch 3129/4000\n",
            "1/1 [==============================] - 0s 33ms/step - loss: 4.1643e-04 - accuracy: 1.0000 - val_loss: 0.4644 - val_accuracy: 0.9143\n",
            "Epoch 3130/4000\n",
            "1/1 [==============================] - 0s 47ms/step - loss: 4.1605e-04 - accuracy: 1.0000 - val_loss: 0.4645 - val_accuracy: 0.9143\n",
            "Epoch 3131/4000\n",
            "1/1 [==============================] - 0s 46ms/step - loss: 4.1565e-04 - accuracy: 1.0000 - val_loss: 0.4645 - val_accuracy: 0.9143\n",
            "Epoch 3132/4000\n",
            "1/1 [==============================] - 0s 48ms/step - loss: 4.1527e-04 - accuracy: 1.0000 - val_loss: 0.4646 - val_accuracy: 0.9143\n",
            "Epoch 3133/4000\n",
            "1/1 [==============================] - 0s 48ms/step - loss: 4.1489e-04 - accuracy: 1.0000 - val_loss: 0.4647 - val_accuracy: 0.9143\n",
            "Epoch 3134/4000\n",
            "1/1 [==============================] - 0s 34ms/step - loss: 4.1451e-04 - accuracy: 1.0000 - val_loss: 0.4647 - val_accuracy: 0.9143\n",
            "Epoch 3135/4000\n",
            "1/1 [==============================] - 0s 35ms/step - loss: 4.1413e-04 - accuracy: 1.0000 - val_loss: 0.4648 - val_accuracy: 0.9143\n",
            "Epoch 3136/4000\n",
            "1/1 [==============================] - 0s 43ms/step - loss: 4.1374e-04 - accuracy: 1.0000 - val_loss: 0.4648 - val_accuracy: 0.9143\n",
            "Epoch 3137/4000\n",
            "1/1 [==============================] - 0s 48ms/step - loss: 4.1335e-04 - accuracy: 1.0000 - val_loss: 0.4649 - val_accuracy: 0.9143\n",
            "Epoch 3138/4000\n",
            "1/1 [==============================] - 0s 47ms/step - loss: 4.1296e-04 - accuracy: 1.0000 - val_loss: 0.4650 - val_accuracy: 0.9143\n",
            "Epoch 3139/4000\n",
            "1/1 [==============================] - 0s 46ms/step - loss: 4.1257e-04 - accuracy: 1.0000 - val_loss: 0.4650 - val_accuracy: 0.9143\n",
            "Epoch 3140/4000\n",
            "1/1 [==============================] - 0s 33ms/step - loss: 4.1217e-04 - accuracy: 1.0000 - val_loss: 0.4651 - val_accuracy: 0.9143\n",
            "Epoch 3141/4000\n",
            "1/1 [==============================] - 0s 49ms/step - loss: 4.1178e-04 - accuracy: 1.0000 - val_loss: 0.4652 - val_accuracy: 0.9143\n",
            "Epoch 3142/4000\n",
            "1/1 [==============================] - 0s 51ms/step - loss: 4.1141e-04 - accuracy: 1.0000 - val_loss: 0.4652 - val_accuracy: 0.9143\n",
            "Epoch 3143/4000\n",
            "1/1 [==============================] - 0s 37ms/step - loss: 4.1102e-04 - accuracy: 1.0000 - val_loss: 0.4653 - val_accuracy: 0.9143\n",
            "Epoch 3144/4000\n",
            "1/1 [==============================] - 0s 41ms/step - loss: 4.1065e-04 - accuracy: 1.0000 - val_loss: 0.4653 - val_accuracy: 0.9143\n",
            "Epoch 3145/4000\n",
            "1/1 [==============================] - 0s 47ms/step - loss: 4.1026e-04 - accuracy: 1.0000 - val_loss: 0.4654 - val_accuracy: 0.9143\n",
            "Epoch 3146/4000\n",
            "1/1 [==============================] - 0s 42ms/step - loss: 4.0987e-04 - accuracy: 1.0000 - val_loss: 0.4654 - val_accuracy: 0.9143\n",
            "Epoch 3147/4000\n",
            "1/1 [==============================] - 0s 49ms/step - loss: 4.0949e-04 - accuracy: 1.0000 - val_loss: 0.4655 - val_accuracy: 0.9143\n",
            "Epoch 3148/4000\n",
            "1/1 [==============================] - 0s 47ms/step - loss: 4.0911e-04 - accuracy: 1.0000 - val_loss: 0.4656 - val_accuracy: 0.9143\n",
            "Epoch 3149/4000\n",
            "1/1 [==============================] - 0s 42ms/step - loss: 4.0874e-04 - accuracy: 1.0000 - val_loss: 0.4656 - val_accuracy: 0.9143\n",
            "Epoch 3150/4000\n",
            "1/1 [==============================] - 0s 50ms/step - loss: 4.0836e-04 - accuracy: 1.0000 - val_loss: 0.4657 - val_accuracy: 0.9143\n",
            "Epoch 3151/4000\n",
            "1/1 [==============================] - 0s 48ms/step - loss: 4.0798e-04 - accuracy: 1.0000 - val_loss: 0.4657 - val_accuracy: 0.9143\n",
            "Epoch 3152/4000\n",
            "1/1 [==============================] - 0s 36ms/step - loss: 4.0758e-04 - accuracy: 1.0000 - val_loss: 0.4658 - val_accuracy: 0.9143\n",
            "Epoch 3153/4000\n",
            "1/1 [==============================] - 0s 48ms/step - loss: 4.0722e-04 - accuracy: 1.0000 - val_loss: 0.4659 - val_accuracy: 0.9143\n",
            "Epoch 3154/4000\n",
            "1/1 [==============================] - 0s 35ms/step - loss: 4.0684e-04 - accuracy: 1.0000 - val_loss: 0.4659 - val_accuracy: 0.9143\n",
            "Epoch 3155/4000\n",
            "1/1 [==============================] - 0s 44ms/step - loss: 4.0645e-04 - accuracy: 1.0000 - val_loss: 0.4660 - val_accuracy: 0.9143\n",
            "Epoch 3156/4000\n",
            "1/1 [==============================] - 0s 48ms/step - loss: 4.0609e-04 - accuracy: 1.0000 - val_loss: 0.4661 - val_accuracy: 0.9143\n",
            "Epoch 3157/4000\n",
            "1/1 [==============================] - 0s 46ms/step - loss: 4.0570e-04 - accuracy: 1.0000 - val_loss: 0.4661 - val_accuracy: 0.9143\n",
            "Epoch 3158/4000\n",
            "1/1 [==============================] - 0s 52ms/step - loss: 4.0536e-04 - accuracy: 1.0000 - val_loss: 0.4662 - val_accuracy: 0.9143\n",
            "Epoch 3159/4000\n",
            "1/1 [==============================] - 0s 49ms/step - loss: 4.0498e-04 - accuracy: 1.0000 - val_loss: 0.4662 - val_accuracy: 0.9143\n",
            "Epoch 3160/4000\n",
            "1/1 [==============================] - 0s 35ms/step - loss: 4.0459e-04 - accuracy: 1.0000 - val_loss: 0.4663 - val_accuracy: 0.9143\n",
            "Epoch 3161/4000\n",
            "1/1 [==============================] - 0s 50ms/step - loss: 4.0422e-04 - accuracy: 1.0000 - val_loss: 0.4664 - val_accuracy: 0.9143\n",
            "Epoch 3162/4000\n",
            "1/1 [==============================] - 0s 49ms/step - loss: 4.0384e-04 - accuracy: 1.0000 - val_loss: 0.4664 - val_accuracy: 0.9143\n",
            "Epoch 3163/4000\n",
            "1/1 [==============================] - 0s 33ms/step - loss: 4.0348e-04 - accuracy: 1.0000 - val_loss: 0.4665 - val_accuracy: 0.9143\n",
            "Epoch 3164/4000\n",
            "1/1 [==============================] - 0s 49ms/step - loss: 4.0310e-04 - accuracy: 1.0000 - val_loss: 0.4665 - val_accuracy: 0.9143\n",
            "Epoch 3165/4000\n",
            "1/1 [==============================] - 0s 36ms/step - loss: 4.0272e-04 - accuracy: 1.0000 - val_loss: 0.4666 - val_accuracy: 0.9143\n",
            "Epoch 3166/4000\n",
            "1/1 [==============================] - 0s 49ms/step - loss: 4.0234e-04 - accuracy: 1.0000 - val_loss: 0.4667 - val_accuracy: 0.9143\n",
            "Epoch 3167/4000\n",
            "1/1 [==============================] - 0s 53ms/step - loss: 4.0196e-04 - accuracy: 1.0000 - val_loss: 0.4667 - val_accuracy: 0.9143\n",
            "Epoch 3168/4000\n",
            "1/1 [==============================] - 0s 53ms/step - loss: 4.0161e-04 - accuracy: 1.0000 - val_loss: 0.4668 - val_accuracy: 0.9143\n",
            "Epoch 3169/4000\n",
            "1/1 [==============================] - 0s 46ms/step - loss: 4.0125e-04 - accuracy: 1.0000 - val_loss: 0.4669 - val_accuracy: 0.9143\n",
            "Epoch 3170/4000\n",
            "1/1 [==============================] - 0s 49ms/step - loss: 4.0085e-04 - accuracy: 1.0000 - val_loss: 0.4669 - val_accuracy: 0.9143\n",
            "Epoch 3171/4000\n",
            "1/1 [==============================] - 0s 33ms/step - loss: 4.0048e-04 - accuracy: 1.0000 - val_loss: 0.4670 - val_accuracy: 0.9143\n",
            "Epoch 3172/4000\n",
            "1/1 [==============================] - 0s 48ms/step - loss: 4.0010e-04 - accuracy: 1.0000 - val_loss: 0.4670 - val_accuracy: 0.9143\n",
            "Epoch 3173/4000\n",
            "1/1 [==============================] - 0s 40ms/step - loss: 3.9976e-04 - accuracy: 1.0000 - val_loss: 0.4671 - val_accuracy: 0.9143\n",
            "Epoch 3174/4000\n",
            "1/1 [==============================] - 0s 51ms/step - loss: 3.9939e-04 - accuracy: 1.0000 - val_loss: 0.4672 - val_accuracy: 0.9143\n",
            "Epoch 3175/4000\n",
            "1/1 [==============================] - 0s 49ms/step - loss: 3.9898e-04 - accuracy: 1.0000 - val_loss: 0.4672 - val_accuracy: 0.9143\n",
            "Epoch 3176/4000\n",
            "1/1 [==============================] - 0s 46ms/step - loss: 3.9863e-04 - accuracy: 1.0000 - val_loss: 0.4673 - val_accuracy: 0.9143\n",
            "Epoch 3177/4000\n",
            "1/1 [==============================] - 0s 48ms/step - loss: 3.9827e-04 - accuracy: 1.0000 - val_loss: 0.4673 - val_accuracy: 0.9143\n",
            "Epoch 3178/4000\n",
            "1/1 [==============================] - 0s 54ms/step - loss: 3.9788e-04 - accuracy: 1.0000 - val_loss: 0.4674 - val_accuracy: 0.9143\n",
            "Epoch 3179/4000\n",
            "1/1 [==============================] - 0s 48ms/step - loss: 3.9751e-04 - accuracy: 1.0000 - val_loss: 0.4675 - val_accuracy: 0.9143\n",
            "Epoch 3180/4000\n",
            "1/1 [==============================] - 0s 46ms/step - loss: 3.9715e-04 - accuracy: 1.0000 - val_loss: 0.4675 - val_accuracy: 0.9143\n",
            "Epoch 3181/4000\n",
            "1/1 [==============================] - 0s 34ms/step - loss: 3.9678e-04 - accuracy: 1.0000 - val_loss: 0.4676 - val_accuracy: 0.9143\n",
            "Epoch 3182/4000\n",
            "1/1 [==============================] - 0s 37ms/step - loss: 3.9641e-04 - accuracy: 1.0000 - val_loss: 0.4676 - val_accuracy: 0.9143\n",
            "Epoch 3183/4000\n",
            "1/1 [==============================] - 0s 52ms/step - loss: 3.9605e-04 - accuracy: 1.0000 - val_loss: 0.4677 - val_accuracy: 0.9143\n",
            "Epoch 3184/4000\n",
            "1/1 [==============================] - 0s 37ms/step - loss: 3.9569e-04 - accuracy: 1.0000 - val_loss: 0.4678 - val_accuracy: 0.9143\n",
            "Epoch 3185/4000\n",
            "1/1 [==============================] - 0s 37ms/step - loss: 3.9532e-04 - accuracy: 1.0000 - val_loss: 0.4678 - val_accuracy: 0.9143\n",
            "Epoch 3186/4000\n",
            "1/1 [==============================] - 0s 38ms/step - loss: 3.9496e-04 - accuracy: 1.0000 - val_loss: 0.4679 - val_accuracy: 0.9143\n",
            "Epoch 3187/4000\n",
            "1/1 [==============================] - 0s 39ms/step - loss: 3.9460e-04 - accuracy: 1.0000 - val_loss: 0.4679 - val_accuracy: 0.9143\n",
            "Epoch 3188/4000\n",
            "1/1 [==============================] - 0s 57ms/step - loss: 3.9425e-04 - accuracy: 1.0000 - val_loss: 0.4680 - val_accuracy: 0.9143\n",
            "Epoch 3189/4000\n",
            "1/1 [==============================] - 0s 49ms/step - loss: 3.9387e-04 - accuracy: 1.0000 - val_loss: 0.4680 - val_accuracy: 0.9143\n",
            "Epoch 3190/4000\n",
            "1/1 [==============================] - 0s 47ms/step - loss: 3.9349e-04 - accuracy: 1.0000 - val_loss: 0.4681 - val_accuracy: 0.9143\n",
            "Epoch 3191/4000\n",
            "1/1 [==============================] - 0s 38ms/step - loss: 3.9311e-04 - accuracy: 1.0000 - val_loss: 0.4682 - val_accuracy: 0.9143\n",
            "Epoch 3192/4000\n",
            "1/1 [==============================] - 0s 36ms/step - loss: 3.9276e-04 - accuracy: 1.0000 - val_loss: 0.4682 - val_accuracy: 0.9143\n",
            "Epoch 3193/4000\n",
            "1/1 [==============================] - 0s 49ms/step - loss: 3.9240e-04 - accuracy: 1.0000 - val_loss: 0.4683 - val_accuracy: 0.9143\n",
            "Epoch 3194/4000\n",
            "1/1 [==============================] - 0s 47ms/step - loss: 3.9205e-04 - accuracy: 1.0000 - val_loss: 0.4684 - val_accuracy: 0.9143\n",
            "Epoch 3195/4000\n",
            "1/1 [==============================] - 0s 51ms/step - loss: 3.9170e-04 - accuracy: 1.0000 - val_loss: 0.4684 - val_accuracy: 0.9143\n",
            "Epoch 3196/4000\n",
            "1/1 [==============================] - 0s 52ms/step - loss: 3.9132e-04 - accuracy: 1.0000 - val_loss: 0.4685 - val_accuracy: 0.9143\n",
            "Epoch 3197/4000\n",
            "1/1 [==============================] - 0s 62ms/step - loss: 3.9094e-04 - accuracy: 1.0000 - val_loss: 0.4686 - val_accuracy: 0.9143\n",
            "Epoch 3198/4000\n",
            "1/1 [==============================] - 0s 49ms/step - loss: 3.9059e-04 - accuracy: 1.0000 - val_loss: 0.4686 - val_accuracy: 0.9143\n",
            "Epoch 3199/4000\n",
            "1/1 [==============================] - 0s 51ms/step - loss: 3.9023e-04 - accuracy: 1.0000 - val_loss: 0.4687 - val_accuracy: 0.9143\n",
            "Epoch 3200/4000\n",
            "1/1 [==============================] - 0s 54ms/step - loss: 3.8987e-04 - accuracy: 1.0000 - val_loss: 0.4687 - val_accuracy: 0.9143\n",
            "Epoch 3201/4000\n",
            "1/1 [==============================] - 0s 47ms/step - loss: 3.8952e-04 - accuracy: 1.0000 - val_loss: 0.4688 - val_accuracy: 0.9143\n",
            "Epoch 3202/4000\n",
            "1/1 [==============================] - 0s 48ms/step - loss: 3.8916e-04 - accuracy: 1.0000 - val_loss: 0.4689 - val_accuracy: 0.9143\n",
            "Epoch 3203/4000\n",
            "1/1 [==============================] - 0s 33ms/step - loss: 3.8879e-04 - accuracy: 1.0000 - val_loss: 0.4689 - val_accuracy: 0.9143\n",
            "Epoch 3204/4000\n",
            "1/1 [==============================] - 0s 51ms/step - loss: 3.8846e-04 - accuracy: 1.0000 - val_loss: 0.4690 - val_accuracy: 0.9143\n",
            "Epoch 3205/4000\n",
            "1/1 [==============================] - 0s 47ms/step - loss: 3.8811e-04 - accuracy: 1.0000 - val_loss: 0.4690 - val_accuracy: 0.9143\n",
            "Epoch 3206/4000\n",
            "1/1 [==============================] - 0s 32ms/step - loss: 3.8776e-04 - accuracy: 1.0000 - val_loss: 0.4691 - val_accuracy: 0.9143\n",
            "Epoch 3207/4000\n",
            "1/1 [==============================] - 0s 47ms/step - loss: 3.8740e-04 - accuracy: 1.0000 - val_loss: 0.4692 - val_accuracy: 0.9143\n",
            "Epoch 3208/4000\n",
            "1/1 [==============================] - 0s 48ms/step - loss: 3.8703e-04 - accuracy: 1.0000 - val_loss: 0.4692 - val_accuracy: 0.9143\n",
            "Epoch 3209/4000\n",
            "1/1 [==============================] - 0s 51ms/step - loss: 3.8669e-04 - accuracy: 1.0000 - val_loss: 0.4693 - val_accuracy: 0.9143\n",
            "Epoch 3210/4000\n",
            "1/1 [==============================] - 0s 33ms/step - loss: 3.8634e-04 - accuracy: 1.0000 - val_loss: 0.4693 - val_accuracy: 0.9143\n",
            "Epoch 3211/4000\n",
            "1/1 [==============================] - 0s 54ms/step - loss: 3.8598e-04 - accuracy: 1.0000 - val_loss: 0.4694 - val_accuracy: 0.9143\n",
            "Epoch 3212/4000\n",
            "1/1 [==============================] - 0s 45ms/step - loss: 3.8562e-04 - accuracy: 1.0000 - val_loss: 0.4695 - val_accuracy: 0.9143\n",
            "Epoch 3213/4000\n",
            "1/1 [==============================] - 0s 47ms/step - loss: 3.8528e-04 - accuracy: 1.0000 - val_loss: 0.4695 - val_accuracy: 0.9143\n",
            "Epoch 3214/4000\n",
            "1/1 [==============================] - 0s 51ms/step - loss: 3.8491e-04 - accuracy: 1.0000 - val_loss: 0.4696 - val_accuracy: 0.9143\n",
            "Epoch 3215/4000\n",
            "1/1 [==============================] - 0s 48ms/step - loss: 3.8455e-04 - accuracy: 1.0000 - val_loss: 0.4696 - val_accuracy: 0.9143\n",
            "Epoch 3216/4000\n",
            "1/1 [==============================] - 0s 35ms/step - loss: 3.8421e-04 - accuracy: 1.0000 - val_loss: 0.4697 - val_accuracy: 0.9143\n",
            "Epoch 3217/4000\n",
            "1/1 [==============================] - 0s 34ms/step - loss: 3.8386e-04 - accuracy: 1.0000 - val_loss: 0.4697 - val_accuracy: 0.9143\n",
            "Epoch 3218/4000\n",
            "1/1 [==============================] - 0s 54ms/step - loss: 3.8353e-04 - accuracy: 1.0000 - val_loss: 0.4698 - val_accuracy: 0.9143\n",
            "Epoch 3219/4000\n",
            "1/1 [==============================] - 0s 54ms/step - loss: 3.8319e-04 - accuracy: 1.0000 - val_loss: 0.4699 - val_accuracy: 0.9143\n",
            "Epoch 3220/4000\n",
            "1/1 [==============================] - 0s 48ms/step - loss: 3.8281e-04 - accuracy: 1.0000 - val_loss: 0.4699 - val_accuracy: 0.9143\n",
            "Epoch 3221/4000\n",
            "1/1 [==============================] - 0s 47ms/step - loss: 3.8245e-04 - accuracy: 1.0000 - val_loss: 0.4700 - val_accuracy: 0.9143\n",
            "Epoch 3222/4000\n",
            "1/1 [==============================] - 0s 35ms/step - loss: 3.8212e-04 - accuracy: 1.0000 - val_loss: 0.4701 - val_accuracy: 0.9143\n",
            "Epoch 3223/4000\n",
            "1/1 [==============================] - 0s 34ms/step - loss: 3.8177e-04 - accuracy: 1.0000 - val_loss: 0.4701 - val_accuracy: 0.9143\n",
            "Epoch 3224/4000\n",
            "1/1 [==============================] - 0s 51ms/step - loss: 3.8141e-04 - accuracy: 1.0000 - val_loss: 0.4702 - val_accuracy: 0.9143\n",
            "Epoch 3225/4000\n",
            "1/1 [==============================] - 0s 37ms/step - loss: 3.8106e-04 - accuracy: 1.0000 - val_loss: 0.4702 - val_accuracy: 0.9143\n",
            "Epoch 3226/4000\n",
            "1/1 [==============================] - 0s 52ms/step - loss: 3.8071e-04 - accuracy: 1.0000 - val_loss: 0.4703 - val_accuracy: 0.9143\n",
            "Epoch 3227/4000\n",
            "1/1 [==============================] - 0s 50ms/step - loss: 3.8037e-04 - accuracy: 1.0000 - val_loss: 0.4704 - val_accuracy: 0.9143\n",
            "Epoch 3228/4000\n",
            "1/1 [==============================] - 0s 33ms/step - loss: 3.8004e-04 - accuracy: 1.0000 - val_loss: 0.4704 - val_accuracy: 0.9143\n",
            "Epoch 3229/4000\n",
            "1/1 [==============================] - 0s 32ms/step - loss: 3.7967e-04 - accuracy: 1.0000 - val_loss: 0.4705 - val_accuracy: 0.9143\n",
            "Epoch 3230/4000\n",
            "1/1 [==============================] - 0s 47ms/step - loss: 3.7932e-04 - accuracy: 1.0000 - val_loss: 0.4705 - val_accuracy: 0.9143\n",
            "Epoch 3231/4000\n",
            "1/1 [==============================] - 0s 46ms/step - loss: 3.7899e-04 - accuracy: 1.0000 - val_loss: 0.4706 - val_accuracy: 0.9143\n",
            "Epoch 3232/4000\n",
            "1/1 [==============================] - 0s 35ms/step - loss: 3.7865e-04 - accuracy: 1.0000 - val_loss: 0.4707 - val_accuracy: 0.9143\n",
            "Epoch 3233/4000\n",
            "1/1 [==============================] - 0s 49ms/step - loss: 3.7831e-04 - accuracy: 1.0000 - val_loss: 0.4707 - val_accuracy: 0.9143\n",
            "Epoch 3234/4000\n",
            "1/1 [==============================] - 0s 61ms/step - loss: 3.7798e-04 - accuracy: 1.0000 - val_loss: 0.4708 - val_accuracy: 0.9143\n",
            "Epoch 3235/4000\n",
            "1/1 [==============================] - 0s 46ms/step - loss: 3.7762e-04 - accuracy: 1.0000 - val_loss: 0.4708 - val_accuracy: 0.9143\n",
            "Epoch 3236/4000\n",
            "1/1 [==============================] - 0s 62ms/step - loss: 3.7725e-04 - accuracy: 1.0000 - val_loss: 0.4709 - val_accuracy: 0.9143\n",
            "Epoch 3237/4000\n",
            "1/1 [==============================] - 0s 35ms/step - loss: 3.7691e-04 - accuracy: 1.0000 - val_loss: 0.4710 - val_accuracy: 0.9143\n",
            "Epoch 3238/4000\n",
            "1/1 [==============================] - 0s 45ms/step - loss: 3.7656e-04 - accuracy: 1.0000 - val_loss: 0.4710 - val_accuracy: 0.9143\n",
            "Epoch 3239/4000\n",
            "1/1 [==============================] - 0s 51ms/step - loss: 3.7624e-04 - accuracy: 1.0000 - val_loss: 0.4711 - val_accuracy: 0.9143\n",
            "Epoch 3240/4000\n",
            "1/1 [==============================] - 0s 53ms/step - loss: 3.7589e-04 - accuracy: 1.0000 - val_loss: 0.4711 - val_accuracy: 0.9143\n",
            "Epoch 3241/4000\n",
            "1/1 [==============================] - 0s 53ms/step - loss: 3.7554e-04 - accuracy: 1.0000 - val_loss: 0.4712 - val_accuracy: 0.9143\n",
            "Epoch 3242/4000\n",
            "1/1 [==============================] - 0s 49ms/step - loss: 3.7519e-04 - accuracy: 1.0000 - val_loss: 0.4712 - val_accuracy: 0.9143\n",
            "Epoch 3243/4000\n",
            "1/1 [==============================] - 0s 53ms/step - loss: 3.7487e-04 - accuracy: 1.0000 - val_loss: 0.4713 - val_accuracy: 0.9143\n",
            "Epoch 3244/4000\n",
            "1/1 [==============================] - 0s 46ms/step - loss: 3.7453e-04 - accuracy: 1.0000 - val_loss: 0.4714 - val_accuracy: 0.9143\n",
            "Epoch 3245/4000\n",
            "1/1 [==============================] - 0s 48ms/step - loss: 3.7418e-04 - accuracy: 1.0000 - val_loss: 0.4714 - val_accuracy: 0.9143\n",
            "Epoch 3246/4000\n",
            "1/1 [==============================] - 0s 49ms/step - loss: 3.7383e-04 - accuracy: 1.0000 - val_loss: 0.4715 - val_accuracy: 0.9143\n",
            "Epoch 3247/4000\n",
            "1/1 [==============================] - 0s 47ms/step - loss: 3.7349e-04 - accuracy: 1.0000 - val_loss: 0.4715 - val_accuracy: 0.9143\n",
            "Epoch 3248/4000\n",
            "1/1 [==============================] - 0s 49ms/step - loss: 3.7316e-04 - accuracy: 1.0000 - val_loss: 0.4716 - val_accuracy: 0.9143\n",
            "Epoch 3249/4000\n",
            "1/1 [==============================] - 0s 49ms/step - loss: 3.7283e-04 - accuracy: 1.0000 - val_loss: 0.4717 - val_accuracy: 0.9143\n",
            "Epoch 3250/4000\n",
            "1/1 [==============================] - 0s 35ms/step - loss: 3.7250e-04 - accuracy: 1.0000 - val_loss: 0.4717 - val_accuracy: 0.9143\n",
            "Epoch 3251/4000\n",
            "1/1 [==============================] - 0s 51ms/step - loss: 3.7217e-04 - accuracy: 1.0000 - val_loss: 0.4718 - val_accuracy: 0.9143\n",
            "Epoch 3252/4000\n",
            "1/1 [==============================] - 0s 47ms/step - loss: 3.7181e-04 - accuracy: 1.0000 - val_loss: 0.4719 - val_accuracy: 0.9143\n",
            "Epoch 3253/4000\n",
            "1/1 [==============================] - 0s 54ms/step - loss: 3.7145e-04 - accuracy: 1.0000 - val_loss: 0.4719 - val_accuracy: 0.9143\n",
            "Epoch 3254/4000\n",
            "1/1 [==============================] - 0s 47ms/step - loss: 3.7113e-04 - accuracy: 1.0000 - val_loss: 0.4720 - val_accuracy: 0.9143\n",
            "Epoch 3255/4000\n",
            "1/1 [==============================] - 0s 47ms/step - loss: 3.7083e-04 - accuracy: 1.0000 - val_loss: 0.4720 - val_accuracy: 0.9143\n",
            "Epoch 3256/4000\n",
            "1/1 [==============================] - 0s 52ms/step - loss: 3.7050e-04 - accuracy: 1.0000 - val_loss: 0.4721 - val_accuracy: 0.9143\n",
            "Epoch 3257/4000\n",
            "1/1 [==============================] - 0s 36ms/step - loss: 3.7014e-04 - accuracy: 1.0000 - val_loss: 0.4721 - val_accuracy: 0.9143\n",
            "Epoch 3258/4000\n",
            "1/1 [==============================] - 0s 47ms/step - loss: 3.6977e-04 - accuracy: 1.0000 - val_loss: 0.4722 - val_accuracy: 0.9143\n",
            "Epoch 3259/4000\n",
            "1/1 [==============================] - 0s 52ms/step - loss: 3.6943e-04 - accuracy: 1.0000 - val_loss: 0.4723 - val_accuracy: 0.9143\n",
            "Epoch 3260/4000\n",
            "1/1 [==============================] - 0s 47ms/step - loss: 3.6912e-04 - accuracy: 1.0000 - val_loss: 0.4723 - val_accuracy: 0.9143\n",
            "Epoch 3261/4000\n",
            "1/1 [==============================] - 0s 47ms/step - loss: 3.6881e-04 - accuracy: 1.0000 - val_loss: 0.4724 - val_accuracy: 0.9143\n",
            "Epoch 3262/4000\n",
            "1/1 [==============================] - 0s 48ms/step - loss: 3.6846e-04 - accuracy: 1.0000 - val_loss: 0.4724 - val_accuracy: 0.9143\n",
            "Epoch 3263/4000\n",
            "1/1 [==============================] - 0s 46ms/step - loss: 3.6811e-04 - accuracy: 1.0000 - val_loss: 0.4725 - val_accuracy: 0.9143\n",
            "Epoch 3264/4000\n",
            "1/1 [==============================] - 0s 54ms/step - loss: 3.6778e-04 - accuracy: 1.0000 - val_loss: 0.4726 - val_accuracy: 0.9143\n",
            "Epoch 3265/4000\n",
            "1/1 [==============================] - 0s 46ms/step - loss: 3.6747e-04 - accuracy: 1.0000 - val_loss: 0.4726 - val_accuracy: 0.9143\n",
            "Epoch 3266/4000\n",
            "1/1 [==============================] - 0s 48ms/step - loss: 3.6715e-04 - accuracy: 1.0000 - val_loss: 0.4727 - val_accuracy: 0.9143\n",
            "Epoch 3267/4000\n",
            "1/1 [==============================] - 0s 50ms/step - loss: 3.6680e-04 - accuracy: 1.0000 - val_loss: 0.4727 - val_accuracy: 0.9143\n",
            "Epoch 3268/4000\n",
            "1/1 [==============================] - 0s 49ms/step - loss: 3.6645e-04 - accuracy: 1.0000 - val_loss: 0.4728 - val_accuracy: 0.9143\n",
            "Epoch 3269/4000\n",
            "1/1 [==============================] - 0s 49ms/step - loss: 3.6614e-04 - accuracy: 1.0000 - val_loss: 0.4729 - val_accuracy: 0.9143\n",
            "Epoch 3270/4000\n",
            "1/1 [==============================] - 0s 50ms/step - loss: 3.6581e-04 - accuracy: 1.0000 - val_loss: 0.4729 - val_accuracy: 0.9143\n",
            "Epoch 3271/4000\n",
            "1/1 [==============================] - 0s 45ms/step - loss: 3.6546e-04 - accuracy: 1.0000 - val_loss: 0.4730 - val_accuracy: 0.9143\n",
            "Epoch 3272/4000\n",
            "1/1 [==============================] - 0s 49ms/step - loss: 3.6512e-04 - accuracy: 1.0000 - val_loss: 0.4730 - val_accuracy: 0.9143\n",
            "Epoch 3273/4000\n",
            "1/1 [==============================] - 0s 48ms/step - loss: 3.6480e-04 - accuracy: 1.0000 - val_loss: 0.4731 - val_accuracy: 0.9143\n",
            "Epoch 3274/4000\n",
            "1/1 [==============================] - 0s 50ms/step - loss: 3.6448e-04 - accuracy: 1.0000 - val_loss: 0.4732 - val_accuracy: 0.9143\n",
            "Epoch 3275/4000\n",
            "1/1 [==============================] - 0s 46ms/step - loss: 3.6417e-04 - accuracy: 1.0000 - val_loss: 0.4732 - val_accuracy: 0.9143\n",
            "Epoch 3276/4000\n",
            "1/1 [==============================] - 0s 47ms/step - loss: 3.6383e-04 - accuracy: 1.0000 - val_loss: 0.4733 - val_accuracy: 0.9143\n",
            "Epoch 3277/4000\n",
            "1/1 [==============================] - 0s 47ms/step - loss: 3.6349e-04 - accuracy: 1.0000 - val_loss: 0.4733 - val_accuracy: 0.9143\n",
            "Epoch 3278/4000\n",
            "1/1 [==============================] - 0s 47ms/step - loss: 3.6315e-04 - accuracy: 1.0000 - val_loss: 0.4734 - val_accuracy: 0.9143\n",
            "Epoch 3279/4000\n",
            "1/1 [==============================] - 0s 39ms/step - loss: 3.6283e-04 - accuracy: 1.0000 - val_loss: 0.4734 - val_accuracy: 0.9143\n",
            "Epoch 3280/4000\n",
            "1/1 [==============================] - 0s 47ms/step - loss: 3.6250e-04 - accuracy: 1.0000 - val_loss: 0.4735 - val_accuracy: 0.9143\n",
            "Epoch 3281/4000\n",
            "1/1 [==============================] - 0s 36ms/step - loss: 3.6218e-04 - accuracy: 1.0000 - val_loss: 0.4736 - val_accuracy: 0.9143\n",
            "Epoch 3282/4000\n",
            "1/1 [==============================] - 0s 47ms/step - loss: 3.6185e-04 - accuracy: 1.0000 - val_loss: 0.4736 - val_accuracy: 0.9143\n",
            "Epoch 3283/4000\n",
            "1/1 [==============================] - 0s 50ms/step - loss: 3.6153e-04 - accuracy: 1.0000 - val_loss: 0.4737 - val_accuracy: 0.9143\n",
            "Epoch 3284/4000\n",
            "1/1 [==============================] - 0s 47ms/step - loss: 3.6121e-04 - accuracy: 1.0000 - val_loss: 0.4737 - val_accuracy: 0.9143\n",
            "Epoch 3285/4000\n",
            "1/1 [==============================] - 0s 32ms/step - loss: 3.6088e-04 - accuracy: 1.0000 - val_loss: 0.4738 - val_accuracy: 0.9143\n",
            "Epoch 3286/4000\n",
            "1/1 [==============================] - 0s 40ms/step - loss: 3.6057e-04 - accuracy: 1.0000 - val_loss: 0.4739 - val_accuracy: 0.9143\n",
            "Epoch 3287/4000\n",
            "1/1 [==============================] - 0s 49ms/step - loss: 3.6025e-04 - accuracy: 1.0000 - val_loss: 0.4739 - val_accuracy: 0.9143\n",
            "Epoch 3288/4000\n",
            "1/1 [==============================] - 0s 59ms/step - loss: 3.5994e-04 - accuracy: 1.0000 - val_loss: 0.4740 - val_accuracy: 0.9143\n",
            "Epoch 3289/4000\n",
            "1/1 [==============================] - 0s 48ms/step - loss: 3.5961e-04 - accuracy: 1.0000 - val_loss: 0.4740 - val_accuracy: 0.9143\n",
            "Epoch 3290/4000\n",
            "1/1 [==============================] - 0s 38ms/step - loss: 3.5929e-04 - accuracy: 1.0000 - val_loss: 0.4741 - val_accuracy: 0.9143\n",
            "Epoch 3291/4000\n",
            "1/1 [==============================] - 0s 52ms/step - loss: 3.5894e-04 - accuracy: 1.0000 - val_loss: 0.4742 - val_accuracy: 0.9143\n",
            "Epoch 3292/4000\n",
            "1/1 [==============================] - 0s 50ms/step - loss: 3.5864e-04 - accuracy: 1.0000 - val_loss: 0.4742 - val_accuracy: 0.9143\n",
            "Epoch 3293/4000\n",
            "1/1 [==============================] - 0s 48ms/step - loss: 3.5833e-04 - accuracy: 1.0000 - val_loss: 0.4743 - val_accuracy: 0.9143\n",
            "Epoch 3294/4000\n",
            "1/1 [==============================] - 0s 47ms/step - loss: 3.5800e-04 - accuracy: 1.0000 - val_loss: 0.4743 - val_accuracy: 0.9143\n",
            "Epoch 3295/4000\n",
            "1/1 [==============================] - 0s 49ms/step - loss: 3.5767e-04 - accuracy: 1.0000 - val_loss: 0.4744 - val_accuracy: 0.9143\n",
            "Epoch 3296/4000\n",
            "1/1 [==============================] - 0s 33ms/step - loss: 3.5735e-04 - accuracy: 1.0000 - val_loss: 0.4745 - val_accuracy: 0.9143\n",
            "Epoch 3297/4000\n",
            "1/1 [==============================] - 0s 48ms/step - loss: 3.5703e-04 - accuracy: 1.0000 - val_loss: 0.4745 - val_accuracy: 0.9143\n",
            "Epoch 3298/4000\n",
            "1/1 [==============================] - 0s 44ms/step - loss: 3.5670e-04 - accuracy: 1.0000 - val_loss: 0.4746 - val_accuracy: 0.9143\n",
            "Epoch 3299/4000\n",
            "1/1 [==============================] - 0s 49ms/step - loss: 3.5639e-04 - accuracy: 1.0000 - val_loss: 0.4746 - val_accuracy: 0.9143\n",
            "Epoch 3300/4000\n",
            "1/1 [==============================] - 0s 50ms/step - loss: 3.5608e-04 - accuracy: 1.0000 - val_loss: 0.4747 - val_accuracy: 0.9143\n",
            "Epoch 3301/4000\n",
            "1/1 [==============================] - 0s 47ms/step - loss: 3.5573e-04 - accuracy: 1.0000 - val_loss: 0.4748 - val_accuracy: 0.9143\n",
            "Epoch 3302/4000\n",
            "1/1 [==============================] - 0s 35ms/step - loss: 3.5542e-04 - accuracy: 1.0000 - val_loss: 0.4748 - val_accuracy: 0.9143\n",
            "Epoch 3303/4000\n",
            "1/1 [==============================] - 0s 51ms/step - loss: 3.5510e-04 - accuracy: 1.0000 - val_loss: 0.4749 - val_accuracy: 0.9143\n",
            "Epoch 3304/4000\n",
            "1/1 [==============================] - 0s 49ms/step - loss: 3.5479e-04 - accuracy: 1.0000 - val_loss: 0.4749 - val_accuracy: 0.9143\n",
            "Epoch 3305/4000\n",
            "1/1 [==============================] - 0s 48ms/step - loss: 3.5445e-04 - accuracy: 1.0000 - val_loss: 0.4750 - val_accuracy: 0.9143\n",
            "Epoch 3306/4000\n",
            "1/1 [==============================] - 0s 51ms/step - loss: 3.5414e-04 - accuracy: 1.0000 - val_loss: 0.4751 - val_accuracy: 0.9143\n",
            "Epoch 3307/4000\n",
            "1/1 [==============================] - 0s 47ms/step - loss: 3.5383e-04 - accuracy: 1.0000 - val_loss: 0.4751 - val_accuracy: 0.9143\n",
            "Epoch 3308/4000\n",
            "1/1 [==============================] - 0s 47ms/step - loss: 3.5352e-04 - accuracy: 1.0000 - val_loss: 0.4752 - val_accuracy: 0.9143\n",
            "Epoch 3309/4000\n",
            "1/1 [==============================] - 0s 49ms/step - loss: 3.5320e-04 - accuracy: 1.0000 - val_loss: 0.4752 - val_accuracy: 0.9143\n",
            "Epoch 3310/4000\n",
            "1/1 [==============================] - 0s 32ms/step - loss: 3.5288e-04 - accuracy: 1.0000 - val_loss: 0.4753 - val_accuracy: 0.9143\n",
            "Epoch 3311/4000\n",
            "1/1 [==============================] - 0s 47ms/step - loss: 3.5256e-04 - accuracy: 1.0000 - val_loss: 0.4753 - val_accuracy: 0.9143\n",
            "Epoch 3312/4000\n",
            "1/1 [==============================] - 0s 48ms/step - loss: 3.5226e-04 - accuracy: 1.0000 - val_loss: 0.4754 - val_accuracy: 0.9143\n",
            "Epoch 3313/4000\n",
            "1/1 [==============================] - 0s 47ms/step - loss: 3.5193e-04 - accuracy: 1.0000 - val_loss: 0.4755 - val_accuracy: 0.9143\n",
            "Epoch 3314/4000\n",
            "1/1 [==============================] - 0s 53ms/step - loss: 3.5161e-04 - accuracy: 1.0000 - val_loss: 0.4755 - val_accuracy: 0.9143\n",
            "Epoch 3315/4000\n",
            "1/1 [==============================] - 0s 39ms/step - loss: 3.5131e-04 - accuracy: 1.0000 - val_loss: 0.4756 - val_accuracy: 0.9143\n",
            "Epoch 3316/4000\n",
            "1/1 [==============================] - 0s 48ms/step - loss: 3.5100e-04 - accuracy: 1.0000 - val_loss: 0.4756 - val_accuracy: 0.9143\n",
            "Epoch 3317/4000\n",
            "1/1 [==============================] - 0s 44ms/step - loss: 3.5068e-04 - accuracy: 1.0000 - val_loss: 0.4757 - val_accuracy: 0.9143\n",
            "Epoch 3318/4000\n",
            "1/1 [==============================] - 0s 50ms/step - loss: 3.5036e-04 - accuracy: 1.0000 - val_loss: 0.4758 - val_accuracy: 0.9143\n",
            "Epoch 3319/4000\n",
            "1/1 [==============================] - 0s 33ms/step - loss: 3.5006e-04 - accuracy: 1.0000 - val_loss: 0.4758 - val_accuracy: 0.9143\n",
            "Epoch 3320/4000\n",
            "1/1 [==============================] - 0s 43ms/step - loss: 3.4975e-04 - accuracy: 1.0000 - val_loss: 0.4759 - val_accuracy: 0.9143\n",
            "Epoch 3321/4000\n",
            "1/1 [==============================] - 0s 51ms/step - loss: 3.4942e-04 - accuracy: 1.0000 - val_loss: 0.4759 - val_accuracy: 0.9143\n",
            "Epoch 3322/4000\n",
            "1/1 [==============================] - 0s 46ms/step - loss: 3.4910e-04 - accuracy: 1.0000 - val_loss: 0.4760 - val_accuracy: 0.9143\n",
            "Epoch 3323/4000\n",
            "1/1 [==============================] - 0s 47ms/step - loss: 3.4879e-04 - accuracy: 1.0000 - val_loss: 0.4761 - val_accuracy: 0.9143\n",
            "Epoch 3324/4000\n",
            "1/1 [==============================] - 0s 53ms/step - loss: 3.4849e-04 - accuracy: 1.0000 - val_loss: 0.4761 - val_accuracy: 0.9143\n",
            "Epoch 3325/4000\n",
            "1/1 [==============================] - 0s 50ms/step - loss: 3.4818e-04 - accuracy: 1.0000 - val_loss: 0.4762 - val_accuracy: 0.9143\n",
            "Epoch 3326/4000\n",
            "1/1 [==============================] - 0s 68ms/step - loss: 3.4786e-04 - accuracy: 1.0000 - val_loss: 0.4762 - val_accuracy: 0.9143\n",
            "Epoch 3327/4000\n",
            "1/1 [==============================] - 0s 51ms/step - loss: 3.4754e-04 - accuracy: 1.0000 - val_loss: 0.4763 - val_accuracy: 0.9143\n",
            "Epoch 3328/4000\n",
            "1/1 [==============================] - 0s 51ms/step - loss: 3.4724e-04 - accuracy: 1.0000 - val_loss: 0.4764 - val_accuracy: 0.9143\n",
            "Epoch 3329/4000\n",
            "1/1 [==============================] - 0s 46ms/step - loss: 3.4694e-04 - accuracy: 1.0000 - val_loss: 0.4764 - val_accuracy: 0.9143\n",
            "Epoch 3330/4000\n",
            "1/1 [==============================] - 0s 48ms/step - loss: 3.4664e-04 - accuracy: 1.0000 - val_loss: 0.4765 - val_accuracy: 0.9143\n",
            "Epoch 3331/4000\n",
            "1/1 [==============================] - 0s 50ms/step - loss: 3.4633e-04 - accuracy: 1.0000 - val_loss: 0.4765 - val_accuracy: 0.9143\n",
            "Epoch 3332/4000\n",
            "1/1 [==============================] - 0s 46ms/step - loss: 3.4602e-04 - accuracy: 1.0000 - val_loss: 0.4766 - val_accuracy: 0.9143\n",
            "Epoch 3333/4000\n",
            "1/1 [==============================] - 0s 62ms/step - loss: 3.4570e-04 - accuracy: 1.0000 - val_loss: 0.4766 - val_accuracy: 0.9143\n",
            "Epoch 3334/4000\n",
            "1/1 [==============================] - 0s 55ms/step - loss: 3.4540e-04 - accuracy: 1.0000 - val_loss: 0.4767 - val_accuracy: 0.9143\n",
            "Epoch 3335/4000\n",
            "1/1 [==============================] - 0s 50ms/step - loss: 3.4510e-04 - accuracy: 1.0000 - val_loss: 0.4767 - val_accuracy: 0.9143\n",
            "Epoch 3336/4000\n",
            "1/1 [==============================] - 0s 49ms/step - loss: 3.4478e-04 - accuracy: 1.0000 - val_loss: 0.4768 - val_accuracy: 0.9143\n",
            "Epoch 3337/4000\n",
            "1/1 [==============================] - 0s 48ms/step - loss: 3.4448e-04 - accuracy: 1.0000 - val_loss: 0.4769 - val_accuracy: 0.9143\n",
            "Epoch 3338/4000\n",
            "1/1 [==============================] - 0s 47ms/step - loss: 3.4417e-04 - accuracy: 1.0000 - val_loss: 0.4769 - val_accuracy: 0.9143\n",
            "Epoch 3339/4000\n",
            "1/1 [==============================] - 0s 44ms/step - loss: 3.4388e-04 - accuracy: 1.0000 - val_loss: 0.4770 - val_accuracy: 0.9143\n",
            "Epoch 3340/4000\n",
            "1/1 [==============================] - 0s 49ms/step - loss: 3.4356e-04 - accuracy: 1.0000 - val_loss: 0.4770 - val_accuracy: 0.9143\n",
            "Epoch 3341/4000\n",
            "1/1 [==============================] - 0s 58ms/step - loss: 3.4325e-04 - accuracy: 1.0000 - val_loss: 0.4771 - val_accuracy: 0.9143\n",
            "Epoch 3342/4000\n",
            "1/1 [==============================] - 0s 47ms/step - loss: 3.4294e-04 - accuracy: 1.0000 - val_loss: 0.4772 - val_accuracy: 0.9143\n",
            "Epoch 3343/4000\n",
            "1/1 [==============================] - 0s 55ms/step - loss: 3.4265e-04 - accuracy: 1.0000 - val_loss: 0.4772 - val_accuracy: 0.9143\n",
            "Epoch 3344/4000\n",
            "1/1 [==============================] - 0s 49ms/step - loss: 3.4235e-04 - accuracy: 1.0000 - val_loss: 0.4773 - val_accuracy: 0.9143\n",
            "Epoch 3345/4000\n",
            "1/1 [==============================] - 0s 38ms/step - loss: 3.4204e-04 - accuracy: 1.0000 - val_loss: 0.4773 - val_accuracy: 0.9143\n",
            "Epoch 3346/4000\n",
            "1/1 [==============================] - 0s 47ms/step - loss: 3.4174e-04 - accuracy: 1.0000 - val_loss: 0.4774 - val_accuracy: 0.9143\n",
            "Epoch 3347/4000\n",
            "1/1 [==============================] - 0s 57ms/step - loss: 3.4142e-04 - accuracy: 1.0000 - val_loss: 0.4774 - val_accuracy: 0.9143\n",
            "Epoch 3348/4000\n",
            "1/1 [==============================] - 0s 49ms/step - loss: 3.4113e-04 - accuracy: 1.0000 - val_loss: 0.4775 - val_accuracy: 0.9143\n",
            "Epoch 3349/4000\n",
            "1/1 [==============================] - 0s 46ms/step - loss: 3.4084e-04 - accuracy: 1.0000 - val_loss: 0.4776 - val_accuracy: 0.9143\n",
            "Epoch 3350/4000\n",
            "1/1 [==============================] - 0s 38ms/step - loss: 3.4053e-04 - accuracy: 1.0000 - val_loss: 0.4776 - val_accuracy: 0.9143\n",
            "Epoch 3351/4000\n",
            "1/1 [==============================] - 0s 49ms/step - loss: 3.4023e-04 - accuracy: 1.0000 - val_loss: 0.4777 - val_accuracy: 0.9143\n",
            "Epoch 3352/4000\n",
            "1/1 [==============================] - 0s 49ms/step - loss: 3.3993e-04 - accuracy: 1.0000 - val_loss: 0.4777 - val_accuracy: 0.9143\n",
            "Epoch 3353/4000\n",
            "1/1 [==============================] - 0s 52ms/step - loss: 3.3961e-04 - accuracy: 1.0000 - val_loss: 0.4778 - val_accuracy: 0.9143\n",
            "Epoch 3354/4000\n",
            "1/1 [==============================] - 0s 46ms/step - loss: 3.3931e-04 - accuracy: 1.0000 - val_loss: 0.4779 - val_accuracy: 0.9143\n",
            "Epoch 3355/4000\n",
            "1/1 [==============================] - 0s 51ms/step - loss: 3.3903e-04 - accuracy: 1.0000 - val_loss: 0.4779 - val_accuracy: 0.9143\n",
            "Epoch 3356/4000\n",
            "1/1 [==============================] - 0s 50ms/step - loss: 3.3872e-04 - accuracy: 1.0000 - val_loss: 0.4780 - val_accuracy: 0.9143\n",
            "Epoch 3357/4000\n",
            "1/1 [==============================] - 0s 33ms/step - loss: 3.3842e-04 - accuracy: 1.0000 - val_loss: 0.4780 - val_accuracy: 0.9143\n",
            "Epoch 3358/4000\n",
            "1/1 [==============================] - 0s 46ms/step - loss: 3.3812e-04 - accuracy: 1.0000 - val_loss: 0.4781 - val_accuracy: 0.9143\n",
            "Epoch 3359/4000\n",
            "1/1 [==============================] - 0s 44ms/step - loss: 3.3781e-04 - accuracy: 1.0000 - val_loss: 0.4782 - val_accuracy: 0.9143\n",
            "Epoch 3360/4000\n",
            "1/1 [==============================] - 0s 48ms/step - loss: 3.3751e-04 - accuracy: 1.0000 - val_loss: 0.4782 - val_accuracy: 0.9143\n",
            "Epoch 3361/4000\n",
            "1/1 [==============================] - 0s 57ms/step - loss: 3.3722e-04 - accuracy: 1.0000 - val_loss: 0.4783 - val_accuracy: 0.9143\n",
            "Epoch 3362/4000\n",
            "1/1 [==============================] - 0s 49ms/step - loss: 3.3692e-04 - accuracy: 1.0000 - val_loss: 0.4783 - val_accuracy: 0.9143\n",
            "Epoch 3363/4000\n",
            "1/1 [==============================] - 0s 46ms/step - loss: 3.3662e-04 - accuracy: 1.0000 - val_loss: 0.4784 - val_accuracy: 0.9143\n",
            "Epoch 3364/4000\n",
            "1/1 [==============================] - 0s 46ms/step - loss: 3.3633e-04 - accuracy: 1.0000 - val_loss: 0.4784 - val_accuracy: 0.9143\n",
            "Epoch 3365/4000\n",
            "1/1 [==============================] - 0s 51ms/step - loss: 3.3603e-04 - accuracy: 1.0000 - val_loss: 0.4785 - val_accuracy: 0.9143\n",
            "Epoch 3366/4000\n",
            "1/1 [==============================] - 0s 41ms/step - loss: 3.3573e-04 - accuracy: 1.0000 - val_loss: 0.4786 - val_accuracy: 0.9143\n",
            "Epoch 3367/4000\n",
            "1/1 [==============================] - 0s 36ms/step - loss: 3.3542e-04 - accuracy: 1.0000 - val_loss: 0.4786 - val_accuracy: 0.9143\n",
            "Epoch 3368/4000\n",
            "1/1 [==============================] - 0s 49ms/step - loss: 3.3512e-04 - accuracy: 1.0000 - val_loss: 0.4787 - val_accuracy: 0.9143\n",
            "Epoch 3369/4000\n",
            "1/1 [==============================] - 0s 43ms/step - loss: 3.3484e-04 - accuracy: 1.0000 - val_loss: 0.4787 - val_accuracy: 0.9143\n",
            "Epoch 3370/4000\n",
            "1/1 [==============================] - 0s 46ms/step - loss: 3.3455e-04 - accuracy: 1.0000 - val_loss: 0.4788 - val_accuracy: 0.9143\n",
            "Epoch 3371/4000\n",
            "1/1 [==============================] - 0s 33ms/step - loss: 3.3424e-04 - accuracy: 1.0000 - val_loss: 0.4788 - val_accuracy: 0.9143\n",
            "Epoch 3372/4000\n",
            "1/1 [==============================] - 0s 47ms/step - loss: 3.3395e-04 - accuracy: 1.0000 - val_loss: 0.4789 - val_accuracy: 0.9143\n",
            "Epoch 3373/4000\n",
            "1/1 [==============================] - 0s 45ms/step - loss: 3.3367e-04 - accuracy: 1.0000 - val_loss: 0.4790 - val_accuracy: 0.9143\n",
            "Epoch 3374/4000\n",
            "1/1 [==============================] - 0s 48ms/step - loss: 3.3339e-04 - accuracy: 1.0000 - val_loss: 0.4790 - val_accuracy: 0.9143\n",
            "Epoch 3375/4000\n",
            "1/1 [==============================] - 0s 48ms/step - loss: 3.3310e-04 - accuracy: 1.0000 - val_loss: 0.4791 - val_accuracy: 0.9143\n",
            "Epoch 3376/4000\n",
            "1/1 [==============================] - 0s 52ms/step - loss: 3.3280e-04 - accuracy: 1.0000 - val_loss: 0.4791 - val_accuracy: 0.9143\n",
            "Epoch 3377/4000\n",
            "1/1 [==============================] - 0s 48ms/step - loss: 3.3249e-04 - accuracy: 1.0000 - val_loss: 0.4792 - val_accuracy: 0.9143\n",
            "Epoch 3378/4000\n",
            "1/1 [==============================] - 0s 46ms/step - loss: 3.3219e-04 - accuracy: 1.0000 - val_loss: 0.4793 - val_accuracy: 0.9143\n",
            "Epoch 3379/4000\n",
            "1/1 [==============================] - 0s 48ms/step - loss: 3.3192e-04 - accuracy: 1.0000 - val_loss: 0.4793 - val_accuracy: 0.9143\n",
            "Epoch 3380/4000\n",
            "1/1 [==============================] - 0s 50ms/step - loss: 3.3163e-04 - accuracy: 1.0000 - val_loss: 0.4794 - val_accuracy: 0.9143\n",
            "Epoch 3381/4000\n",
            "1/1 [==============================] - 0s 38ms/step - loss: 3.3134e-04 - accuracy: 1.0000 - val_loss: 0.4794 - val_accuracy: 0.9143\n",
            "Epoch 3382/4000\n",
            "1/1 [==============================] - 0s 51ms/step - loss: 3.3104e-04 - accuracy: 1.0000 - val_loss: 0.4795 - val_accuracy: 0.9143\n",
            "Epoch 3383/4000\n",
            "1/1 [==============================] - 0s 39ms/step - loss: 3.3074e-04 - accuracy: 1.0000 - val_loss: 0.4795 - val_accuracy: 0.9143\n",
            "Epoch 3384/4000\n",
            "1/1 [==============================] - 0s 47ms/step - loss: 3.3045e-04 - accuracy: 1.0000 - val_loss: 0.4796 - val_accuracy: 0.9143\n",
            "Epoch 3385/4000\n",
            "1/1 [==============================] - 0s 41ms/step - loss: 3.3017e-04 - accuracy: 1.0000 - val_loss: 0.4796 - val_accuracy: 0.9143\n",
            "Epoch 3386/4000\n",
            "1/1 [==============================] - 0s 46ms/step - loss: 3.2988e-04 - accuracy: 1.0000 - val_loss: 0.4797 - val_accuracy: 0.9143\n",
            "Epoch 3387/4000\n",
            "1/1 [==============================] - 0s 47ms/step - loss: 3.2959e-04 - accuracy: 1.0000 - val_loss: 0.4798 - val_accuracy: 0.9143\n",
            "Epoch 3388/4000\n",
            "1/1 [==============================] - 0s 45ms/step - loss: 3.2931e-04 - accuracy: 1.0000 - val_loss: 0.4798 - val_accuracy: 0.9143\n",
            "Epoch 3389/4000\n",
            "1/1 [==============================] - 0s 46ms/step - loss: 3.2901e-04 - accuracy: 1.0000 - val_loss: 0.4799 - val_accuracy: 0.9143\n",
            "Epoch 3390/4000\n",
            "1/1 [==============================] - 0s 52ms/step - loss: 3.2872e-04 - accuracy: 1.0000 - val_loss: 0.4799 - val_accuracy: 0.9143\n",
            "Epoch 3391/4000\n",
            "1/1 [==============================] - 0s 45ms/step - loss: 3.2843e-04 - accuracy: 1.0000 - val_loss: 0.4800 - val_accuracy: 0.9143\n",
            "Epoch 3392/4000\n",
            "1/1 [==============================] - 0s 49ms/step - loss: 3.2814e-04 - accuracy: 1.0000 - val_loss: 0.4800 - val_accuracy: 0.9143\n",
            "Epoch 3393/4000\n",
            "1/1 [==============================] - 0s 34ms/step - loss: 3.2784e-04 - accuracy: 1.0000 - val_loss: 0.4801 - val_accuracy: 0.9143\n",
            "Epoch 3394/4000\n",
            "1/1 [==============================] - 0s 47ms/step - loss: 3.2755e-04 - accuracy: 1.0000 - val_loss: 0.4802 - val_accuracy: 0.9143\n",
            "Epoch 3395/4000\n",
            "1/1 [==============================] - 0s 58ms/step - loss: 3.2728e-04 - accuracy: 1.0000 - val_loss: 0.4802 - val_accuracy: 0.9143\n",
            "Epoch 3396/4000\n",
            "1/1 [==============================] - 0s 36ms/step - loss: 3.2699e-04 - accuracy: 1.0000 - val_loss: 0.4803 - val_accuracy: 0.9143\n",
            "Epoch 3397/4000\n",
            "1/1 [==============================] - 0s 47ms/step - loss: 3.2671e-04 - accuracy: 1.0000 - val_loss: 0.4804 - val_accuracy: 0.9143\n",
            "Epoch 3398/4000\n",
            "1/1 [==============================] - 0s 33ms/step - loss: 3.2642e-04 - accuracy: 1.0000 - val_loss: 0.4804 - val_accuracy: 0.9143\n",
            "Epoch 3399/4000\n",
            "1/1 [==============================] - 0s 50ms/step - loss: 3.2613e-04 - accuracy: 1.0000 - val_loss: 0.4805 - val_accuracy: 0.9143\n",
            "Epoch 3400/4000\n",
            "1/1 [==============================] - 0s 48ms/step - loss: 3.2585e-04 - accuracy: 1.0000 - val_loss: 0.4805 - val_accuracy: 0.9143\n",
            "Epoch 3401/4000\n",
            "1/1 [==============================] - 0s 50ms/step - loss: 3.2556e-04 - accuracy: 1.0000 - val_loss: 0.4806 - val_accuracy: 0.9143\n",
            "Epoch 3402/4000\n",
            "1/1 [==============================] - 0s 50ms/step - loss: 3.2527e-04 - accuracy: 1.0000 - val_loss: 0.4806 - val_accuracy: 0.9143\n",
            "Epoch 3403/4000\n",
            "1/1 [==============================] - 0s 44ms/step - loss: 3.2499e-04 - accuracy: 1.0000 - val_loss: 0.4807 - val_accuracy: 0.9143\n",
            "Epoch 3404/4000\n",
            "1/1 [==============================] - 0s 46ms/step - loss: 3.2470e-04 - accuracy: 1.0000 - val_loss: 0.4808 - val_accuracy: 0.9143\n",
            "Epoch 3405/4000\n",
            "1/1 [==============================] - 0s 34ms/step - loss: 3.2441e-04 - accuracy: 1.0000 - val_loss: 0.4808 - val_accuracy: 0.9143\n",
            "Epoch 3406/4000\n",
            "1/1 [==============================] - 0s 36ms/step - loss: 3.2412e-04 - accuracy: 1.0000 - val_loss: 0.4809 - val_accuracy: 0.9143\n",
            "Epoch 3407/4000\n",
            "1/1 [==============================] - 0s 47ms/step - loss: 3.2385e-04 - accuracy: 1.0000 - val_loss: 0.4809 - val_accuracy: 0.9143\n",
            "Epoch 3408/4000\n",
            "1/1 [==============================] - 0s 51ms/step - loss: 3.2357e-04 - accuracy: 1.0000 - val_loss: 0.4810 - val_accuracy: 0.9143\n",
            "Epoch 3409/4000\n",
            "1/1 [==============================] - 0s 46ms/step - loss: 3.2328e-04 - accuracy: 1.0000 - val_loss: 0.4810 - val_accuracy: 0.9143\n",
            "Epoch 3410/4000\n",
            "1/1 [==============================] - 0s 38ms/step - loss: 3.2300e-04 - accuracy: 1.0000 - val_loss: 0.4811 - val_accuracy: 0.9143\n",
            "Epoch 3411/4000\n",
            "1/1 [==============================] - 0s 46ms/step - loss: 3.2271e-04 - accuracy: 1.0000 - val_loss: 0.4812 - val_accuracy: 0.9143\n",
            "Epoch 3412/4000\n",
            "1/1 [==============================] - 0s 49ms/step - loss: 3.2243e-04 - accuracy: 1.0000 - val_loss: 0.4812 - val_accuracy: 0.9143\n",
            "Epoch 3413/4000\n",
            "1/1 [==============================] - 0s 47ms/step - loss: 3.2216e-04 - accuracy: 1.0000 - val_loss: 0.4813 - val_accuracy: 0.9143\n",
            "Epoch 3414/4000\n",
            "1/1 [==============================] - 0s 36ms/step - loss: 3.2188e-04 - accuracy: 1.0000 - val_loss: 0.4813 - val_accuracy: 0.9143\n",
            "Epoch 3415/4000\n",
            "1/1 [==============================] - 0s 50ms/step - loss: 3.2160e-04 - accuracy: 1.0000 - val_loss: 0.4814 - val_accuracy: 0.9143\n",
            "Epoch 3416/4000\n",
            "1/1 [==============================] - 0s 48ms/step - loss: 3.2130e-04 - accuracy: 1.0000 - val_loss: 0.4814 - val_accuracy: 0.9143\n",
            "Epoch 3417/4000\n",
            "1/1 [==============================] - 0s 58ms/step - loss: 3.2102e-04 - accuracy: 1.0000 - val_loss: 0.4815 - val_accuracy: 0.9143\n",
            "Epoch 3418/4000\n",
            "1/1 [==============================] - 0s 47ms/step - loss: 3.2073e-04 - accuracy: 1.0000 - val_loss: 0.4816 - val_accuracy: 0.9143\n",
            "Epoch 3419/4000\n",
            "1/1 [==============================] - 0s 54ms/step - loss: 3.2047e-04 - accuracy: 1.0000 - val_loss: 0.4816 - val_accuracy: 0.9143\n",
            "Epoch 3420/4000\n",
            "1/1 [==============================] - 0s 32ms/step - loss: 3.2020e-04 - accuracy: 1.0000 - val_loss: 0.4817 - val_accuracy: 0.9143\n",
            "Epoch 3421/4000\n",
            "1/1 [==============================] - 0s 65ms/step - loss: 3.1991e-04 - accuracy: 1.0000 - val_loss: 0.4817 - val_accuracy: 0.9143\n",
            "Epoch 3422/4000\n",
            "1/1 [==============================] - 0s 51ms/step - loss: 3.1963e-04 - accuracy: 1.0000 - val_loss: 0.4818 - val_accuracy: 0.9143\n",
            "Epoch 3423/4000\n",
            "1/1 [==============================] - 0s 47ms/step - loss: 3.1934e-04 - accuracy: 1.0000 - val_loss: 0.4818 - val_accuracy: 0.9143\n",
            "Epoch 3424/4000\n",
            "1/1 [==============================] - 0s 37ms/step - loss: 3.1908e-04 - accuracy: 1.0000 - val_loss: 0.4819 - val_accuracy: 0.9143\n",
            "Epoch 3425/4000\n",
            "1/1 [==============================] - 0s 36ms/step - loss: 3.1882e-04 - accuracy: 1.0000 - val_loss: 0.4820 - val_accuracy: 0.9143\n",
            "Epoch 3426/4000\n",
            "1/1 [==============================] - 0s 46ms/step - loss: 3.1853e-04 - accuracy: 1.0000 - val_loss: 0.4820 - val_accuracy: 0.9143\n",
            "Epoch 3427/4000\n",
            "1/1 [==============================] - 0s 48ms/step - loss: 3.1824e-04 - accuracy: 1.0000 - val_loss: 0.4821 - val_accuracy: 0.9143\n",
            "Epoch 3428/4000\n",
            "1/1 [==============================] - 0s 36ms/step - loss: 3.1795e-04 - accuracy: 1.0000 - val_loss: 0.4821 - val_accuracy: 0.9143\n",
            "Epoch 3429/4000\n",
            "1/1 [==============================] - 0s 36ms/step - loss: 3.1768e-04 - accuracy: 1.0000 - val_loss: 0.4822 - val_accuracy: 0.9143\n",
            "Epoch 3430/4000\n",
            "1/1 [==============================] - 0s 45ms/step - loss: 3.1741e-04 - accuracy: 1.0000 - val_loss: 0.4823 - val_accuracy: 0.9143\n",
            "Epoch 3431/4000\n",
            "1/1 [==============================] - 0s 66ms/step - loss: 3.1712e-04 - accuracy: 1.0000 - val_loss: 0.4823 - val_accuracy: 0.9143\n",
            "Epoch 3432/4000\n",
            "1/1 [==============================] - 0s 51ms/step - loss: 3.1684e-04 - accuracy: 1.0000 - val_loss: 0.4824 - val_accuracy: 0.9143\n",
            "Epoch 3433/4000\n",
            "1/1 [==============================] - 0s 56ms/step - loss: 3.1658e-04 - accuracy: 1.0000 - val_loss: 0.4824 - val_accuracy: 0.9143\n",
            "Epoch 3434/4000\n",
            "1/1 [==============================] - 0s 47ms/step - loss: 3.1630e-04 - accuracy: 1.0000 - val_loss: 0.4825 - val_accuracy: 0.9143\n",
            "Epoch 3435/4000\n",
            "1/1 [==============================] - 0s 48ms/step - loss: 3.1601e-04 - accuracy: 1.0000 - val_loss: 0.4825 - val_accuracy: 0.9143\n",
            "Epoch 3436/4000\n",
            "1/1 [==============================] - 0s 47ms/step - loss: 3.1574e-04 - accuracy: 1.0000 - val_loss: 0.4826 - val_accuracy: 0.9143\n",
            "Epoch 3437/4000\n",
            "1/1 [==============================] - 0s 37ms/step - loss: 3.1548e-04 - accuracy: 1.0000 - val_loss: 0.4827 - val_accuracy: 0.9143\n",
            "Epoch 3438/4000\n",
            "1/1 [==============================] - 0s 51ms/step - loss: 3.1520e-04 - accuracy: 1.0000 - val_loss: 0.4827 - val_accuracy: 0.9143\n",
            "Epoch 3439/4000\n",
            "1/1 [==============================] - 0s 47ms/step - loss: 3.1491e-04 - accuracy: 1.0000 - val_loss: 0.4828 - val_accuracy: 0.9143\n",
            "Epoch 3440/4000\n",
            "1/1 [==============================] - 0s 51ms/step - loss: 3.1464e-04 - accuracy: 1.0000 - val_loss: 0.4828 - val_accuracy: 0.9143\n",
            "Epoch 3441/4000\n",
            "1/1 [==============================] - 0s 52ms/step - loss: 3.1438e-04 - accuracy: 1.0000 - val_loss: 0.4829 - val_accuracy: 0.9143\n",
            "Epoch 3442/4000\n",
            "1/1 [==============================] - 0s 34ms/step - loss: 3.1411e-04 - accuracy: 1.0000 - val_loss: 0.4830 - val_accuracy: 0.9143\n",
            "Epoch 3443/4000\n",
            "1/1 [==============================] - 0s 48ms/step - loss: 3.1383e-04 - accuracy: 1.0000 - val_loss: 0.4830 - val_accuracy: 0.9143\n",
            "Epoch 3444/4000\n",
            "1/1 [==============================] - 0s 50ms/step - loss: 3.1354e-04 - accuracy: 1.0000 - val_loss: 0.4831 - val_accuracy: 0.9143\n",
            "Epoch 3445/4000\n",
            "1/1 [==============================] - 0s 39ms/step - loss: 3.1328e-04 - accuracy: 1.0000 - val_loss: 0.4831 - val_accuracy: 0.9143\n",
            "Epoch 3446/4000\n",
            "1/1 [==============================] - 0s 47ms/step - loss: 3.1302e-04 - accuracy: 1.0000 - val_loss: 0.4832 - val_accuracy: 0.9143\n",
            "Epoch 3447/4000\n",
            "1/1 [==============================] - 0s 49ms/step - loss: 3.1273e-04 - accuracy: 1.0000 - val_loss: 0.4832 - val_accuracy: 0.9143\n",
            "Epoch 3448/4000\n",
            "1/1 [==============================] - 0s 52ms/step - loss: 3.1247e-04 - accuracy: 1.0000 - val_loss: 0.4833 - val_accuracy: 0.9143\n",
            "Epoch 3449/4000\n",
            "1/1 [==============================] - 0s 49ms/step - loss: 3.1221e-04 - accuracy: 1.0000 - val_loss: 0.4834 - val_accuracy: 0.9143\n",
            "Epoch 3450/4000\n",
            "1/1 [==============================] - 0s 51ms/step - loss: 3.1192e-04 - accuracy: 1.0000 - val_loss: 0.4834 - val_accuracy: 0.9143\n",
            "Epoch 3451/4000\n",
            "1/1 [==============================] - 0s 46ms/step - loss: 3.1165e-04 - accuracy: 1.0000 - val_loss: 0.4835 - val_accuracy: 0.9143\n",
            "Epoch 3452/4000\n",
            "1/1 [==============================] - 0s 47ms/step - loss: 3.1139e-04 - accuracy: 1.0000 - val_loss: 0.4835 - val_accuracy: 0.9143\n",
            "Epoch 3453/4000\n",
            "1/1 [==============================] - 0s 50ms/step - loss: 3.1112e-04 - accuracy: 1.0000 - val_loss: 0.4836 - val_accuracy: 0.9143\n",
            "Epoch 3454/4000\n",
            "1/1 [==============================] - 0s 54ms/step - loss: 3.1086e-04 - accuracy: 1.0000 - val_loss: 0.4836 - val_accuracy: 0.9143\n",
            "Epoch 3455/4000\n",
            "1/1 [==============================] - 0s 47ms/step - loss: 3.1057e-04 - accuracy: 1.0000 - val_loss: 0.4837 - val_accuracy: 0.9143\n",
            "Epoch 3456/4000\n",
            "1/1 [==============================] - 0s 49ms/step - loss: 3.1030e-04 - accuracy: 1.0000 - val_loss: 0.4838 - val_accuracy: 0.9143\n",
            "Epoch 3457/4000\n",
            "1/1 [==============================] - 0s 50ms/step - loss: 3.1004e-04 - accuracy: 1.0000 - val_loss: 0.4838 - val_accuracy: 0.9143\n",
            "Epoch 3458/4000\n",
            "1/1 [==============================] - 0s 49ms/step - loss: 3.0978e-04 - accuracy: 1.0000 - val_loss: 0.4839 - val_accuracy: 0.9143\n",
            "Epoch 3459/4000\n",
            "1/1 [==============================] - 0s 48ms/step - loss: 3.0951e-04 - accuracy: 1.0000 - val_loss: 0.4839 - val_accuracy: 0.9143\n",
            "Epoch 3460/4000\n",
            "1/1 [==============================] - 0s 52ms/step - loss: 3.0924e-04 - accuracy: 1.0000 - val_loss: 0.4840 - val_accuracy: 0.9143\n",
            "Epoch 3461/4000\n",
            "1/1 [==============================] - 0s 54ms/step - loss: 3.0896e-04 - accuracy: 1.0000 - val_loss: 0.4840 - val_accuracy: 0.9143\n",
            "Epoch 3462/4000\n",
            "1/1 [==============================] - 0s 46ms/step - loss: 3.0870e-04 - accuracy: 1.0000 - val_loss: 0.4841 - val_accuracy: 0.9143\n",
            "Epoch 3463/4000\n",
            "1/1 [==============================] - 0s 54ms/step - loss: 3.0843e-04 - accuracy: 1.0000 - val_loss: 0.4842 - val_accuracy: 0.9143\n",
            "Epoch 3464/4000\n",
            "1/1 [==============================] - 0s 50ms/step - loss: 3.0816e-04 - accuracy: 1.0000 - val_loss: 0.4842 - val_accuracy: 0.9143\n",
            "Epoch 3465/4000\n",
            "1/1 [==============================] - 0s 47ms/step - loss: 3.0790e-04 - accuracy: 1.0000 - val_loss: 0.4843 - val_accuracy: 0.9143\n",
            "Epoch 3466/4000\n",
            "1/1 [==============================] - 0s 32ms/step - loss: 3.0763e-04 - accuracy: 1.0000 - val_loss: 0.4843 - val_accuracy: 0.9143\n",
            "Epoch 3467/4000\n",
            "1/1 [==============================] - 0s 49ms/step - loss: 3.0736e-04 - accuracy: 1.0000 - val_loss: 0.4844 - val_accuracy: 0.9143\n",
            "Epoch 3468/4000\n",
            "1/1 [==============================] - 0s 50ms/step - loss: 3.0709e-04 - accuracy: 1.0000 - val_loss: 0.4844 - val_accuracy: 0.9143\n",
            "Epoch 3469/4000\n",
            "1/1 [==============================] - 0s 55ms/step - loss: 3.0683e-04 - accuracy: 1.0000 - val_loss: 0.4845 - val_accuracy: 0.9143\n",
            "Epoch 3470/4000\n",
            "1/1 [==============================] - 0s 48ms/step - loss: 3.0656e-04 - accuracy: 1.0000 - val_loss: 0.4846 - val_accuracy: 0.9143\n",
            "Epoch 3471/4000\n",
            "1/1 [==============================] - 0s 47ms/step - loss: 3.0630e-04 - accuracy: 1.0000 - val_loss: 0.4846 - val_accuracy: 0.9143\n",
            "Epoch 3472/4000\n",
            "1/1 [==============================] - 0s 52ms/step - loss: 3.0605e-04 - accuracy: 1.0000 - val_loss: 0.4847 - val_accuracy: 0.9143\n",
            "Epoch 3473/4000\n",
            "1/1 [==============================] - 0s 46ms/step - loss: 3.0578e-04 - accuracy: 1.0000 - val_loss: 0.4847 - val_accuracy: 0.9143\n",
            "Epoch 3474/4000\n",
            "1/1 [==============================] - 0s 39ms/step - loss: 3.0551e-04 - accuracy: 1.0000 - val_loss: 0.4848 - val_accuracy: 0.9143\n",
            "Epoch 3475/4000\n",
            "1/1 [==============================] - 0s 48ms/step - loss: 3.0525e-04 - accuracy: 1.0000 - val_loss: 0.4848 - val_accuracy: 0.9143\n",
            "Epoch 3476/4000\n",
            "1/1 [==============================] - 0s 47ms/step - loss: 3.0500e-04 - accuracy: 1.0000 - val_loss: 0.4849 - val_accuracy: 0.9143\n",
            "Epoch 3477/4000\n",
            "1/1 [==============================] - 0s 40ms/step - loss: 3.0473e-04 - accuracy: 1.0000 - val_loss: 0.4849 - val_accuracy: 0.9143\n",
            "Epoch 3478/4000\n",
            "1/1 [==============================] - 0s 47ms/step - loss: 3.0447e-04 - accuracy: 1.0000 - val_loss: 0.4850 - val_accuracy: 0.9143\n",
            "Epoch 3479/4000\n",
            "1/1 [==============================] - 0s 54ms/step - loss: 3.0420e-04 - accuracy: 1.0000 - val_loss: 0.4851 - val_accuracy: 0.9143\n",
            "Epoch 3480/4000\n",
            "1/1 [==============================] - 0s 35ms/step - loss: 3.0395e-04 - accuracy: 1.0000 - val_loss: 0.4851 - val_accuracy: 0.9143\n",
            "Epoch 3481/4000\n",
            "1/1 [==============================] - 0s 48ms/step - loss: 3.0369e-04 - accuracy: 1.0000 - val_loss: 0.4852 - val_accuracy: 0.9143\n",
            "Epoch 3482/4000\n",
            "1/1 [==============================] - 0s 35ms/step - loss: 3.0340e-04 - accuracy: 1.0000 - val_loss: 0.4852 - val_accuracy: 0.9143\n",
            "Epoch 3483/4000\n",
            "1/1 [==============================] - 0s 34ms/step - loss: 3.0314e-04 - accuracy: 1.0000 - val_loss: 0.4853 - val_accuracy: 0.9143\n",
            "Epoch 3484/4000\n",
            "1/1 [==============================] - 0s 43ms/step - loss: 3.0289e-04 - accuracy: 1.0000 - val_loss: 0.4853 - val_accuracy: 0.9143\n",
            "Epoch 3485/4000\n",
            "1/1 [==============================] - 0s 48ms/step - loss: 3.0264e-04 - accuracy: 1.0000 - val_loss: 0.4854 - val_accuracy: 0.9143\n",
            "Epoch 3486/4000\n",
            "1/1 [==============================] - 0s 41ms/step - loss: 3.0237e-04 - accuracy: 1.0000 - val_loss: 0.4855 - val_accuracy: 0.9143\n",
            "Epoch 3487/4000\n",
            "1/1 [==============================] - 0s 50ms/step - loss: 3.0211e-04 - accuracy: 1.0000 - val_loss: 0.4855 - val_accuracy: 0.9143\n",
            "Epoch 3488/4000\n",
            "1/1 [==============================] - 0s 48ms/step - loss: 3.0186e-04 - accuracy: 1.0000 - val_loss: 0.4856 - val_accuracy: 0.9143\n",
            "Epoch 3489/4000\n",
            "1/1 [==============================] - 0s 43ms/step - loss: 3.0160e-04 - accuracy: 1.0000 - val_loss: 0.4856 - val_accuracy: 0.9143\n",
            "Epoch 3490/4000\n",
            "1/1 [==============================] - 0s 34ms/step - loss: 3.0133e-04 - accuracy: 1.0000 - val_loss: 0.4857 - val_accuracy: 0.9143\n",
            "Epoch 3491/4000\n",
            "1/1 [==============================] - 0s 34ms/step - loss: 3.0106e-04 - accuracy: 1.0000 - val_loss: 0.4857 - val_accuracy: 0.9143\n",
            "Epoch 3492/4000\n",
            "1/1 [==============================] - 0s 48ms/step - loss: 3.0082e-04 - accuracy: 1.0000 - val_loss: 0.4858 - val_accuracy: 0.9143\n",
            "Epoch 3493/4000\n",
            "1/1 [==============================] - 0s 45ms/step - loss: 3.0057e-04 - accuracy: 1.0000 - val_loss: 0.4859 - val_accuracy: 0.9143\n",
            "Epoch 3494/4000\n",
            "1/1 [==============================] - 0s 51ms/step - loss: 3.0030e-04 - accuracy: 1.0000 - val_loss: 0.4859 - val_accuracy: 0.9143\n",
            "Epoch 3495/4000\n",
            "1/1 [==============================] - 0s 47ms/step - loss: 3.0005e-04 - accuracy: 1.0000 - val_loss: 0.4860 - val_accuracy: 0.9143\n",
            "Epoch 3496/4000\n",
            "1/1 [==============================] - 0s 49ms/step - loss: 2.9979e-04 - accuracy: 1.0000 - val_loss: 0.4860 - val_accuracy: 0.9143\n",
            "Epoch 3497/4000\n",
            "1/1 [==============================] - 0s 31ms/step - loss: 2.9954e-04 - accuracy: 1.0000 - val_loss: 0.4861 - val_accuracy: 0.9143\n",
            "Epoch 3498/4000\n",
            "1/1 [==============================] - 0s 50ms/step - loss: 2.9927e-04 - accuracy: 1.0000 - val_loss: 0.4862 - val_accuracy: 0.9143\n",
            "Epoch 3499/4000\n",
            "1/1 [==============================] - 0s 51ms/step - loss: 2.9901e-04 - accuracy: 1.0000 - val_loss: 0.4862 - val_accuracy: 0.9143\n",
            "Epoch 3500/4000\n",
            "1/1 [==============================] - 0s 47ms/step - loss: 2.9876e-04 - accuracy: 1.0000 - val_loss: 0.4863 - val_accuracy: 0.9143\n",
            "Epoch 3501/4000\n",
            "1/1 [==============================] - 0s 49ms/step - loss: 2.9850e-04 - accuracy: 1.0000 - val_loss: 0.4863 - val_accuracy: 0.9143\n",
            "Epoch 3502/4000\n",
            "1/1 [==============================] - 0s 47ms/step - loss: 2.9823e-04 - accuracy: 1.0000 - val_loss: 0.4864 - val_accuracy: 0.9143\n",
            "Epoch 3503/4000\n",
            "1/1 [==============================] - 0s 47ms/step - loss: 2.9798e-04 - accuracy: 1.0000 - val_loss: 0.4864 - val_accuracy: 0.9143\n",
            "Epoch 3504/4000\n",
            "1/1 [==============================] - 0s 52ms/step - loss: 2.9773e-04 - accuracy: 1.0000 - val_loss: 0.4865 - val_accuracy: 0.9143\n",
            "Epoch 3505/4000\n",
            "1/1 [==============================] - 0s 44ms/step - loss: 2.9747e-04 - accuracy: 1.0000 - val_loss: 0.4866 - val_accuracy: 0.9143\n",
            "Epoch 3506/4000\n",
            "1/1 [==============================] - 0s 33ms/step - loss: 2.9722e-04 - accuracy: 1.0000 - val_loss: 0.4866 - val_accuracy: 0.9143\n",
            "Epoch 3507/4000\n",
            "1/1 [==============================] - 0s 34ms/step - loss: 2.9696e-04 - accuracy: 1.0000 - val_loss: 0.4867 - val_accuracy: 0.9143\n",
            "Epoch 3508/4000\n",
            "1/1 [==============================] - 0s 48ms/step - loss: 2.9671e-04 - accuracy: 1.0000 - val_loss: 0.4867 - val_accuracy: 0.9143\n",
            "Epoch 3509/4000\n",
            "1/1 [==============================] - 0s 49ms/step - loss: 2.9645e-04 - accuracy: 1.0000 - val_loss: 0.4868 - val_accuracy: 0.9143\n",
            "Epoch 3510/4000\n",
            "1/1 [==============================] - 0s 49ms/step - loss: 2.9621e-04 - accuracy: 1.0000 - val_loss: 0.4868 - val_accuracy: 0.9143\n",
            "Epoch 3511/4000\n",
            "1/1 [==============================] - 0s 49ms/step - loss: 2.9596e-04 - accuracy: 1.0000 - val_loss: 0.4869 - val_accuracy: 0.9143\n",
            "Epoch 3512/4000\n",
            "1/1 [==============================] - 0s 54ms/step - loss: 2.9571e-04 - accuracy: 1.0000 - val_loss: 0.4869 - val_accuracy: 0.9143\n",
            "Epoch 3513/4000\n",
            "1/1 [==============================] - 0s 47ms/step - loss: 2.9545e-04 - accuracy: 1.0000 - val_loss: 0.4870 - val_accuracy: 0.9143\n",
            "Epoch 3514/4000\n",
            "1/1 [==============================] - 0s 47ms/step - loss: 2.9519e-04 - accuracy: 1.0000 - val_loss: 0.4870 - val_accuracy: 0.9143\n",
            "Epoch 3515/4000\n",
            "1/1 [==============================] - 0s 48ms/step - loss: 2.9494e-04 - accuracy: 1.0000 - val_loss: 0.4871 - val_accuracy: 0.9143\n",
            "Epoch 3516/4000\n",
            "1/1 [==============================] - 0s 52ms/step - loss: 2.9469e-04 - accuracy: 1.0000 - val_loss: 0.4872 - val_accuracy: 0.9143\n",
            "Epoch 3517/4000\n",
            "1/1 [==============================] - 0s 46ms/step - loss: 2.9445e-04 - accuracy: 1.0000 - val_loss: 0.4872 - val_accuracy: 0.9143\n",
            "Epoch 3518/4000\n",
            "1/1 [==============================] - 0s 36ms/step - loss: 2.9420e-04 - accuracy: 1.0000 - val_loss: 0.4873 - val_accuracy: 0.9143\n",
            "Epoch 3519/4000\n",
            "1/1 [==============================] - 0s 50ms/step - loss: 2.9394e-04 - accuracy: 1.0000 - val_loss: 0.4873 - val_accuracy: 0.9143\n",
            "Epoch 3520/4000\n",
            "1/1 [==============================] - 0s 46ms/step - loss: 2.9368e-04 - accuracy: 1.0000 - val_loss: 0.4874 - val_accuracy: 0.9143\n",
            "Epoch 3521/4000\n",
            "1/1 [==============================] - 0s 53ms/step - loss: 2.9343e-04 - accuracy: 1.0000 - val_loss: 0.4874 - val_accuracy: 0.9143\n",
            "Epoch 3522/4000\n",
            "1/1 [==============================] - 0s 46ms/step - loss: 2.9318e-04 - accuracy: 1.0000 - val_loss: 0.4875 - val_accuracy: 0.9143\n",
            "Epoch 3523/4000\n",
            "1/1 [==============================] - 0s 49ms/step - loss: 2.9294e-04 - accuracy: 1.0000 - val_loss: 0.4876 - val_accuracy: 0.9143\n",
            "Epoch 3524/4000\n",
            "1/1 [==============================] - 0s 47ms/step - loss: 2.9269e-04 - accuracy: 1.0000 - val_loss: 0.4876 - val_accuracy: 0.9143\n",
            "Epoch 3525/4000\n",
            "1/1 [==============================] - 0s 46ms/step - loss: 2.9245e-04 - accuracy: 1.0000 - val_loss: 0.4877 - val_accuracy: 0.9143\n",
            "Epoch 3526/4000\n",
            "1/1 [==============================] - 0s 35ms/step - loss: 2.9220e-04 - accuracy: 1.0000 - val_loss: 0.4877 - val_accuracy: 0.9143\n",
            "Epoch 3527/4000\n",
            "1/1 [==============================] - 0s 47ms/step - loss: 2.9193e-04 - accuracy: 1.0000 - val_loss: 0.4878 - val_accuracy: 0.9143\n",
            "Epoch 3528/4000\n",
            "1/1 [==============================] - 0s 56ms/step - loss: 2.9168e-04 - accuracy: 1.0000 - val_loss: 0.4878 - val_accuracy: 0.9143\n",
            "Epoch 3529/4000\n",
            "1/1 [==============================] - 0s 41ms/step - loss: 2.9144e-04 - accuracy: 1.0000 - val_loss: 0.4879 - val_accuracy: 0.9143\n",
            "Epoch 3530/4000\n",
            "1/1 [==============================] - 0s 37ms/step - loss: 2.9119e-04 - accuracy: 1.0000 - val_loss: 0.4879 - val_accuracy: 0.9143\n",
            "Epoch 3531/4000\n",
            "1/1 [==============================] - 0s 49ms/step - loss: 2.9094e-04 - accuracy: 1.0000 - val_loss: 0.4880 - val_accuracy: 0.9143\n",
            "Epoch 3532/4000\n",
            "1/1 [==============================] - 0s 53ms/step - loss: 2.9070e-04 - accuracy: 1.0000 - val_loss: 0.4881 - val_accuracy: 0.9143\n",
            "Epoch 3533/4000\n",
            "1/1 [==============================] - 0s 46ms/step - loss: 2.9044e-04 - accuracy: 1.0000 - val_loss: 0.4881 - val_accuracy: 0.9143\n",
            "Epoch 3534/4000\n",
            "1/1 [==============================] - 0s 58ms/step - loss: 2.9019e-04 - accuracy: 1.0000 - val_loss: 0.4882 - val_accuracy: 0.9143\n",
            "Epoch 3535/4000\n",
            "1/1 [==============================] - 0s 38ms/step - loss: 2.8995e-04 - accuracy: 1.0000 - val_loss: 0.4882 - val_accuracy: 0.9143\n",
            "Epoch 3536/4000\n",
            "1/1 [==============================] - 0s 49ms/step - loss: 2.8972e-04 - accuracy: 1.0000 - val_loss: 0.4883 - val_accuracy: 0.9143\n",
            "Epoch 3537/4000\n",
            "1/1 [==============================] - 0s 46ms/step - loss: 2.8946e-04 - accuracy: 1.0000 - val_loss: 0.4884 - val_accuracy: 0.9143\n",
            "Epoch 3538/4000\n",
            "1/1 [==============================] - 0s 46ms/step - loss: 2.8921e-04 - accuracy: 1.0000 - val_loss: 0.4884 - val_accuracy: 0.9143\n",
            "Epoch 3539/4000\n",
            "1/1 [==============================] - 0s 39ms/step - loss: 2.8896e-04 - accuracy: 1.0000 - val_loss: 0.4885 - val_accuracy: 0.9143\n",
            "Epoch 3540/4000\n",
            "1/1 [==============================] - 0s 47ms/step - loss: 2.8871e-04 - accuracy: 1.0000 - val_loss: 0.4885 - val_accuracy: 0.9143\n",
            "Epoch 3541/4000\n",
            "1/1 [==============================] - 0s 51ms/step - loss: 2.8848e-04 - accuracy: 1.0000 - val_loss: 0.4886 - val_accuracy: 0.9143\n",
            "Epoch 3542/4000\n",
            "1/1 [==============================] - 0s 49ms/step - loss: 2.8823e-04 - accuracy: 1.0000 - val_loss: 0.4886 - val_accuracy: 0.9143\n",
            "Epoch 3543/4000\n",
            "1/1 [==============================] - 0s 36ms/step - loss: 2.8797e-04 - accuracy: 1.0000 - val_loss: 0.4887 - val_accuracy: 0.9143\n",
            "Epoch 3544/4000\n",
            "1/1 [==============================] - 0s 41ms/step - loss: 2.8773e-04 - accuracy: 1.0000 - val_loss: 0.4887 - val_accuracy: 0.9143\n",
            "Epoch 3545/4000\n",
            "1/1 [==============================] - 0s 47ms/step - loss: 2.8749e-04 - accuracy: 1.0000 - val_loss: 0.4888 - val_accuracy: 0.9143\n",
            "Epoch 3546/4000\n",
            "1/1 [==============================] - 0s 52ms/step - loss: 2.8725e-04 - accuracy: 1.0000 - val_loss: 0.4889 - val_accuracy: 0.9143\n",
            "Epoch 3547/4000\n",
            "1/1 [==============================] - 0s 49ms/step - loss: 2.8700e-04 - accuracy: 1.0000 - val_loss: 0.4889 - val_accuracy: 0.9143\n",
            "Epoch 3548/4000\n",
            "1/1 [==============================] - 0s 56ms/step - loss: 2.8676e-04 - accuracy: 1.0000 - val_loss: 0.4890 - val_accuracy: 0.9143\n",
            "Epoch 3549/4000\n",
            "1/1 [==============================] - 0s 57ms/step - loss: 2.8651e-04 - accuracy: 1.0000 - val_loss: 0.4890 - val_accuracy: 0.9143\n",
            "Epoch 3550/4000\n",
            "1/1 [==============================] - 0s 44ms/step - loss: 2.8627e-04 - accuracy: 1.0000 - val_loss: 0.4891 - val_accuracy: 0.9143\n",
            "Epoch 3551/4000\n",
            "1/1 [==============================] - 0s 55ms/step - loss: 2.8603e-04 - accuracy: 1.0000 - val_loss: 0.4891 - val_accuracy: 0.9143\n",
            "Epoch 3552/4000\n",
            "1/1 [==============================] - 0s 51ms/step - loss: 2.8578e-04 - accuracy: 1.0000 - val_loss: 0.4892 - val_accuracy: 0.9143\n",
            "Epoch 3553/4000\n",
            "1/1 [==============================] - 0s 37ms/step - loss: 2.8556e-04 - accuracy: 1.0000 - val_loss: 0.4892 - val_accuracy: 0.9143\n",
            "Epoch 3554/4000\n",
            "1/1 [==============================] - 0s 40ms/step - loss: 2.8531e-04 - accuracy: 1.0000 - val_loss: 0.4893 - val_accuracy: 0.9143\n",
            "Epoch 3555/4000\n",
            "1/1 [==============================] - 0s 50ms/step - loss: 2.8507e-04 - accuracy: 1.0000 - val_loss: 0.4894 - val_accuracy: 0.9143\n",
            "Epoch 3556/4000\n",
            "1/1 [==============================] - 0s 61ms/step - loss: 2.8483e-04 - accuracy: 1.0000 - val_loss: 0.4894 - val_accuracy: 0.9143\n",
            "Epoch 3557/4000\n",
            "1/1 [==============================] - 0s 56ms/step - loss: 2.8459e-04 - accuracy: 1.0000 - val_loss: 0.4895 - val_accuracy: 0.9143\n",
            "Epoch 3558/4000\n",
            "1/1 [==============================] - 0s 53ms/step - loss: 2.8435e-04 - accuracy: 1.0000 - val_loss: 0.4895 - val_accuracy: 0.9143\n",
            "Epoch 3559/4000\n",
            "1/1 [==============================] - 0s 57ms/step - loss: 2.8411e-04 - accuracy: 1.0000 - val_loss: 0.4896 - val_accuracy: 0.9143\n",
            "Epoch 3560/4000\n",
            "1/1 [==============================] - 0s 51ms/step - loss: 2.8387e-04 - accuracy: 1.0000 - val_loss: 0.4896 - val_accuracy: 0.9143\n",
            "Epoch 3561/4000\n",
            "1/1 [==============================] - 0s 56ms/step - loss: 2.8361e-04 - accuracy: 1.0000 - val_loss: 0.4897 - val_accuracy: 0.9143\n",
            "Epoch 3562/4000\n",
            "1/1 [==============================] - 0s 44ms/step - loss: 2.8337e-04 - accuracy: 1.0000 - val_loss: 0.4898 - val_accuracy: 0.9143\n",
            "Epoch 3563/4000\n",
            "1/1 [==============================] - 0s 50ms/step - loss: 2.8314e-04 - accuracy: 1.0000 - val_loss: 0.4898 - val_accuracy: 0.9143\n",
            "Epoch 3564/4000\n",
            "1/1 [==============================] - 0s 50ms/step - loss: 2.8290e-04 - accuracy: 1.0000 - val_loss: 0.4899 - val_accuracy: 0.9143\n",
            "Epoch 3565/4000\n",
            "1/1 [==============================] - 0s 47ms/step - loss: 2.8267e-04 - accuracy: 1.0000 - val_loss: 0.4899 - val_accuracy: 0.9143\n",
            "Epoch 3566/4000\n",
            "1/1 [==============================] - 0s 43ms/step - loss: 2.8243e-04 - accuracy: 1.0000 - val_loss: 0.4900 - val_accuracy: 0.9143\n",
            "Epoch 3567/4000\n",
            "1/1 [==============================] - 0s 36ms/step - loss: 2.8217e-04 - accuracy: 1.0000 - val_loss: 0.4900 - val_accuracy: 0.9143\n",
            "Epoch 3568/4000\n",
            "1/1 [==============================] - 0s 41ms/step - loss: 2.8193e-04 - accuracy: 1.0000 - val_loss: 0.4901 - val_accuracy: 0.9143\n",
            "Epoch 3569/4000\n",
            "1/1 [==============================] - 0s 48ms/step - loss: 2.8169e-04 - accuracy: 1.0000 - val_loss: 0.4901 - val_accuracy: 0.9143\n",
            "Epoch 3570/4000\n",
            "1/1 [==============================] - 0s 32ms/step - loss: 2.8147e-04 - accuracy: 1.0000 - val_loss: 0.4902 - val_accuracy: 0.9143\n",
            "Epoch 3571/4000\n",
            "1/1 [==============================] - 0s 46ms/step - loss: 2.8123e-04 - accuracy: 1.0000 - val_loss: 0.4902 - val_accuracy: 0.9143\n",
            "Epoch 3572/4000\n",
            "1/1 [==============================] - 0s 47ms/step - loss: 2.8098e-04 - accuracy: 1.0000 - val_loss: 0.4903 - val_accuracy: 0.9143\n",
            "Epoch 3573/4000\n",
            "1/1 [==============================] - 0s 35ms/step - loss: 2.8073e-04 - accuracy: 1.0000 - val_loss: 0.4904 - val_accuracy: 0.9143\n",
            "Epoch 3574/4000\n",
            "1/1 [==============================] - 0s 52ms/step - loss: 2.8050e-04 - accuracy: 1.0000 - val_loss: 0.4904 - val_accuracy: 0.9143\n",
            "Epoch 3575/4000\n",
            "1/1 [==============================] - 0s 50ms/step - loss: 2.8027e-04 - accuracy: 1.0000 - val_loss: 0.4905 - val_accuracy: 0.9143\n",
            "Epoch 3576/4000\n",
            "1/1 [==============================] - 0s 48ms/step - loss: 2.8004e-04 - accuracy: 1.0000 - val_loss: 0.4905 - val_accuracy: 0.9143\n",
            "Epoch 3577/4000\n",
            "1/1 [==============================] - 0s 46ms/step - loss: 2.7981e-04 - accuracy: 1.0000 - val_loss: 0.4906 - val_accuracy: 0.9143\n",
            "Epoch 3578/4000\n",
            "1/1 [==============================] - 0s 51ms/step - loss: 2.7957e-04 - accuracy: 1.0000 - val_loss: 0.4906 - val_accuracy: 0.9143\n",
            "Epoch 3579/4000\n",
            "1/1 [==============================] - 0s 36ms/step - loss: 2.7932e-04 - accuracy: 1.0000 - val_loss: 0.4907 - val_accuracy: 0.9143\n",
            "Epoch 3580/4000\n",
            "1/1 [==============================] - 0s 55ms/step - loss: 2.7910e-04 - accuracy: 1.0000 - val_loss: 0.4907 - val_accuracy: 0.9143\n",
            "Epoch 3581/4000\n",
            "1/1 [==============================] - 0s 49ms/step - loss: 2.7885e-04 - accuracy: 1.0000 - val_loss: 0.4908 - val_accuracy: 0.9143\n",
            "Epoch 3582/4000\n",
            "1/1 [==============================] - 0s 50ms/step - loss: 2.7861e-04 - accuracy: 1.0000 - val_loss: 0.4909 - val_accuracy: 0.9143\n",
            "Epoch 3583/4000\n",
            "1/1 [==============================] - 0s 53ms/step - loss: 2.7838e-04 - accuracy: 1.0000 - val_loss: 0.4909 - val_accuracy: 0.9143\n",
            "Epoch 3584/4000\n",
            "1/1 [==============================] - 0s 54ms/step - loss: 2.7814e-04 - accuracy: 1.0000 - val_loss: 0.4910 - val_accuracy: 0.9143\n",
            "Epoch 3585/4000\n",
            "1/1 [==============================] - 0s 54ms/step - loss: 2.7791e-04 - accuracy: 1.0000 - val_loss: 0.4910 - val_accuracy: 0.9143\n",
            "Epoch 3586/4000\n",
            "1/1 [==============================] - 0s 50ms/step - loss: 2.7767e-04 - accuracy: 1.0000 - val_loss: 0.4911 - val_accuracy: 0.9143\n",
            "Epoch 3587/4000\n",
            "1/1 [==============================] - 0s 50ms/step - loss: 2.7744e-04 - accuracy: 1.0000 - val_loss: 0.4911 - val_accuracy: 0.9143\n",
            "Epoch 3588/4000\n",
            "1/1 [==============================] - 0s 52ms/step - loss: 2.7721e-04 - accuracy: 1.0000 - val_loss: 0.4912 - val_accuracy: 0.9143\n",
            "Epoch 3589/4000\n",
            "1/1 [==============================] - 0s 45ms/step - loss: 2.7699e-04 - accuracy: 1.0000 - val_loss: 0.4913 - val_accuracy: 0.9143\n",
            "Epoch 3590/4000\n",
            "1/1 [==============================] - 0s 56ms/step - loss: 2.7675e-04 - accuracy: 1.0000 - val_loss: 0.4913 - val_accuracy: 0.9143\n",
            "Epoch 3591/4000\n",
            "1/1 [==============================] - 0s 34ms/step - loss: 2.7651e-04 - accuracy: 1.0000 - val_loss: 0.4914 - val_accuracy: 0.9143\n",
            "Epoch 3592/4000\n",
            "1/1 [==============================] - 0s 49ms/step - loss: 2.7629e-04 - accuracy: 1.0000 - val_loss: 0.4914 - val_accuracy: 0.9143\n",
            "Epoch 3593/4000\n",
            "1/1 [==============================] - 0s 52ms/step - loss: 2.7606e-04 - accuracy: 1.0000 - val_loss: 0.4915 - val_accuracy: 0.9143\n",
            "Epoch 3594/4000\n",
            "1/1 [==============================] - 0s 50ms/step - loss: 2.7583e-04 - accuracy: 1.0000 - val_loss: 0.4915 - val_accuracy: 0.9143\n",
            "Epoch 3595/4000\n",
            "1/1 [==============================] - 0s 51ms/step - loss: 2.7560e-04 - accuracy: 1.0000 - val_loss: 0.4916 - val_accuracy: 0.9143\n",
            "Epoch 3596/4000\n",
            "1/1 [==============================] - 0s 37ms/step - loss: 2.7535e-04 - accuracy: 1.0000 - val_loss: 0.4916 - val_accuracy: 0.9143\n",
            "Epoch 3597/4000\n",
            "1/1 [==============================] - 0s 34ms/step - loss: 2.7512e-04 - accuracy: 1.0000 - val_loss: 0.4917 - val_accuracy: 0.9143\n",
            "Epoch 3598/4000\n",
            "1/1 [==============================] - 0s 49ms/step - loss: 2.7490e-04 - accuracy: 1.0000 - val_loss: 0.4918 - val_accuracy: 0.9143\n",
            "Epoch 3599/4000\n",
            "1/1 [==============================] - 0s 32ms/step - loss: 2.7467e-04 - accuracy: 1.0000 - val_loss: 0.4918 - val_accuracy: 0.9143\n",
            "Epoch 3600/4000\n",
            "1/1 [==============================] - 0s 46ms/step - loss: 2.7443e-04 - accuracy: 1.0000 - val_loss: 0.4919 - val_accuracy: 0.9143\n",
            "Epoch 3601/4000\n",
            "1/1 [==============================] - 0s 50ms/step - loss: 2.7419e-04 - accuracy: 1.0000 - val_loss: 0.4919 - val_accuracy: 0.9143\n",
            "Epoch 3602/4000\n",
            "1/1 [==============================] - 0s 38ms/step - loss: 2.7396e-04 - accuracy: 1.0000 - val_loss: 0.4920 - val_accuracy: 0.9143\n",
            "Epoch 3603/4000\n",
            "1/1 [==============================] - 0s 38ms/step - loss: 2.7374e-04 - accuracy: 1.0000 - val_loss: 0.4920 - val_accuracy: 0.9143\n",
            "Epoch 3604/4000\n",
            "1/1 [==============================] - 0s 51ms/step - loss: 2.7352e-04 - accuracy: 1.0000 - val_loss: 0.4921 - val_accuracy: 0.9143\n",
            "Epoch 3605/4000\n",
            "1/1 [==============================] - 0s 33ms/step - loss: 2.7328e-04 - accuracy: 1.0000 - val_loss: 0.4921 - val_accuracy: 0.9143\n",
            "Epoch 3606/4000\n",
            "1/1 [==============================] - 0s 47ms/step - loss: 2.7304e-04 - accuracy: 1.0000 - val_loss: 0.4922 - val_accuracy: 0.9143\n",
            "Epoch 3607/4000\n",
            "1/1 [==============================] - 0s 47ms/step - loss: 2.7281e-04 - accuracy: 1.0000 - val_loss: 0.4923 - val_accuracy: 0.9143\n",
            "Epoch 3608/4000\n",
            "1/1 [==============================] - 0s 47ms/step - loss: 2.7259e-04 - accuracy: 1.0000 - val_loss: 0.4923 - val_accuracy: 0.9143\n",
            "Epoch 3609/4000\n",
            "1/1 [==============================] - 0s 46ms/step - loss: 2.7237e-04 - accuracy: 1.0000 - val_loss: 0.4924 - val_accuracy: 0.9143\n",
            "Epoch 3610/4000\n",
            "1/1 [==============================] - 0s 51ms/step - loss: 2.7214e-04 - accuracy: 1.0000 - val_loss: 0.4924 - val_accuracy: 0.9143\n",
            "Epoch 3611/4000\n",
            "1/1 [==============================] - 0s 62ms/step - loss: 2.7190e-04 - accuracy: 1.0000 - val_loss: 0.4925 - val_accuracy: 0.9143\n",
            "Epoch 3612/4000\n",
            "1/1 [==============================] - 0s 46ms/step - loss: 2.7166e-04 - accuracy: 1.0000 - val_loss: 0.4925 - val_accuracy: 0.9143\n",
            "Epoch 3613/4000\n",
            "1/1 [==============================] - 0s 49ms/step - loss: 2.7145e-04 - accuracy: 1.0000 - val_loss: 0.4926 - val_accuracy: 0.9143\n",
            "Epoch 3614/4000\n",
            "1/1 [==============================] - 0s 51ms/step - loss: 2.7124e-04 - accuracy: 1.0000 - val_loss: 0.4926 - val_accuracy: 0.9143\n",
            "Epoch 3615/4000\n",
            "1/1 [==============================] - 0s 49ms/step - loss: 2.7101e-04 - accuracy: 1.0000 - val_loss: 0.4927 - val_accuracy: 0.9143\n",
            "Epoch 3616/4000\n",
            "1/1 [==============================] - 0s 47ms/step - loss: 2.7077e-04 - accuracy: 1.0000 - val_loss: 0.4928 - val_accuracy: 0.9143\n",
            "Epoch 3617/4000\n",
            "1/1 [==============================] - 0s 33ms/step - loss: 2.7053e-04 - accuracy: 1.0000 - val_loss: 0.4928 - val_accuracy: 0.9143\n",
            "Epoch 3618/4000\n",
            "1/1 [==============================] - 0s 52ms/step - loss: 2.7031e-04 - accuracy: 1.0000 - val_loss: 0.4929 - val_accuracy: 0.9143\n",
            "Epoch 3619/4000\n",
            "1/1 [==============================] - 0s 49ms/step - loss: 2.7010e-04 - accuracy: 1.0000 - val_loss: 0.4929 - val_accuracy: 0.9143\n",
            "Epoch 3620/4000\n",
            "1/1 [==============================] - 0s 50ms/step - loss: 2.6987e-04 - accuracy: 1.0000 - val_loss: 0.4930 - val_accuracy: 0.9143\n",
            "Epoch 3621/4000\n",
            "1/1 [==============================] - 0s 37ms/step - loss: 2.6964e-04 - accuracy: 1.0000 - val_loss: 0.4930 - val_accuracy: 0.9143\n",
            "Epoch 3622/4000\n",
            "1/1 [==============================] - 0s 46ms/step - loss: 2.6940e-04 - accuracy: 1.0000 - val_loss: 0.4931 - val_accuracy: 0.9143\n",
            "Epoch 3623/4000\n",
            "1/1 [==============================] - 0s 60ms/step - loss: 2.6919e-04 - accuracy: 1.0000 - val_loss: 0.4931 - val_accuracy: 0.9143\n",
            "Epoch 3624/4000\n",
            "1/1 [==============================] - 0s 49ms/step - loss: 2.6896e-04 - accuracy: 1.0000 - val_loss: 0.4932 - val_accuracy: 0.9143\n",
            "Epoch 3625/4000\n",
            "1/1 [==============================] - 0s 36ms/step - loss: 2.6873e-04 - accuracy: 1.0000 - val_loss: 0.4932 - val_accuracy: 0.9143\n",
            "Epoch 3626/4000\n",
            "1/1 [==============================] - 0s 48ms/step - loss: 2.6851e-04 - accuracy: 1.0000 - val_loss: 0.4933 - val_accuracy: 0.9143\n",
            "Epoch 3627/4000\n",
            "1/1 [==============================] - 0s 47ms/step - loss: 2.6828e-04 - accuracy: 1.0000 - val_loss: 0.4934 - val_accuracy: 0.9143\n",
            "Epoch 3628/4000\n",
            "1/1 [==============================] - 0s 42ms/step - loss: 2.6806e-04 - accuracy: 1.0000 - val_loss: 0.4934 - val_accuracy: 0.9143\n",
            "Epoch 3629/4000\n",
            "1/1 [==============================] - 0s 39ms/step - loss: 2.6784e-04 - accuracy: 1.0000 - val_loss: 0.4935 - val_accuracy: 0.9143\n",
            "Epoch 3630/4000\n",
            "1/1 [==============================] - 0s 47ms/step - loss: 2.6761e-04 - accuracy: 1.0000 - val_loss: 0.4935 - val_accuracy: 0.9143\n",
            "Epoch 3631/4000\n",
            "1/1 [==============================] - 0s 50ms/step - loss: 2.6739e-04 - accuracy: 1.0000 - val_loss: 0.4936 - val_accuracy: 0.9143\n",
            "Epoch 3632/4000\n",
            "1/1 [==============================] - 0s 54ms/step - loss: 2.6717e-04 - accuracy: 1.0000 - val_loss: 0.4936 - val_accuracy: 0.9143\n",
            "Epoch 3633/4000\n",
            "1/1 [==============================] - 0s 48ms/step - loss: 2.6694e-04 - accuracy: 1.0000 - val_loss: 0.4937 - val_accuracy: 0.9143\n",
            "Epoch 3634/4000\n",
            "1/1 [==============================] - 0s 39ms/step - loss: 2.6673e-04 - accuracy: 1.0000 - val_loss: 0.4937 - val_accuracy: 0.9143\n",
            "Epoch 3635/4000\n",
            "1/1 [==============================] - 0s 48ms/step - loss: 2.6651e-04 - accuracy: 1.0000 - val_loss: 0.4938 - val_accuracy: 0.9143\n",
            "Epoch 3636/4000\n",
            "1/1 [==============================] - 0s 35ms/step - loss: 2.6627e-04 - accuracy: 1.0000 - val_loss: 0.4939 - val_accuracy: 0.9143\n",
            "Epoch 3637/4000\n",
            "1/1 [==============================] - 0s 32ms/step - loss: 2.6605e-04 - accuracy: 1.0000 - val_loss: 0.4939 - val_accuracy: 0.9143\n",
            "Epoch 3638/4000\n",
            "1/1 [==============================] - 0s 47ms/step - loss: 2.6585e-04 - accuracy: 1.0000 - val_loss: 0.4940 - val_accuracy: 0.9143\n",
            "Epoch 3639/4000\n",
            "1/1 [==============================] - 0s 49ms/step - loss: 2.6562e-04 - accuracy: 1.0000 - val_loss: 0.4940 - val_accuracy: 0.9143\n",
            "Epoch 3640/4000\n",
            "1/1 [==============================] - 0s 44ms/step - loss: 2.6538e-04 - accuracy: 1.0000 - val_loss: 0.4941 - val_accuracy: 0.9143\n",
            "Epoch 3641/4000\n",
            "1/1 [==============================] - 0s 51ms/step - loss: 2.6516e-04 - accuracy: 1.0000 - val_loss: 0.4941 - val_accuracy: 0.9143\n",
            "Epoch 3642/4000\n",
            "1/1 [==============================] - 0s 48ms/step - loss: 2.6496e-04 - accuracy: 1.0000 - val_loss: 0.4942 - val_accuracy: 0.9143\n",
            "Epoch 3643/4000\n",
            "1/1 [==============================] - 0s 48ms/step - loss: 2.6473e-04 - accuracy: 1.0000 - val_loss: 0.4942 - val_accuracy: 0.9143\n",
            "Epoch 3644/4000\n",
            "1/1 [==============================] - 0s 56ms/step - loss: 2.6450e-04 - accuracy: 1.0000 - val_loss: 0.4943 - val_accuracy: 0.9143\n",
            "Epoch 3645/4000\n",
            "1/1 [==============================] - 0s 50ms/step - loss: 2.6429e-04 - accuracy: 1.0000 - val_loss: 0.4943 - val_accuracy: 0.9143\n",
            "Epoch 3646/4000\n",
            "1/1 [==============================] - 0s 64ms/step - loss: 2.6408e-04 - accuracy: 1.0000 - val_loss: 0.4944 - val_accuracy: 0.9143\n",
            "Epoch 3647/4000\n",
            "1/1 [==============================] - 0s 34ms/step - loss: 2.6385e-04 - accuracy: 1.0000 - val_loss: 0.4945 - val_accuracy: 0.9143\n",
            "Epoch 3648/4000\n",
            "1/1 [==============================] - 0s 50ms/step - loss: 2.6362e-04 - accuracy: 1.0000 - val_loss: 0.4945 - val_accuracy: 0.9143\n",
            "Epoch 3649/4000\n",
            "1/1 [==============================] - 0s 46ms/step - loss: 2.6340e-04 - accuracy: 1.0000 - val_loss: 0.4946 - val_accuracy: 0.9143\n",
            "Epoch 3650/4000\n",
            "1/1 [==============================] - 0s 49ms/step - loss: 2.6319e-04 - accuracy: 1.0000 - val_loss: 0.4946 - val_accuracy: 0.9143\n",
            "Epoch 3651/4000\n",
            "1/1 [==============================] - 0s 37ms/step - loss: 2.6297e-04 - accuracy: 1.0000 - val_loss: 0.4947 - val_accuracy: 0.9143\n",
            "Epoch 3652/4000\n",
            "1/1 [==============================] - 0s 38ms/step - loss: 2.6275e-04 - accuracy: 1.0000 - val_loss: 0.4947 - val_accuracy: 0.9143\n",
            "Epoch 3653/4000\n",
            "1/1 [==============================] - 0s 43ms/step - loss: 2.6253e-04 - accuracy: 1.0000 - val_loss: 0.4948 - val_accuracy: 0.9143\n",
            "Epoch 3654/4000\n",
            "1/1 [==============================] - 0s 53ms/step - loss: 2.6232e-04 - accuracy: 1.0000 - val_loss: 0.4948 - val_accuracy: 0.9143\n",
            "Epoch 3655/4000\n",
            "1/1 [==============================] - 0s 54ms/step - loss: 2.6211e-04 - accuracy: 1.0000 - val_loss: 0.4949 - val_accuracy: 0.9143\n",
            "Epoch 3656/4000\n",
            "1/1 [==============================] - 0s 47ms/step - loss: 2.6188e-04 - accuracy: 1.0000 - val_loss: 0.4950 - val_accuracy: 0.9143\n",
            "Epoch 3657/4000\n",
            "1/1 [==============================] - 0s 51ms/step - loss: 2.6165e-04 - accuracy: 1.0000 - val_loss: 0.4950 - val_accuracy: 0.9143\n",
            "Epoch 3658/4000\n",
            "1/1 [==============================] - 0s 47ms/step - loss: 2.6144e-04 - accuracy: 1.0000 - val_loss: 0.4950 - val_accuracy: 0.9143\n",
            "Epoch 3659/4000\n",
            "1/1 [==============================] - 0s 34ms/step - loss: 2.6122e-04 - accuracy: 1.0000 - val_loss: 0.4951 - val_accuracy: 0.9143\n",
            "Epoch 3660/4000\n",
            "1/1 [==============================] - 0s 34ms/step - loss: 2.6100e-04 - accuracy: 1.0000 - val_loss: 0.4952 - val_accuracy: 0.9143\n",
            "Epoch 3661/4000\n",
            "1/1 [==============================] - 0s 44ms/step - loss: 2.6078e-04 - accuracy: 1.0000 - val_loss: 0.4952 - val_accuracy: 0.9143\n",
            "Epoch 3662/4000\n",
            "1/1 [==============================] - 0s 51ms/step - loss: 2.6056e-04 - accuracy: 1.0000 - val_loss: 0.4953 - val_accuracy: 0.9143\n",
            "Epoch 3663/4000\n",
            "1/1 [==============================] - 0s 47ms/step - loss: 2.6035e-04 - accuracy: 1.0000 - val_loss: 0.4953 - val_accuracy: 0.9143\n",
            "Epoch 3664/4000\n",
            "1/1 [==============================] - 0s 50ms/step - loss: 2.6015e-04 - accuracy: 1.0000 - val_loss: 0.4954 - val_accuracy: 0.9143\n",
            "Epoch 3665/4000\n",
            "1/1 [==============================] - 0s 52ms/step - loss: 2.5993e-04 - accuracy: 1.0000 - val_loss: 0.4954 - val_accuracy: 0.9143\n",
            "Epoch 3666/4000\n",
            "1/1 [==============================] - 0s 48ms/step - loss: 2.5970e-04 - accuracy: 1.0000 - val_loss: 0.4955 - val_accuracy: 0.9143\n",
            "Epoch 3667/4000\n",
            "1/1 [==============================] - 0s 47ms/step - loss: 2.5949e-04 - accuracy: 1.0000 - val_loss: 0.4955 - val_accuracy: 0.9143\n",
            "Epoch 3668/4000\n",
            "1/1 [==============================] - 0s 49ms/step - loss: 2.5927e-04 - accuracy: 1.0000 - val_loss: 0.4956 - val_accuracy: 0.9143\n",
            "Epoch 3669/4000\n",
            "1/1 [==============================] - 0s 48ms/step - loss: 2.5906e-04 - accuracy: 1.0000 - val_loss: 0.4957 - val_accuracy: 0.9143\n",
            "Epoch 3670/4000\n",
            "1/1 [==============================] - 0s 47ms/step - loss: 2.5884e-04 - accuracy: 1.0000 - val_loss: 0.4957 - val_accuracy: 0.9143\n",
            "Epoch 3671/4000\n",
            "1/1 [==============================] - 0s 51ms/step - loss: 2.5862e-04 - accuracy: 1.0000 - val_loss: 0.4958 - val_accuracy: 0.9143\n",
            "Epoch 3672/4000\n",
            "1/1 [==============================] - 0s 46ms/step - loss: 2.5842e-04 - accuracy: 1.0000 - val_loss: 0.4958 - val_accuracy: 0.9143\n",
            "Epoch 3673/4000\n",
            "1/1 [==============================] - 0s 38ms/step - loss: 2.5821e-04 - accuracy: 1.0000 - val_loss: 0.4959 - val_accuracy: 0.9143\n",
            "Epoch 3674/4000\n",
            "1/1 [==============================] - 0s 52ms/step - loss: 2.5798e-04 - accuracy: 1.0000 - val_loss: 0.4959 - val_accuracy: 0.9143\n",
            "Epoch 3675/4000\n",
            "1/1 [==============================] - 0s 47ms/step - loss: 2.5776e-04 - accuracy: 1.0000 - val_loss: 0.4960 - val_accuracy: 0.9143\n",
            "Epoch 3676/4000\n",
            "1/1 [==============================] - 0s 46ms/step - loss: 2.5757e-04 - accuracy: 1.0000 - val_loss: 0.4960 - val_accuracy: 0.9143\n",
            "Epoch 3677/4000\n",
            "1/1 [==============================] - 0s 59ms/step - loss: 2.5736e-04 - accuracy: 1.0000 - val_loss: 0.4961 - val_accuracy: 0.9143\n",
            "Epoch 3678/4000\n",
            "1/1 [==============================] - 0s 50ms/step - loss: 2.5714e-04 - accuracy: 1.0000 - val_loss: 0.4961 - val_accuracy: 0.9143\n",
            "Epoch 3679/4000\n",
            "1/1 [==============================] - 0s 52ms/step - loss: 2.5692e-04 - accuracy: 1.0000 - val_loss: 0.4962 - val_accuracy: 0.9143\n",
            "Epoch 3680/4000\n",
            "1/1 [==============================] - 0s 46ms/step - loss: 2.5670e-04 - accuracy: 1.0000 - val_loss: 0.4963 - val_accuracy: 0.9143\n",
            "Epoch 3681/4000\n",
            "1/1 [==============================] - 0s 48ms/step - loss: 2.5650e-04 - accuracy: 1.0000 - val_loss: 0.4963 - val_accuracy: 0.9143\n",
            "Epoch 3682/4000\n",
            "1/1 [==============================] - 0s 47ms/step - loss: 2.5629e-04 - accuracy: 1.0000 - val_loss: 0.4964 - val_accuracy: 0.9143\n",
            "Epoch 3683/4000\n",
            "1/1 [==============================] - 0s 38ms/step - loss: 2.5606e-04 - accuracy: 1.0000 - val_loss: 0.4964 - val_accuracy: 0.9143\n",
            "Epoch 3684/4000\n",
            "1/1 [==============================] - 0s 55ms/step - loss: 2.5585e-04 - accuracy: 1.0000 - val_loss: 0.4965 - val_accuracy: 0.9143\n",
            "Epoch 3685/4000\n",
            "1/1 [==============================] - 0s 36ms/step - loss: 2.5564e-04 - accuracy: 1.0000 - val_loss: 0.4965 - val_accuracy: 0.9143\n",
            "Epoch 3686/4000\n",
            "1/1 [==============================] - 0s 54ms/step - loss: 2.5543e-04 - accuracy: 1.0000 - val_loss: 0.4966 - val_accuracy: 0.9143\n",
            "Epoch 3687/4000\n",
            "1/1 [==============================] - 0s 47ms/step - loss: 2.5523e-04 - accuracy: 1.0000 - val_loss: 0.4966 - val_accuracy: 0.9143\n",
            "Epoch 3688/4000\n",
            "1/1 [==============================] - 0s 48ms/step - loss: 2.5502e-04 - accuracy: 1.0000 - val_loss: 0.4967 - val_accuracy: 0.9143\n",
            "Epoch 3689/4000\n",
            "1/1 [==============================] - 0s 56ms/step - loss: 2.5480e-04 - accuracy: 1.0000 - val_loss: 0.4967 - val_accuracy: 0.9143\n",
            "Epoch 3690/4000\n",
            "1/1 [==============================] - 0s 49ms/step - loss: 2.5460e-04 - accuracy: 1.0000 - val_loss: 0.4968 - val_accuracy: 0.9143\n",
            "Epoch 3691/4000\n",
            "1/1 [==============================] - 0s 46ms/step - loss: 2.5440e-04 - accuracy: 1.0000 - val_loss: 0.4968 - val_accuracy: 0.9143\n",
            "Epoch 3692/4000\n",
            "1/1 [==============================] - 0s 50ms/step - loss: 2.5419e-04 - accuracy: 1.0000 - val_loss: 0.4969 - val_accuracy: 0.9143\n",
            "Epoch 3693/4000\n",
            "1/1 [==============================] - 0s 49ms/step - loss: 2.5398e-04 - accuracy: 1.0000 - val_loss: 0.4970 - val_accuracy: 0.9143\n",
            "Epoch 3694/4000\n",
            "1/1 [==============================] - 0s 47ms/step - loss: 2.5377e-04 - accuracy: 1.0000 - val_loss: 0.4970 - val_accuracy: 0.9143\n",
            "Epoch 3695/4000\n",
            "1/1 [==============================] - 0s 50ms/step - loss: 2.5356e-04 - accuracy: 1.0000 - val_loss: 0.4971 - val_accuracy: 0.9143\n",
            "Epoch 3696/4000\n",
            "1/1 [==============================] - 0s 34ms/step - loss: 2.5335e-04 - accuracy: 1.0000 - val_loss: 0.4971 - val_accuracy: 0.9143\n",
            "Epoch 3697/4000\n",
            "1/1 [==============================] - 0s 50ms/step - loss: 2.5314e-04 - accuracy: 1.0000 - val_loss: 0.4972 - val_accuracy: 0.9143\n",
            "Epoch 3698/4000\n",
            "1/1 [==============================] - 0s 65ms/step - loss: 2.5293e-04 - accuracy: 1.0000 - val_loss: 0.4972 - val_accuracy: 0.9143\n",
            "Epoch 3699/4000\n",
            "1/1 [==============================] - 0s 47ms/step - loss: 2.5272e-04 - accuracy: 1.0000 - val_loss: 0.4973 - val_accuracy: 0.9143\n",
            "Epoch 3700/4000\n",
            "1/1 [==============================] - 0s 36ms/step - loss: 2.5251e-04 - accuracy: 1.0000 - val_loss: 0.4973 - val_accuracy: 0.9143\n",
            "Epoch 3701/4000\n",
            "1/1 [==============================] - 0s 46ms/step - loss: 2.5229e-04 - accuracy: 1.0000 - val_loss: 0.4974 - val_accuracy: 0.9143\n",
            "Epoch 3702/4000\n",
            "1/1 [==============================] - 0s 47ms/step - loss: 2.5208e-04 - accuracy: 1.0000 - val_loss: 0.4975 - val_accuracy: 0.9143\n",
            "Epoch 3703/4000\n",
            "1/1 [==============================] - 0s 48ms/step - loss: 2.5189e-04 - accuracy: 1.0000 - val_loss: 0.4975 - val_accuracy: 0.9143\n",
            "Epoch 3704/4000\n",
            "1/1 [==============================] - 0s 51ms/step - loss: 2.5169e-04 - accuracy: 1.0000 - val_loss: 0.4976 - val_accuracy: 0.9143\n",
            "Epoch 3705/4000\n",
            "1/1 [==============================] - 0s 50ms/step - loss: 2.5148e-04 - accuracy: 1.0000 - val_loss: 0.4976 - val_accuracy: 0.9143\n",
            "Epoch 3706/4000\n",
            "1/1 [==============================] - 0s 46ms/step - loss: 2.5126e-04 - accuracy: 1.0000 - val_loss: 0.4977 - val_accuracy: 0.9143\n",
            "Epoch 3707/4000\n",
            "1/1 [==============================] - 0s 47ms/step - loss: 2.5104e-04 - accuracy: 1.0000 - val_loss: 0.4977 - val_accuracy: 0.9143\n",
            "Epoch 3708/4000\n",
            "1/1 [==============================] - 0s 47ms/step - loss: 2.5085e-04 - accuracy: 1.0000 - val_loss: 0.4978 - val_accuracy: 0.9143\n",
            "Epoch 3709/4000\n",
            "1/1 [==============================] - 0s 32ms/step - loss: 2.5065e-04 - accuracy: 1.0000 - val_loss: 0.4978 - val_accuracy: 0.9143\n",
            "Epoch 3710/4000\n",
            "1/1 [==============================] - 0s 45ms/step - loss: 2.5043e-04 - accuracy: 1.0000 - val_loss: 0.4979 - val_accuracy: 0.9143\n",
            "Epoch 3711/4000\n",
            "1/1 [==============================] - 0s 33ms/step - loss: 2.5022e-04 - accuracy: 1.0000 - val_loss: 0.4979 - val_accuracy: 0.9143\n",
            "Epoch 3712/4000\n",
            "1/1 [==============================] - 0s 47ms/step - loss: 2.5002e-04 - accuracy: 1.0000 - val_loss: 0.4980 - val_accuracy: 0.9143\n",
            "Epoch 3713/4000\n",
            "1/1 [==============================] - 0s 50ms/step - loss: 2.4981e-04 - accuracy: 1.0000 - val_loss: 0.4980 - val_accuracy: 0.9143\n",
            "Epoch 3714/4000\n",
            "1/1 [==============================] - 0s 38ms/step - loss: 2.4960e-04 - accuracy: 1.0000 - val_loss: 0.4981 - val_accuracy: 0.9143\n",
            "Epoch 3715/4000\n",
            "1/1 [==============================] - 0s 49ms/step - loss: 2.4940e-04 - accuracy: 1.0000 - val_loss: 0.4982 - val_accuracy: 0.9143\n",
            "Epoch 3716/4000\n",
            "1/1 [==============================] - 0s 47ms/step - loss: 2.4919e-04 - accuracy: 1.0000 - val_loss: 0.4982 - val_accuracy: 0.9143\n",
            "Epoch 3717/4000\n",
            "1/1 [==============================] - 0s 34ms/step - loss: 2.4899e-04 - accuracy: 1.0000 - val_loss: 0.4983 - val_accuracy: 0.9143\n",
            "Epoch 3718/4000\n",
            "1/1 [==============================] - 0s 50ms/step - loss: 2.4878e-04 - accuracy: 1.0000 - val_loss: 0.4983 - val_accuracy: 0.9143\n",
            "Epoch 3719/4000\n",
            "1/1 [==============================] - 0s 45ms/step - loss: 2.4858e-04 - accuracy: 1.0000 - val_loss: 0.4984 - val_accuracy: 0.9143\n",
            "Epoch 3720/4000\n",
            "1/1 [==============================] - 0s 38ms/step - loss: 2.4838e-04 - accuracy: 1.0000 - val_loss: 0.4984 - val_accuracy: 0.9143\n",
            "Epoch 3721/4000\n",
            "1/1 [==============================] - 0s 48ms/step - loss: 2.4818e-04 - accuracy: 1.0000 - val_loss: 0.4985 - val_accuracy: 0.9143\n",
            "Epoch 3722/4000\n",
            "1/1 [==============================] - 0s 49ms/step - loss: 2.4797e-04 - accuracy: 1.0000 - val_loss: 0.4985 - val_accuracy: 0.9143\n",
            "Epoch 3723/4000\n",
            "1/1 [==============================] - 0s 47ms/step - loss: 2.4776e-04 - accuracy: 1.0000 - val_loss: 0.4986 - val_accuracy: 0.9143\n",
            "Epoch 3724/4000\n",
            "1/1 [==============================] - 0s 36ms/step - loss: 2.4756e-04 - accuracy: 1.0000 - val_loss: 0.4986 - val_accuracy: 0.9143\n",
            "Epoch 3725/4000\n",
            "1/1 [==============================] - 0s 53ms/step - loss: 2.4735e-04 - accuracy: 1.0000 - val_loss: 0.4987 - val_accuracy: 0.9143\n",
            "Epoch 3726/4000\n",
            "1/1 [==============================] - 0s 49ms/step - loss: 2.4715e-04 - accuracy: 1.0000 - val_loss: 0.4988 - val_accuracy: 0.9143\n",
            "Epoch 3727/4000\n",
            "1/1 [==============================] - 0s 49ms/step - loss: 2.4695e-04 - accuracy: 1.0000 - val_loss: 0.4988 - val_accuracy: 0.9143\n",
            "Epoch 3728/4000\n",
            "1/1 [==============================] - 0s 49ms/step - loss: 2.4675e-04 - accuracy: 1.0000 - val_loss: 0.4989 - val_accuracy: 0.9143\n",
            "Epoch 3729/4000\n",
            "1/1 [==============================] - 0s 50ms/step - loss: 2.4655e-04 - accuracy: 1.0000 - val_loss: 0.4989 - val_accuracy: 0.9143\n",
            "Epoch 3730/4000\n",
            "1/1 [==============================] - 0s 34ms/step - loss: 2.4634e-04 - accuracy: 1.0000 - val_loss: 0.4990 - val_accuracy: 0.9143\n",
            "Epoch 3731/4000\n",
            "1/1 [==============================] - 0s 50ms/step - loss: 2.4614e-04 - accuracy: 1.0000 - val_loss: 0.4990 - val_accuracy: 0.9143\n",
            "Epoch 3732/4000\n",
            "1/1 [==============================] - 0s 46ms/step - loss: 2.4594e-04 - accuracy: 1.0000 - val_loss: 0.4991 - val_accuracy: 0.9143\n",
            "Epoch 3733/4000\n",
            "1/1 [==============================] - 0s 47ms/step - loss: 2.4574e-04 - accuracy: 1.0000 - val_loss: 0.4991 - val_accuracy: 0.9143\n",
            "Epoch 3734/4000\n",
            "1/1 [==============================] - 0s 49ms/step - loss: 2.4553e-04 - accuracy: 1.0000 - val_loss: 0.4992 - val_accuracy: 0.9143\n",
            "Epoch 3735/4000\n",
            "1/1 [==============================] - 0s 45ms/step - loss: 2.4533e-04 - accuracy: 1.0000 - val_loss: 0.4992 - val_accuracy: 0.9143\n",
            "Epoch 3736/4000\n",
            "1/1 [==============================] - 0s 47ms/step - loss: 2.4513e-04 - accuracy: 1.0000 - val_loss: 0.4993 - val_accuracy: 0.9143\n",
            "Epoch 3737/4000\n",
            "1/1 [==============================] - 0s 46ms/step - loss: 2.4494e-04 - accuracy: 1.0000 - val_loss: 0.4993 - val_accuracy: 0.9143\n",
            "Epoch 3738/4000\n",
            "1/1 [==============================] - 0s 50ms/step - loss: 2.4474e-04 - accuracy: 1.0000 - val_loss: 0.4994 - val_accuracy: 0.9143\n",
            "Epoch 3739/4000\n",
            "1/1 [==============================] - 0s 37ms/step - loss: 2.4453e-04 - accuracy: 1.0000 - val_loss: 0.4994 - val_accuracy: 0.9143\n",
            "Epoch 3740/4000\n",
            "1/1 [==============================] - 0s 53ms/step - loss: 2.4433e-04 - accuracy: 1.0000 - val_loss: 0.4995 - val_accuracy: 0.9143\n",
            "Epoch 3741/4000\n",
            "1/1 [==============================] - 0s 34ms/step - loss: 2.4413e-04 - accuracy: 1.0000 - val_loss: 0.4996 - val_accuracy: 0.9143\n",
            "Epoch 3742/4000\n",
            "1/1 [==============================] - 0s 43ms/step - loss: 2.4393e-04 - accuracy: 1.0000 - val_loss: 0.4996 - val_accuracy: 0.9143\n",
            "Epoch 3743/4000\n",
            "1/1 [==============================] - 0s 32ms/step - loss: 2.4374e-04 - accuracy: 1.0000 - val_loss: 0.4997 - val_accuracy: 0.9143\n",
            "Epoch 3744/4000\n",
            "1/1 [==============================] - 0s 49ms/step - loss: 2.4354e-04 - accuracy: 1.0000 - val_loss: 0.4997 - val_accuracy: 0.9143\n",
            "Epoch 3745/4000\n",
            "1/1 [==============================] - 0s 35ms/step - loss: 2.4333e-04 - accuracy: 1.0000 - val_loss: 0.4998 - val_accuracy: 0.9143\n",
            "Epoch 3746/4000\n",
            "1/1 [==============================] - 0s 36ms/step - loss: 2.4313e-04 - accuracy: 1.0000 - val_loss: 0.4998 - val_accuracy: 0.9143\n",
            "Epoch 3747/4000\n",
            "1/1 [==============================] - 0s 54ms/step - loss: 2.4294e-04 - accuracy: 1.0000 - val_loss: 0.4999 - val_accuracy: 0.9143\n",
            "Epoch 3748/4000\n",
            "1/1 [==============================] - 0s 52ms/step - loss: 2.4275e-04 - accuracy: 1.0000 - val_loss: 0.4999 - val_accuracy: 0.9143\n",
            "Epoch 3749/4000\n",
            "1/1 [==============================] - 0s 36ms/step - loss: 2.4254e-04 - accuracy: 1.0000 - val_loss: 0.5000 - val_accuracy: 0.9143\n",
            "Epoch 3750/4000\n",
            "1/1 [==============================] - 0s 50ms/step - loss: 2.4234e-04 - accuracy: 1.0000 - val_loss: 0.5000 - val_accuracy: 0.9143\n",
            "Epoch 3751/4000\n",
            "1/1 [==============================] - 0s 54ms/step - loss: 2.4214e-04 - accuracy: 1.0000 - val_loss: 0.5001 - val_accuracy: 0.9143\n",
            "Epoch 3752/4000\n",
            "1/1 [==============================] - 0s 47ms/step - loss: 2.4195e-04 - accuracy: 1.0000 - val_loss: 0.5002 - val_accuracy: 0.9143\n",
            "Epoch 3753/4000\n",
            "1/1 [==============================] - 0s 45ms/step - loss: 2.4174e-04 - accuracy: 1.0000 - val_loss: 0.5002 - val_accuracy: 0.9143\n",
            "Epoch 3754/4000\n",
            "1/1 [==============================] - 0s 47ms/step - loss: 2.4155e-04 - accuracy: 1.0000 - val_loss: 0.5003 - val_accuracy: 0.9143\n",
            "Epoch 3755/4000\n",
            "1/1 [==============================] - 0s 48ms/step - loss: 2.4136e-04 - accuracy: 1.0000 - val_loss: 0.5003 - val_accuracy: 0.9143\n",
            "Epoch 3756/4000\n",
            "1/1 [==============================] - 0s 49ms/step - loss: 2.4116e-04 - accuracy: 1.0000 - val_loss: 0.5004 - val_accuracy: 0.9143\n",
            "Epoch 3757/4000\n",
            "1/1 [==============================] - 0s 50ms/step - loss: 2.4096e-04 - accuracy: 1.0000 - val_loss: 0.5004 - val_accuracy: 0.9143\n",
            "Epoch 3758/4000\n",
            "1/1 [==============================] - 0s 50ms/step - loss: 2.4076e-04 - accuracy: 1.0000 - val_loss: 0.5005 - val_accuracy: 0.9143\n",
            "Epoch 3759/4000\n",
            "1/1 [==============================] - 0s 47ms/step - loss: 2.4057e-04 - accuracy: 1.0000 - val_loss: 0.5005 - val_accuracy: 0.9143\n",
            "Epoch 3760/4000\n",
            "1/1 [==============================] - 0s 40ms/step - loss: 2.4037e-04 - accuracy: 1.0000 - val_loss: 0.5006 - val_accuracy: 0.9143\n",
            "Epoch 3761/4000\n",
            "1/1 [==============================] - 0s 45ms/step - loss: 2.4017e-04 - accuracy: 1.0000 - val_loss: 0.5006 - val_accuracy: 0.9143\n",
            "Epoch 3762/4000\n",
            "1/1 [==============================] - 0s 36ms/step - loss: 2.3998e-04 - accuracy: 1.0000 - val_loss: 0.5007 - val_accuracy: 0.9143\n",
            "Epoch 3763/4000\n",
            "1/1 [==============================] - 0s 32ms/step - loss: 2.3979e-04 - accuracy: 1.0000 - val_loss: 0.5007 - val_accuracy: 0.9143\n",
            "Epoch 3764/4000\n",
            "1/1 [==============================] - 0s 46ms/step - loss: 2.3959e-04 - accuracy: 1.0000 - val_loss: 0.5008 - val_accuracy: 0.9143\n",
            "Epoch 3765/4000\n",
            "1/1 [==============================] - 0s 49ms/step - loss: 2.3939e-04 - accuracy: 1.0000 - val_loss: 0.5009 - val_accuracy: 0.9143\n",
            "Epoch 3766/4000\n",
            "1/1 [==============================] - 0s 43ms/step - loss: 2.3920e-04 - accuracy: 1.0000 - val_loss: 0.5009 - val_accuracy: 0.9143\n",
            "Epoch 3767/4000\n",
            "1/1 [==============================] - 0s 41ms/step - loss: 2.3901e-04 - accuracy: 1.0000 - val_loss: 0.5010 - val_accuracy: 0.9143\n",
            "Epoch 3768/4000\n",
            "1/1 [==============================] - 0s 59ms/step - loss: 2.3881e-04 - accuracy: 1.0000 - val_loss: 0.5010 - val_accuracy: 0.9143\n",
            "Epoch 3769/4000\n",
            "1/1 [==============================] - 0s 49ms/step - loss: 2.3861e-04 - accuracy: 1.0000 - val_loss: 0.5011 - val_accuracy: 0.9143\n",
            "Epoch 3770/4000\n",
            "1/1 [==============================] - 0s 45ms/step - loss: 2.3842e-04 - accuracy: 1.0000 - val_loss: 0.5011 - val_accuracy: 0.9143\n",
            "Epoch 3771/4000\n",
            "1/1 [==============================] - 0s 49ms/step - loss: 2.3823e-04 - accuracy: 1.0000 - val_loss: 0.5012 - val_accuracy: 0.9143\n",
            "Epoch 3772/4000\n",
            "1/1 [==============================] - 0s 49ms/step - loss: 2.3804e-04 - accuracy: 1.0000 - val_loss: 0.5012 - val_accuracy: 0.9143\n",
            "Epoch 3773/4000\n",
            "1/1 [==============================] - 0s 49ms/step - loss: 2.3785e-04 - accuracy: 1.0000 - val_loss: 0.5013 - val_accuracy: 0.9143\n",
            "Epoch 3774/4000\n",
            "1/1 [==============================] - 0s 57ms/step - loss: 2.3765e-04 - accuracy: 1.0000 - val_loss: 0.5013 - val_accuracy: 0.9143\n",
            "Epoch 3775/4000\n",
            "1/1 [==============================] - 0s 42ms/step - loss: 2.3746e-04 - accuracy: 1.0000 - val_loss: 0.5014 - val_accuracy: 0.9143\n",
            "Epoch 3776/4000\n",
            "1/1 [==============================] - 0s 40ms/step - loss: 2.3726e-04 - accuracy: 1.0000 - val_loss: 0.5014 - val_accuracy: 0.9143\n",
            "Epoch 3777/4000\n",
            "1/1 [==============================] - 0s 49ms/step - loss: 2.3707e-04 - accuracy: 1.0000 - val_loss: 0.5015 - val_accuracy: 0.9143\n",
            "Epoch 3778/4000\n",
            "1/1 [==============================] - 0s 52ms/step - loss: 2.3687e-04 - accuracy: 1.0000 - val_loss: 0.5016 - val_accuracy: 0.9143\n",
            "Epoch 3779/4000\n",
            "1/1 [==============================] - 0s 37ms/step - loss: 2.3668e-04 - accuracy: 1.0000 - val_loss: 0.5016 - val_accuracy: 0.9143\n",
            "Epoch 3780/4000\n",
            "1/1 [==============================] - 0s 58ms/step - loss: 2.3649e-04 - accuracy: 1.0000 - val_loss: 0.5017 - val_accuracy: 0.9143\n",
            "Epoch 3781/4000\n",
            "1/1 [==============================] - 0s 48ms/step - loss: 2.3630e-04 - accuracy: 1.0000 - val_loss: 0.5017 - val_accuracy: 0.9143\n",
            "Epoch 3782/4000\n",
            "1/1 [==============================] - 0s 52ms/step - loss: 2.3611e-04 - accuracy: 1.0000 - val_loss: 0.5018 - val_accuracy: 0.9143\n",
            "Epoch 3783/4000\n",
            "1/1 [==============================] - 0s 58ms/step - loss: 2.3592e-04 - accuracy: 1.0000 - val_loss: 0.5018 - val_accuracy: 0.9143\n",
            "Epoch 3784/4000\n",
            "1/1 [==============================] - 0s 60ms/step - loss: 2.3573e-04 - accuracy: 1.0000 - val_loss: 0.5019 - val_accuracy: 0.9143\n",
            "Epoch 3785/4000\n",
            "1/1 [==============================] - 0s 55ms/step - loss: 2.3553e-04 - accuracy: 1.0000 - val_loss: 0.5019 - val_accuracy: 0.9143\n",
            "Epoch 3786/4000\n",
            "1/1 [==============================] - 0s 51ms/step - loss: 2.3534e-04 - accuracy: 1.0000 - val_loss: 0.5020 - val_accuracy: 0.9143\n",
            "Epoch 3787/4000\n",
            "1/1 [==============================] - 0s 52ms/step - loss: 2.3516e-04 - accuracy: 1.0000 - val_loss: 0.5020 - val_accuracy: 0.9143\n",
            "Epoch 3788/4000\n",
            "1/1 [==============================] - 0s 53ms/step - loss: 2.3497e-04 - accuracy: 1.0000 - val_loss: 0.5021 - val_accuracy: 0.9143\n",
            "Epoch 3789/4000\n",
            "1/1 [==============================] - 0s 55ms/step - loss: 2.3477e-04 - accuracy: 1.0000 - val_loss: 0.5021 - val_accuracy: 0.9143\n",
            "Epoch 3790/4000\n",
            "1/1 [==============================] - 0s 53ms/step - loss: 2.3457e-04 - accuracy: 1.0000 - val_loss: 0.5022 - val_accuracy: 0.9143\n",
            "Epoch 3791/4000\n",
            "1/1 [==============================] - 0s 52ms/step - loss: 2.3439e-04 - accuracy: 1.0000 - val_loss: 0.5022 - val_accuracy: 0.9143\n",
            "Epoch 3792/4000\n",
            "1/1 [==============================] - 0s 57ms/step - loss: 2.3420e-04 - accuracy: 1.0000 - val_loss: 0.5023 - val_accuracy: 0.9143\n",
            "Epoch 3793/4000\n",
            "1/1 [==============================] - 0s 49ms/step - loss: 2.3402e-04 - accuracy: 1.0000 - val_loss: 0.5024 - val_accuracy: 0.9143\n",
            "Epoch 3794/4000\n",
            "1/1 [==============================] - 0s 52ms/step - loss: 2.3383e-04 - accuracy: 1.0000 - val_loss: 0.5024 - val_accuracy: 0.9143\n",
            "Epoch 3795/4000\n",
            "1/1 [==============================] - 0s 66ms/step - loss: 2.3364e-04 - accuracy: 1.0000 - val_loss: 0.5025 - val_accuracy: 0.9143\n",
            "Epoch 3796/4000\n",
            "1/1 [==============================] - 0s 65ms/step - loss: 2.3344e-04 - accuracy: 1.0000 - val_loss: 0.5025 - val_accuracy: 0.9143\n",
            "Epoch 3797/4000\n",
            "1/1 [==============================] - 0s 69ms/step - loss: 2.3325e-04 - accuracy: 1.0000 - val_loss: 0.5026 - val_accuracy: 0.9143\n",
            "Epoch 3798/4000\n",
            "1/1 [==============================] - 0s 53ms/step - loss: 2.3306e-04 - accuracy: 1.0000 - val_loss: 0.5026 - val_accuracy: 0.9143\n",
            "Epoch 3799/4000\n",
            "1/1 [==============================] - 0s 53ms/step - loss: 2.3287e-04 - accuracy: 1.0000 - val_loss: 0.5027 - val_accuracy: 0.9143\n",
            "Epoch 3800/4000\n",
            "1/1 [==============================] - 0s 56ms/step - loss: 2.3269e-04 - accuracy: 1.0000 - val_loss: 0.5027 - val_accuracy: 0.9143\n",
            "Epoch 3801/4000\n",
            "1/1 [==============================] - 0s 59ms/step - loss: 2.3250e-04 - accuracy: 1.0000 - val_loss: 0.5028 - val_accuracy: 0.9143\n",
            "Epoch 3802/4000\n",
            "1/1 [==============================] - 0s 62ms/step - loss: 2.3232e-04 - accuracy: 1.0000 - val_loss: 0.5028 - val_accuracy: 0.9143\n",
            "Epoch 3803/4000\n",
            "1/1 [==============================] - 0s 67ms/step - loss: 2.3212e-04 - accuracy: 1.0000 - val_loss: 0.5029 - val_accuracy: 0.9143\n",
            "Epoch 3804/4000\n",
            "1/1 [==============================] - 0s 54ms/step - loss: 2.3193e-04 - accuracy: 1.0000 - val_loss: 0.5029 - val_accuracy: 0.9143\n",
            "Epoch 3805/4000\n",
            "1/1 [==============================] - 0s 65ms/step - loss: 2.3175e-04 - accuracy: 1.0000 - val_loss: 0.5030 - val_accuracy: 0.9143\n",
            "Epoch 3806/4000\n",
            "1/1 [==============================] - 0s 47ms/step - loss: 2.3157e-04 - accuracy: 1.0000 - val_loss: 0.5030 - val_accuracy: 0.9143\n",
            "Epoch 3807/4000\n",
            "1/1 [==============================] - 0s 67ms/step - loss: 2.3137e-04 - accuracy: 1.0000 - val_loss: 0.5031 - val_accuracy: 0.9143\n",
            "Epoch 3808/4000\n",
            "1/1 [==============================] - 0s 49ms/step - loss: 2.3118e-04 - accuracy: 1.0000 - val_loss: 0.5031 - val_accuracy: 0.9143\n",
            "Epoch 3809/4000\n",
            "1/1 [==============================] - 0s 70ms/step - loss: 2.3100e-04 - accuracy: 1.0000 - val_loss: 0.5032 - val_accuracy: 0.9143\n",
            "Epoch 3810/4000\n",
            "1/1 [==============================] - 0s 55ms/step - loss: 2.3081e-04 - accuracy: 1.0000 - val_loss: 0.5033 - val_accuracy: 0.9143\n",
            "Epoch 3811/4000\n",
            "1/1 [==============================] - 0s 51ms/step - loss: 2.3063e-04 - accuracy: 1.0000 - val_loss: 0.5033 - val_accuracy: 0.9143\n",
            "Epoch 3812/4000\n",
            "1/1 [==============================] - 0s 72ms/step - loss: 2.3044e-04 - accuracy: 1.0000 - val_loss: 0.5034 - val_accuracy: 0.9143\n",
            "Epoch 3813/4000\n",
            "1/1 [==============================] - 0s 73ms/step - loss: 2.3026e-04 - accuracy: 1.0000 - val_loss: 0.5034 - val_accuracy: 0.9143\n",
            "Epoch 3814/4000\n",
            "1/1 [==============================] - 0s 57ms/step - loss: 2.3007e-04 - accuracy: 1.0000 - val_loss: 0.5035 - val_accuracy: 0.9143\n",
            "Epoch 3815/4000\n",
            "1/1 [==============================] - 0s 57ms/step - loss: 2.2988e-04 - accuracy: 1.0000 - val_loss: 0.5035 - val_accuracy: 0.9143\n",
            "Epoch 3816/4000\n",
            "1/1 [==============================] - 0s 48ms/step - loss: 2.2969e-04 - accuracy: 1.0000 - val_loss: 0.5036 - val_accuracy: 0.9143\n",
            "Epoch 3817/4000\n",
            "1/1 [==============================] - 0s 56ms/step - loss: 2.2951e-04 - accuracy: 1.0000 - val_loss: 0.5036 - val_accuracy: 0.9143\n",
            "Epoch 3818/4000\n",
            "1/1 [==============================] - 0s 67ms/step - loss: 2.2933e-04 - accuracy: 1.0000 - val_loss: 0.5037 - val_accuracy: 0.9143\n",
            "Epoch 3819/4000\n",
            "1/1 [==============================] - 0s 55ms/step - loss: 2.2913e-04 - accuracy: 1.0000 - val_loss: 0.5037 - val_accuracy: 0.9143\n",
            "Epoch 3820/4000\n",
            "1/1 [==============================] - 0s 53ms/step - loss: 2.2895e-04 - accuracy: 1.0000 - val_loss: 0.5038 - val_accuracy: 0.9143\n",
            "Epoch 3821/4000\n",
            "1/1 [==============================] - 0s 53ms/step - loss: 2.2877e-04 - accuracy: 1.0000 - val_loss: 0.5038 - val_accuracy: 0.9143\n",
            "Epoch 3822/4000\n",
            "1/1 [==============================] - 0s 55ms/step - loss: 2.2859e-04 - accuracy: 1.0000 - val_loss: 0.5039 - val_accuracy: 0.9143\n",
            "Epoch 3823/4000\n",
            "1/1 [==============================] - 0s 60ms/step - loss: 2.2840e-04 - accuracy: 1.0000 - val_loss: 0.5039 - val_accuracy: 0.9143\n",
            "Epoch 3824/4000\n",
            "1/1 [==============================] - 0s 59ms/step - loss: 2.2822e-04 - accuracy: 1.0000 - val_loss: 0.5040 - val_accuracy: 0.9143\n",
            "Epoch 3825/4000\n",
            "1/1 [==============================] - 0s 68ms/step - loss: 2.2803e-04 - accuracy: 1.0000 - val_loss: 0.5040 - val_accuracy: 0.9143\n",
            "Epoch 3826/4000\n",
            "1/1 [==============================] - 0s 70ms/step - loss: 2.2785e-04 - accuracy: 1.0000 - val_loss: 0.5041 - val_accuracy: 0.9143\n",
            "Epoch 3827/4000\n",
            "1/1 [==============================] - 0s 61ms/step - loss: 2.2767e-04 - accuracy: 1.0000 - val_loss: 0.5042 - val_accuracy: 0.9143\n",
            "Epoch 3828/4000\n",
            "1/1 [==============================] - 0s 54ms/step - loss: 2.2748e-04 - accuracy: 1.0000 - val_loss: 0.5042 - val_accuracy: 0.9143\n",
            "Epoch 3829/4000\n",
            "1/1 [==============================] - 0s 56ms/step - loss: 2.2730e-04 - accuracy: 1.0000 - val_loss: 0.5043 - val_accuracy: 0.9143\n",
            "Epoch 3830/4000\n",
            "1/1 [==============================] - 0s 52ms/step - loss: 2.2711e-04 - accuracy: 1.0000 - val_loss: 0.5043 - val_accuracy: 0.9143\n",
            "Epoch 3831/4000\n",
            "1/1 [==============================] - 0s 53ms/step - loss: 2.2692e-04 - accuracy: 1.0000 - val_loss: 0.5044 - val_accuracy: 0.9143\n",
            "Epoch 3832/4000\n",
            "1/1 [==============================] - 0s 59ms/step - loss: 2.2674e-04 - accuracy: 1.0000 - val_loss: 0.5044 - val_accuracy: 0.9143\n",
            "Epoch 3833/4000\n",
            "1/1 [==============================] - 0s 51ms/step - loss: 2.2656e-04 - accuracy: 1.0000 - val_loss: 0.5045 - val_accuracy: 0.9143\n",
            "Epoch 3834/4000\n",
            "1/1 [==============================] - 0s 43ms/step - loss: 2.2638e-04 - accuracy: 1.0000 - val_loss: 0.5045 - val_accuracy: 0.9143\n",
            "Epoch 3835/4000\n",
            "1/1 [==============================] - 0s 50ms/step - loss: 2.2620e-04 - accuracy: 1.0000 - val_loss: 0.5046 - val_accuracy: 0.9143\n",
            "Epoch 3836/4000\n",
            "1/1 [==============================] - 0s 56ms/step - loss: 2.2601e-04 - accuracy: 1.0000 - val_loss: 0.5046 - val_accuracy: 0.9143\n",
            "Epoch 3837/4000\n",
            "1/1 [==============================] - 0s 50ms/step - loss: 2.2584e-04 - accuracy: 1.0000 - val_loss: 0.5047 - val_accuracy: 0.9143\n",
            "Epoch 3838/4000\n",
            "1/1 [==============================] - 0s 50ms/step - loss: 2.2566e-04 - accuracy: 1.0000 - val_loss: 0.5047 - val_accuracy: 0.9143\n",
            "Epoch 3839/4000\n",
            "1/1 [==============================] - 0s 62ms/step - loss: 2.2547e-04 - accuracy: 1.0000 - val_loss: 0.5048 - val_accuracy: 0.9143\n",
            "Epoch 3840/4000\n",
            "1/1 [==============================] - 0s 51ms/step - loss: 2.2529e-04 - accuracy: 1.0000 - val_loss: 0.5048 - val_accuracy: 0.9143\n",
            "Epoch 3841/4000\n",
            "1/1 [==============================] - 0s 48ms/step - loss: 2.2512e-04 - accuracy: 1.0000 - val_loss: 0.5049 - val_accuracy: 0.9143\n",
            "Epoch 3842/4000\n",
            "1/1 [==============================] - 0s 37ms/step - loss: 2.2493e-04 - accuracy: 1.0000 - val_loss: 0.5050 - val_accuracy: 0.9143\n",
            "Epoch 3843/4000\n",
            "1/1 [==============================] - 0s 49ms/step - loss: 2.2475e-04 - accuracy: 1.0000 - val_loss: 0.5050 - val_accuracy: 0.9143\n",
            "Epoch 3844/4000\n",
            "1/1 [==============================] - 0s 33ms/step - loss: 2.2457e-04 - accuracy: 1.0000 - val_loss: 0.5051 - val_accuracy: 0.9143\n",
            "Epoch 3845/4000\n",
            "1/1 [==============================] - 0s 51ms/step - loss: 2.2438e-04 - accuracy: 1.0000 - val_loss: 0.5051 - val_accuracy: 0.9143\n",
            "Epoch 3846/4000\n",
            "1/1 [==============================] - 0s 49ms/step - loss: 2.2421e-04 - accuracy: 1.0000 - val_loss: 0.5052 - val_accuracy: 0.9143\n",
            "Epoch 3847/4000\n",
            "1/1 [==============================] - 0s 47ms/step - loss: 2.2403e-04 - accuracy: 1.0000 - val_loss: 0.5052 - val_accuracy: 0.9143\n",
            "Epoch 3848/4000\n",
            "1/1 [==============================] - 0s 33ms/step - loss: 2.2386e-04 - accuracy: 1.0000 - val_loss: 0.5053 - val_accuracy: 0.9143\n",
            "Epoch 3849/4000\n",
            "1/1 [==============================] - 0s 38ms/step - loss: 2.2367e-04 - accuracy: 1.0000 - val_loss: 0.5053 - val_accuracy: 0.9143\n",
            "Epoch 3850/4000\n",
            "1/1 [==============================] - 0s 30ms/step - loss: 2.2349e-04 - accuracy: 1.0000 - val_loss: 0.5054 - val_accuracy: 0.9143\n",
            "Epoch 3851/4000\n",
            "1/1 [==============================] - 0s 55ms/step - loss: 2.2330e-04 - accuracy: 1.0000 - val_loss: 0.5054 - val_accuracy: 0.9143\n",
            "Epoch 3852/4000\n",
            "1/1 [==============================] - 0s 46ms/step - loss: 2.2313e-04 - accuracy: 1.0000 - val_loss: 0.5055 - val_accuracy: 0.9143\n",
            "Epoch 3853/4000\n",
            "1/1 [==============================] - 0s 40ms/step - loss: 2.2295e-04 - accuracy: 1.0000 - val_loss: 0.5055 - val_accuracy: 0.9143\n",
            "Epoch 3854/4000\n",
            "1/1 [==============================] - 0s 35ms/step - loss: 2.2277e-04 - accuracy: 1.0000 - val_loss: 0.5056 - val_accuracy: 0.9143\n",
            "Epoch 3855/4000\n",
            "1/1 [==============================] - 0s 46ms/step - loss: 2.2258e-04 - accuracy: 1.0000 - val_loss: 0.5056 - val_accuracy: 0.9143\n",
            "Epoch 3856/4000\n",
            "1/1 [==============================] - 0s 33ms/step - loss: 2.2242e-04 - accuracy: 1.0000 - val_loss: 0.5057 - val_accuracy: 0.9143\n",
            "Epoch 3857/4000\n",
            "1/1 [==============================] - 0s 49ms/step - loss: 2.2224e-04 - accuracy: 1.0000 - val_loss: 0.5057 - val_accuracy: 0.9143\n",
            "Epoch 3858/4000\n",
            "1/1 [==============================] - 0s 53ms/step - loss: 2.2206e-04 - accuracy: 1.0000 - val_loss: 0.5058 - val_accuracy: 0.9143\n",
            "Epoch 3859/4000\n",
            "1/1 [==============================] - 0s 48ms/step - loss: 2.2188e-04 - accuracy: 1.0000 - val_loss: 0.5058 - val_accuracy: 0.9143\n",
            "Epoch 3860/4000\n",
            "1/1 [==============================] - 0s 51ms/step - loss: 2.2170e-04 - accuracy: 1.0000 - val_loss: 0.5059 - val_accuracy: 0.9143\n",
            "Epoch 3861/4000\n",
            "1/1 [==============================] - 0s 39ms/step - loss: 2.2153e-04 - accuracy: 1.0000 - val_loss: 0.5060 - val_accuracy: 0.9143\n",
            "Epoch 3862/4000\n",
            "1/1 [==============================] - 0s 32ms/step - loss: 2.2135e-04 - accuracy: 1.0000 - val_loss: 0.5060 - val_accuracy: 0.9143\n",
            "Epoch 3863/4000\n",
            "1/1 [==============================] - 0s 48ms/step - loss: 2.2117e-04 - accuracy: 1.0000 - val_loss: 0.5061 - val_accuracy: 0.9143\n",
            "Epoch 3864/4000\n",
            "1/1 [==============================] - 0s 55ms/step - loss: 2.2099e-04 - accuracy: 1.0000 - val_loss: 0.5061 - val_accuracy: 0.9143\n",
            "Epoch 3865/4000\n",
            "1/1 [==============================] - 0s 46ms/step - loss: 2.2082e-04 - accuracy: 1.0000 - val_loss: 0.5062 - val_accuracy: 0.9143\n",
            "Epoch 3866/4000\n",
            "1/1 [==============================] - 0s 49ms/step - loss: 2.2064e-04 - accuracy: 1.0000 - val_loss: 0.5062 - val_accuracy: 0.9143\n",
            "Epoch 3867/4000\n",
            "1/1 [==============================] - 0s 35ms/step - loss: 2.2047e-04 - accuracy: 1.0000 - val_loss: 0.5063 - val_accuracy: 0.9143\n",
            "Epoch 3868/4000\n",
            "1/1 [==============================] - 0s 49ms/step - loss: 2.2029e-04 - accuracy: 1.0000 - val_loss: 0.5063 - val_accuracy: 0.9143\n",
            "Epoch 3869/4000\n",
            "1/1 [==============================] - 0s 48ms/step - loss: 2.2012e-04 - accuracy: 1.0000 - val_loss: 0.5064 - val_accuracy: 0.9143\n",
            "Epoch 3870/4000\n",
            "1/1 [==============================] - 0s 48ms/step - loss: 2.1994e-04 - accuracy: 1.0000 - val_loss: 0.5064 - val_accuracy: 0.9143\n",
            "Epoch 3871/4000\n",
            "1/1 [==============================] - 0s 40ms/step - loss: 2.1976e-04 - accuracy: 1.0000 - val_loss: 0.5065 - val_accuracy: 0.9143\n",
            "Epoch 3872/4000\n",
            "1/1 [==============================] - 0s 32ms/step - loss: 2.1958e-04 - accuracy: 1.0000 - val_loss: 0.5065 - val_accuracy: 0.9143\n",
            "Epoch 3873/4000\n",
            "1/1 [==============================] - 0s 51ms/step - loss: 2.1941e-04 - accuracy: 1.0000 - val_loss: 0.5066 - val_accuracy: 0.9143\n",
            "Epoch 3874/4000\n",
            "1/1 [==============================] - 0s 50ms/step - loss: 2.1924e-04 - accuracy: 1.0000 - val_loss: 0.5066 - val_accuracy: 0.9143\n",
            "Epoch 3875/4000\n",
            "1/1 [==============================] - 0s 39ms/step - loss: 2.1906e-04 - accuracy: 1.0000 - val_loss: 0.5067 - val_accuracy: 0.9143\n",
            "Epoch 3876/4000\n",
            "1/1 [==============================] - 0s 47ms/step - loss: 2.1888e-04 - accuracy: 1.0000 - val_loss: 0.5067 - val_accuracy: 0.9143\n",
            "Epoch 3877/4000\n",
            "1/1 [==============================] - 0s 51ms/step - loss: 2.1870e-04 - accuracy: 1.0000 - val_loss: 0.5068 - val_accuracy: 0.9143\n",
            "Epoch 3878/4000\n",
            "1/1 [==============================] - 0s 52ms/step - loss: 2.1854e-04 - accuracy: 1.0000 - val_loss: 0.5068 - val_accuracy: 0.9143\n",
            "Epoch 3879/4000\n",
            "1/1 [==============================] - 0s 48ms/step - loss: 2.1836e-04 - accuracy: 1.0000 - val_loss: 0.5069 - val_accuracy: 0.9143\n",
            "Epoch 3880/4000\n",
            "1/1 [==============================] - 0s 48ms/step - loss: 2.1818e-04 - accuracy: 1.0000 - val_loss: 0.5070 - val_accuracy: 0.9143\n",
            "Epoch 3881/4000\n",
            "1/1 [==============================] - 0s 42ms/step - loss: 2.1801e-04 - accuracy: 1.0000 - val_loss: 0.5070 - val_accuracy: 0.9143\n",
            "Epoch 3882/4000\n",
            "1/1 [==============================] - 0s 50ms/step - loss: 2.1783e-04 - accuracy: 1.0000 - val_loss: 0.5071 - val_accuracy: 0.9143\n",
            "Epoch 3883/4000\n",
            "1/1 [==============================] - 0s 47ms/step - loss: 2.1767e-04 - accuracy: 1.0000 - val_loss: 0.5071 - val_accuracy: 0.9143\n",
            "Epoch 3884/4000\n",
            "1/1 [==============================] - 0s 37ms/step - loss: 2.1749e-04 - accuracy: 1.0000 - val_loss: 0.5072 - val_accuracy: 0.9143\n",
            "Epoch 3885/4000\n",
            "1/1 [==============================] - 0s 47ms/step - loss: 2.1731e-04 - accuracy: 1.0000 - val_loss: 0.5072 - val_accuracy: 0.9143\n",
            "Epoch 3886/4000\n",
            "1/1 [==============================] - 0s 51ms/step - loss: 2.1714e-04 - accuracy: 1.0000 - val_loss: 0.5073 - val_accuracy: 0.9143\n",
            "Epoch 3887/4000\n",
            "1/1 [==============================] - 0s 38ms/step - loss: 2.1697e-04 - accuracy: 1.0000 - val_loss: 0.5073 - val_accuracy: 0.9143\n",
            "Epoch 3888/4000\n",
            "1/1 [==============================] - 0s 49ms/step - loss: 2.1680e-04 - accuracy: 1.0000 - val_loss: 0.5074 - val_accuracy: 0.9143\n",
            "Epoch 3889/4000\n",
            "1/1 [==============================] - 0s 48ms/step - loss: 2.1663e-04 - accuracy: 1.0000 - val_loss: 0.5074 - val_accuracy: 0.9143\n",
            "Epoch 3890/4000\n",
            "1/1 [==============================] - 0s 50ms/step - loss: 2.1645e-04 - accuracy: 1.0000 - val_loss: 0.5075 - val_accuracy: 0.9143\n",
            "Epoch 3891/4000\n",
            "1/1 [==============================] - 0s 54ms/step - loss: 2.1628e-04 - accuracy: 1.0000 - val_loss: 0.5075 - val_accuracy: 0.9143\n",
            "Epoch 3892/4000\n",
            "1/1 [==============================] - 0s 48ms/step - loss: 2.1610e-04 - accuracy: 1.0000 - val_loss: 0.5076 - val_accuracy: 0.9143\n",
            "Epoch 3893/4000\n",
            "1/1 [==============================] - 0s 48ms/step - loss: 2.1593e-04 - accuracy: 1.0000 - val_loss: 0.5076 - val_accuracy: 0.9143\n",
            "Epoch 3894/4000\n",
            "1/1 [==============================] - 0s 53ms/step - loss: 2.1576e-04 - accuracy: 1.0000 - val_loss: 0.5077 - val_accuracy: 0.9143\n",
            "Epoch 3895/4000\n",
            "1/1 [==============================] - 0s 48ms/step - loss: 2.1559e-04 - accuracy: 1.0000 - val_loss: 0.5077 - val_accuracy: 0.9143\n",
            "Epoch 3896/4000\n",
            "1/1 [==============================] - 0s 34ms/step - loss: 2.1542e-04 - accuracy: 1.0000 - val_loss: 0.5078 - val_accuracy: 0.9143\n",
            "Epoch 3897/4000\n",
            "1/1 [==============================] - 0s 46ms/step - loss: 2.1525e-04 - accuracy: 1.0000 - val_loss: 0.5078 - val_accuracy: 0.9143\n",
            "Epoch 3898/4000\n",
            "1/1 [==============================] - 0s 62ms/step - loss: 2.1507e-04 - accuracy: 1.0000 - val_loss: 0.5079 - val_accuracy: 0.9143\n",
            "Epoch 3899/4000\n",
            "1/1 [==============================] - 0s 32ms/step - loss: 2.1490e-04 - accuracy: 1.0000 - val_loss: 0.5080 - val_accuracy: 0.9143\n",
            "Epoch 3900/4000\n",
            "1/1 [==============================] - 0s 45ms/step - loss: 2.1473e-04 - accuracy: 1.0000 - val_loss: 0.5080 - val_accuracy: 0.9143\n",
            "Epoch 3901/4000\n",
            "1/1 [==============================] - 0s 52ms/step - loss: 2.1457e-04 - accuracy: 1.0000 - val_loss: 0.5081 - val_accuracy: 0.9143\n",
            "Epoch 3902/4000\n",
            "1/1 [==============================] - 0s 49ms/step - loss: 2.1439e-04 - accuracy: 1.0000 - val_loss: 0.5081 - val_accuracy: 0.9143\n",
            "Epoch 3903/4000\n",
            "1/1 [==============================] - 0s 47ms/step - loss: 2.1422e-04 - accuracy: 1.0000 - val_loss: 0.5082 - val_accuracy: 0.9143\n",
            "Epoch 3904/4000\n",
            "1/1 [==============================] - 0s 47ms/step - loss: 2.1405e-04 - accuracy: 1.0000 - val_loss: 0.5082 - val_accuracy: 0.9143\n",
            "Epoch 3905/4000\n",
            "1/1 [==============================] - 0s 44ms/step - loss: 2.1389e-04 - accuracy: 1.0000 - val_loss: 0.5083 - val_accuracy: 0.9143\n",
            "Epoch 3906/4000\n",
            "1/1 [==============================] - 0s 50ms/step - loss: 2.1372e-04 - accuracy: 1.0000 - val_loss: 0.5083 - val_accuracy: 0.9143\n",
            "Epoch 3907/4000\n",
            "1/1 [==============================] - 0s 48ms/step - loss: 2.1355e-04 - accuracy: 1.0000 - val_loss: 0.5084 - val_accuracy: 0.9143\n",
            "Epoch 3908/4000\n",
            "1/1 [==============================] - 0s 34ms/step - loss: 2.1338e-04 - accuracy: 1.0000 - val_loss: 0.5084 - val_accuracy: 0.9143\n",
            "Epoch 3909/4000\n",
            "1/1 [==============================] - 0s 48ms/step - loss: 2.1320e-04 - accuracy: 1.0000 - val_loss: 0.5085 - val_accuracy: 0.9143\n",
            "Epoch 3910/4000\n",
            "1/1 [==============================] - 0s 50ms/step - loss: 2.1303e-04 - accuracy: 1.0000 - val_loss: 0.5085 - val_accuracy: 0.9143\n",
            "Epoch 3911/4000\n",
            "1/1 [==============================] - 0s 58ms/step - loss: 2.1286e-04 - accuracy: 1.0000 - val_loss: 0.5086 - val_accuracy: 0.9143\n",
            "Epoch 3912/4000\n",
            "1/1 [==============================] - 0s 33ms/step - loss: 2.1269e-04 - accuracy: 1.0000 - val_loss: 0.5086 - val_accuracy: 0.9143\n",
            "Epoch 3913/4000\n",
            "1/1 [==============================] - 0s 55ms/step - loss: 2.1252e-04 - accuracy: 1.0000 - val_loss: 0.5087 - val_accuracy: 0.9143\n",
            "Epoch 3914/4000\n",
            "1/1 [==============================] - 0s 42ms/step - loss: 2.1235e-04 - accuracy: 1.0000 - val_loss: 0.5087 - val_accuracy: 0.9143\n",
            "Epoch 3915/4000\n",
            "1/1 [==============================] - 0s 51ms/step - loss: 2.1219e-04 - accuracy: 1.0000 - val_loss: 0.5088 - val_accuracy: 0.9143\n",
            "Epoch 3916/4000\n",
            "1/1 [==============================] - 0s 49ms/step - loss: 2.1202e-04 - accuracy: 1.0000 - val_loss: 0.5088 - val_accuracy: 0.9143\n",
            "Epoch 3917/4000\n",
            "1/1 [==============================] - 0s 50ms/step - loss: 2.1185e-04 - accuracy: 1.0000 - val_loss: 0.5089 - val_accuracy: 0.9143\n",
            "Epoch 3918/4000\n",
            "1/1 [==============================] - 0s 60ms/step - loss: 2.1168e-04 - accuracy: 1.0000 - val_loss: 0.5089 - val_accuracy: 0.9143\n",
            "Epoch 3919/4000\n",
            "1/1 [==============================] - 0s 48ms/step - loss: 2.1150e-04 - accuracy: 1.0000 - val_loss: 0.5090 - val_accuracy: 0.9143\n",
            "Epoch 3920/4000\n",
            "1/1 [==============================] - 0s 51ms/step - loss: 2.1134e-04 - accuracy: 1.0000 - val_loss: 0.5091 - val_accuracy: 0.9143\n",
            "Epoch 3921/4000\n",
            "1/1 [==============================] - 0s 48ms/step - loss: 2.1117e-04 - accuracy: 1.0000 - val_loss: 0.5091 - val_accuracy: 0.9143\n",
            "Epoch 3922/4000\n",
            "1/1 [==============================] - 0s 54ms/step - loss: 2.1100e-04 - accuracy: 1.0000 - val_loss: 0.5092 - val_accuracy: 0.9143\n",
            "Epoch 3923/4000\n",
            "1/1 [==============================] - 0s 47ms/step - loss: 2.1084e-04 - accuracy: 1.0000 - val_loss: 0.5092 - val_accuracy: 0.9143\n",
            "Epoch 3924/4000\n",
            "1/1 [==============================] - 0s 48ms/step - loss: 2.1068e-04 - accuracy: 1.0000 - val_loss: 0.5093 - val_accuracy: 0.9143\n",
            "Epoch 3925/4000\n",
            "1/1 [==============================] - 0s 37ms/step - loss: 2.1051e-04 - accuracy: 1.0000 - val_loss: 0.5093 - val_accuracy: 0.9143\n",
            "Epoch 3926/4000\n",
            "1/1 [==============================] - 0s 47ms/step - loss: 2.1034e-04 - accuracy: 1.0000 - val_loss: 0.5094 - val_accuracy: 0.9143\n",
            "Epoch 3927/4000\n",
            "1/1 [==============================] - 0s 55ms/step - loss: 2.1017e-04 - accuracy: 1.0000 - val_loss: 0.5094 - val_accuracy: 0.9143\n",
            "Epoch 3928/4000\n",
            "1/1 [==============================] - 0s 50ms/step - loss: 2.1001e-04 - accuracy: 1.0000 - val_loss: 0.5095 - val_accuracy: 0.9143\n",
            "Epoch 3929/4000\n",
            "1/1 [==============================] - 0s 32ms/step - loss: 2.0984e-04 - accuracy: 1.0000 - val_loss: 0.5095 - val_accuracy: 0.9143\n",
            "Epoch 3930/4000\n",
            "1/1 [==============================] - 0s 49ms/step - loss: 2.0968e-04 - accuracy: 1.0000 - val_loss: 0.5096 - val_accuracy: 0.9143\n",
            "Epoch 3931/4000\n",
            "1/1 [==============================] - 0s 52ms/step - loss: 2.0951e-04 - accuracy: 1.0000 - val_loss: 0.5096 - val_accuracy: 0.9143\n",
            "Epoch 3932/4000\n",
            "1/1 [==============================] - 0s 53ms/step - loss: 2.0934e-04 - accuracy: 1.0000 - val_loss: 0.5097 - val_accuracy: 0.9143\n",
            "Epoch 3933/4000\n",
            "1/1 [==============================] - 0s 46ms/step - loss: 2.0917e-04 - accuracy: 1.0000 - val_loss: 0.5097 - val_accuracy: 0.9143\n",
            "Epoch 3934/4000\n",
            "1/1 [==============================] - 0s 92ms/step - loss: 2.0901e-04 - accuracy: 1.0000 - val_loss: 0.5098 - val_accuracy: 0.9143\n",
            "Epoch 3935/4000\n",
            "1/1 [==============================] - 0s 49ms/step - loss: 2.0885e-04 - accuracy: 1.0000 - val_loss: 0.5098 - val_accuracy: 0.9143\n",
            "Epoch 3936/4000\n",
            "1/1 [==============================] - 0s 49ms/step - loss: 2.0868e-04 - accuracy: 1.0000 - val_loss: 0.5099 - val_accuracy: 0.9143\n",
            "Epoch 3937/4000\n",
            "1/1 [==============================] - 0s 51ms/step - loss: 2.0851e-04 - accuracy: 1.0000 - val_loss: 0.5099 - val_accuracy: 0.9143\n",
            "Epoch 3938/4000\n",
            "1/1 [==============================] - 0s 32ms/step - loss: 2.0834e-04 - accuracy: 1.0000 - val_loss: 0.5100 - val_accuracy: 0.9143\n",
            "Epoch 3939/4000\n",
            "1/1 [==============================] - 0s 47ms/step - loss: 2.0818e-04 - accuracy: 1.0000 - val_loss: 0.5100 - val_accuracy: 0.9143\n",
            "Epoch 3940/4000\n",
            "1/1 [==============================] - 0s 51ms/step - loss: 2.0802e-04 - accuracy: 1.0000 - val_loss: 0.5101 - val_accuracy: 0.9143\n",
            "Epoch 3941/4000\n",
            "1/1 [==============================] - 0s 39ms/step - loss: 2.0786e-04 - accuracy: 1.0000 - val_loss: 0.5102 - val_accuracy: 0.9143\n",
            "Epoch 3942/4000\n",
            "1/1 [==============================] - 0s 48ms/step - loss: 2.0768e-04 - accuracy: 1.0000 - val_loss: 0.5102 - val_accuracy: 0.9143\n",
            "Epoch 3943/4000\n",
            "1/1 [==============================] - 0s 49ms/step - loss: 2.0752e-04 - accuracy: 1.0000 - val_loss: 0.5103 - val_accuracy: 0.9143\n",
            "Epoch 3944/4000\n",
            "1/1 [==============================] - 0s 57ms/step - loss: 2.0736e-04 - accuracy: 1.0000 - val_loss: 0.5103 - val_accuracy: 0.9143\n",
            "Epoch 3945/4000\n",
            "1/1 [==============================] - 0s 50ms/step - loss: 2.0720e-04 - accuracy: 1.0000 - val_loss: 0.5104 - val_accuracy: 0.9143\n",
            "Epoch 3946/4000\n",
            "1/1 [==============================] - 0s 48ms/step - loss: 2.0703e-04 - accuracy: 1.0000 - val_loss: 0.5104 - val_accuracy: 0.9143\n",
            "Epoch 3947/4000\n",
            "1/1 [==============================] - 0s 50ms/step - loss: 2.0687e-04 - accuracy: 1.0000 - val_loss: 0.5105 - val_accuracy: 0.9143\n",
            "Epoch 3948/4000\n",
            "1/1 [==============================] - 0s 53ms/step - loss: 2.0672e-04 - accuracy: 1.0000 - val_loss: 0.5105 - val_accuracy: 0.9143\n",
            "Epoch 3949/4000\n",
            "1/1 [==============================] - 0s 39ms/step - loss: 2.0655e-04 - accuracy: 1.0000 - val_loss: 0.5106 - val_accuracy: 0.9143\n",
            "Epoch 3950/4000\n",
            "1/1 [==============================] - 0s 37ms/step - loss: 2.0638e-04 - accuracy: 1.0000 - val_loss: 0.5106 - val_accuracy: 0.9143\n",
            "Epoch 3951/4000\n",
            "1/1 [==============================] - 0s 49ms/step - loss: 2.0622e-04 - accuracy: 1.0000 - val_loss: 0.5107 - val_accuracy: 0.9143\n",
            "Epoch 3952/4000\n",
            "1/1 [==============================] - 0s 50ms/step - loss: 2.0607e-04 - accuracy: 1.0000 - val_loss: 0.5107 - val_accuracy: 0.9143\n",
            "Epoch 3953/4000\n",
            "1/1 [==============================] - 0s 48ms/step - loss: 2.0590e-04 - accuracy: 1.0000 - val_loss: 0.5108 - val_accuracy: 0.9143\n",
            "Epoch 3954/4000\n",
            "1/1 [==============================] - 0s 42ms/step - loss: 2.0573e-04 - accuracy: 1.0000 - val_loss: 0.5108 - val_accuracy: 0.9143\n",
            "Epoch 3955/4000\n",
            "1/1 [==============================] - 0s 56ms/step - loss: 2.0556e-04 - accuracy: 1.0000 - val_loss: 0.5109 - val_accuracy: 0.9143\n",
            "Epoch 3956/4000\n",
            "1/1 [==============================] - 0s 40ms/step - loss: 2.0540e-04 - accuracy: 1.0000 - val_loss: 0.5109 - val_accuracy: 0.9143\n",
            "Epoch 3957/4000\n",
            "1/1 [==============================] - 0s 51ms/step - loss: 2.0524e-04 - accuracy: 1.0000 - val_loss: 0.5110 - val_accuracy: 0.9143\n",
            "Epoch 3958/4000\n",
            "1/1 [==============================] - 0s 52ms/step - loss: 2.0508e-04 - accuracy: 1.0000 - val_loss: 0.5110 - val_accuracy: 0.9143\n",
            "Epoch 3959/4000\n",
            "1/1 [==============================] - 0s 51ms/step - loss: 2.0491e-04 - accuracy: 1.0000 - val_loss: 0.5111 - val_accuracy: 0.9143\n",
            "Epoch 3960/4000\n",
            "1/1 [==============================] - 0s 47ms/step - loss: 2.0475e-04 - accuracy: 1.0000 - val_loss: 0.5111 - val_accuracy: 0.9143\n",
            "Epoch 3961/4000\n",
            "1/1 [==============================] - 0s 53ms/step - loss: 2.0460e-04 - accuracy: 1.0000 - val_loss: 0.5112 - val_accuracy: 0.9143\n",
            "Epoch 3962/4000\n",
            "1/1 [==============================] - 0s 58ms/step - loss: 2.0443e-04 - accuracy: 1.0000 - val_loss: 0.5112 - val_accuracy: 0.9143\n",
            "Epoch 3963/4000\n",
            "1/1 [==============================] - 0s 39ms/step - loss: 2.0427e-04 - accuracy: 1.0000 - val_loss: 0.5113 - val_accuracy: 0.9143\n",
            "Epoch 3964/4000\n",
            "1/1 [==============================] - 0s 48ms/step - loss: 2.0411e-04 - accuracy: 1.0000 - val_loss: 0.5113 - val_accuracy: 0.9143\n",
            "Epoch 3965/4000\n",
            "1/1 [==============================] - 0s 34ms/step - loss: 2.0395e-04 - accuracy: 1.0000 - val_loss: 0.5114 - val_accuracy: 0.9143\n",
            "Epoch 3966/4000\n",
            "1/1 [==============================] - 0s 49ms/step - loss: 2.0379e-04 - accuracy: 1.0000 - val_loss: 0.5114 - val_accuracy: 0.9143\n",
            "Epoch 3967/4000\n",
            "1/1 [==============================] - 0s 34ms/step - loss: 2.0364e-04 - accuracy: 1.0000 - val_loss: 0.5115 - val_accuracy: 0.9143\n",
            "Epoch 3968/4000\n",
            "1/1 [==============================] - 0s 50ms/step - loss: 2.0348e-04 - accuracy: 1.0000 - val_loss: 0.5116 - val_accuracy: 0.9143\n",
            "Epoch 3969/4000\n",
            "1/1 [==============================] - 0s 47ms/step - loss: 2.0331e-04 - accuracy: 1.0000 - val_loss: 0.5116 - val_accuracy: 0.9143\n",
            "Epoch 3970/4000\n",
            "1/1 [==============================] - 0s 37ms/step - loss: 2.0315e-04 - accuracy: 1.0000 - val_loss: 0.5117 - val_accuracy: 0.9143\n",
            "Epoch 3971/4000\n",
            "1/1 [==============================] - 0s 41ms/step - loss: 2.0299e-04 - accuracy: 1.0000 - val_loss: 0.5117 - val_accuracy: 0.9143\n",
            "Epoch 3972/4000\n",
            "1/1 [==============================] - 0s 48ms/step - loss: 2.0283e-04 - accuracy: 1.0000 - val_loss: 0.5118 - val_accuracy: 0.9143\n",
            "Epoch 3973/4000\n",
            "1/1 [==============================] - 0s 34ms/step - loss: 2.0267e-04 - accuracy: 1.0000 - val_loss: 0.5118 - val_accuracy: 0.9143\n",
            "Epoch 3974/4000\n",
            "1/1 [==============================] - 0s 50ms/step - loss: 2.0250e-04 - accuracy: 1.0000 - val_loss: 0.5119 - val_accuracy: 0.9143\n",
            "Epoch 3975/4000\n",
            "1/1 [==============================] - 0s 54ms/step - loss: 2.0235e-04 - accuracy: 1.0000 - val_loss: 0.5119 - val_accuracy: 0.9143\n",
            "Epoch 3976/4000\n",
            "1/1 [==============================] - 0s 49ms/step - loss: 2.0220e-04 - accuracy: 1.0000 - val_loss: 0.5120 - val_accuracy: 0.9143\n",
            "Epoch 3977/4000\n",
            "1/1 [==============================] - 0s 57ms/step - loss: 2.0204e-04 - accuracy: 1.0000 - val_loss: 0.5120 - val_accuracy: 0.9143\n",
            "Epoch 3978/4000\n",
            "1/1 [==============================] - 0s 59ms/step - loss: 2.0187e-04 - accuracy: 1.0000 - val_loss: 0.5121 - val_accuracy: 0.9143\n",
            "Epoch 3979/4000\n",
            "1/1 [==============================] - 0s 49ms/step - loss: 2.0172e-04 - accuracy: 1.0000 - val_loss: 0.5121 - val_accuracy: 0.9143\n",
            "Epoch 3980/4000\n",
            "1/1 [==============================] - 0s 50ms/step - loss: 2.0156e-04 - accuracy: 1.0000 - val_loss: 0.5122 - val_accuracy: 0.9143\n",
            "Epoch 3981/4000\n",
            "1/1 [==============================] - 0s 42ms/step - loss: 2.0140e-04 - accuracy: 1.0000 - val_loss: 0.5122 - val_accuracy: 0.9143\n",
            "Epoch 3982/4000\n",
            "1/1 [==============================] - 0s 49ms/step - loss: 2.0124e-04 - accuracy: 1.0000 - val_loss: 0.5123 - val_accuracy: 0.9143\n",
            "Epoch 3983/4000\n",
            "1/1 [==============================] - 0s 48ms/step - loss: 2.0107e-04 - accuracy: 1.0000 - val_loss: 0.5123 - val_accuracy: 0.9143\n",
            "Epoch 3984/4000\n",
            "1/1 [==============================] - 0s 42ms/step - loss: 2.0093e-04 - accuracy: 1.0000 - val_loss: 0.5124 - val_accuracy: 0.9143\n",
            "Epoch 3985/4000\n",
            "1/1 [==============================] - 0s 35ms/step - loss: 2.0078e-04 - accuracy: 1.0000 - val_loss: 0.5124 - val_accuracy: 0.9143\n",
            "Epoch 3986/4000\n",
            "1/1 [==============================] - 0s 50ms/step - loss: 2.0063e-04 - accuracy: 1.0000 - val_loss: 0.5125 - val_accuracy: 0.9143\n",
            "Epoch 3987/4000\n",
            "1/1 [==============================] - 0s 50ms/step - loss: 2.0046e-04 - accuracy: 1.0000 - val_loss: 0.5126 - val_accuracy: 0.9143\n",
            "Epoch 3988/4000\n",
            "1/1 [==============================] - 0s 53ms/step - loss: 2.0029e-04 - accuracy: 1.0000 - val_loss: 0.5126 - val_accuracy: 0.9143\n",
            "Epoch 3989/4000\n",
            "1/1 [==============================] - 0s 47ms/step - loss: 2.0013e-04 - accuracy: 1.0000 - val_loss: 0.5127 - val_accuracy: 0.9143\n",
            "Epoch 3990/4000\n",
            "1/1 [==============================] - 0s 48ms/step - loss: 1.9998e-04 - accuracy: 1.0000 - val_loss: 0.5127 - val_accuracy: 0.9143\n",
            "Epoch 3991/4000\n",
            "1/1 [==============================] - 0s 43ms/step - loss: 1.9982e-04 - accuracy: 1.0000 - val_loss: 0.5128 - val_accuracy: 0.9143\n",
            "Epoch 3992/4000\n",
            "1/1 [==============================] - 0s 34ms/step - loss: 1.9966e-04 - accuracy: 1.0000 - val_loss: 0.5128 - val_accuracy: 0.9143\n",
            "Epoch 3993/4000\n",
            "1/1 [==============================] - 0s 46ms/step - loss: 1.9951e-04 - accuracy: 1.0000 - val_loss: 0.5129 - val_accuracy: 0.9143\n",
            "Epoch 3994/4000\n",
            "1/1 [==============================] - 0s 48ms/step - loss: 1.9935e-04 - accuracy: 1.0000 - val_loss: 0.5129 - val_accuracy: 0.9143\n",
            "Epoch 3995/4000\n",
            "1/1 [==============================] - 0s 47ms/step - loss: 1.9919e-04 - accuracy: 1.0000 - val_loss: 0.5130 - val_accuracy: 0.9143\n",
            "Epoch 3996/4000\n",
            "1/1 [==============================] - 0s 33ms/step - loss: 1.9904e-04 - accuracy: 1.0000 - val_loss: 0.5130 - val_accuracy: 0.9143\n",
            "Epoch 3997/4000\n",
            "1/1 [==============================] - 0s 49ms/step - loss: 1.9889e-04 - accuracy: 1.0000 - val_loss: 0.5131 - val_accuracy: 0.9143\n",
            "Epoch 3998/4000\n",
            "1/1 [==============================] - 0s 51ms/step - loss: 1.9872e-04 - accuracy: 1.0000 - val_loss: 0.5131 - val_accuracy: 0.9143\n",
            "Epoch 3999/4000\n",
            "1/1 [==============================] - 0s 43ms/step - loss: 1.9857e-04 - accuracy: 1.0000 - val_loss: 0.5132 - val_accuracy: 0.9143\n",
            "Epoch 4000/4000\n",
            "1/1 [==============================] - 0s 53ms/step - loss: 1.9842e-04 - accuracy: 1.0000 - val_loss: 0.5132 - val_accuracy: 0.9143\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# evaluate the model\n",
        "_, train_acc = model.evaluate(trainX, trainy, verbose=0)\n",
        "_, test_acc = model.evaluate(testX, testy, verbose=0)\n",
        "print('Train: %.3f, Test: %.3f' % (train_acc, test_acc))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "tSBP5w4gaVYx",
        "outputId": "acb819d8-b55b-4db9-cd00-224adea6c0a2"
      },
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Train: 1.000, Test: 0.914\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# plot training history\n",
        "pyplot.plot(history.history['loss'], label='train')\n",
        "pyplot.plot(history.history['val_loss'], label='test')\n",
        "pyplot.legend()\n",
        "pyplot.show()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 265
        },
        "id": "UdxiUUgbaXEH",
        "outputId": "6ff98cbe-2207-4229-a437-f05f66bdcc4a"
      },
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## **Overfit MLP With Early Stopping**"
      ],
      "metadata": {
        "id": "52wQbFnaajki"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# mlp overfit on the moons dataset with simple early stopping\n",
        "from sklearn.datasets import make_moons\n",
        "from keras.models import Sequential\n",
        "from keras.layers import Dense\n",
        "from keras.callbacks import EarlyStopping\n",
        "from matplotlib import pyplot"
      ],
      "metadata": {
        "id": "ttYeXEzPaoyZ"
      },
      "execution_count": 15,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# generate 2d classification dataset\n",
        "X, y = make_moons(n_samples=100, noise=0.2, random_state=1)\n",
        "# split into train and test\n",
        "n_train = 30\n",
        "trainX, testX = X[:n_train, :], X[n_train:, :]\n",
        "trainy, testy = y[:n_train], y[n_train:]\n",
        "\n",
        "print(X.shape, y.shape)\n",
        "print(trainX.shape, testX.shape)\n",
        "print(trainy.shape, testy.shape)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "nqO659cfa0XL",
        "outputId": "649d6ffe-e28f-4e0a-891b-1d4272c7d3fa"
      },
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "(100, 2) (100,)\n",
            "(30, 2) (70, 2)\n",
            "(30,) (70,)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# define model\n",
        "model = Sequential()\n",
        "model.add(Dense(500, input_dim=2, activation='relu'))\n",
        "model.add(Dense(1, activation='sigmoid'))\n",
        "model.compile(loss='binary_crossentropy', optimizer='adam', metrics=['accuracy'])"
      ],
      "metadata": {
        "id": "anXfuohNa2fJ"
      },
      "execution_count": 18,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# simple early stopping\n",
        "es = EarlyStopping(monitor='val_loss', mode='min', verbose=1)"
      ],
      "metadata": {
        "id": "gj5Xi-oqa41I"
      },
      "execution_count": 19,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "with tf.device(device_name):\n",
        "  # fit model\n",
        "  history = model.fit(trainX, trainy, validation_data=(testX, testy), epochs=4000, verbose=1, callbacks=[es])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "9kuKSPDVa6bw",
        "outputId": "beef6ad9-4e7d-41eb-c0d9-8fb1dccc8247"
      },
      "execution_count": 23,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/4000\n",
            "1/1 [==============================] - 0s 93ms/step - loss: 0.6925 - accuracy: 0.4667 - val_loss: 0.6760 - val_accuracy: 0.6429\n",
            "Epoch 2/4000\n",
            "1/1 [==============================] - 0s 56ms/step - loss: 0.6755 - accuracy: 0.6000 - val_loss: 0.6650 - val_accuracy: 0.7714\n",
            "Epoch 2: early stopping\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# evaluate the model\n",
        "_, train_acc = model.evaluate(trainX, trainy, verbose=0)\n",
        "_, test_acc = model.evaluate(testX, testy, verbose=0)\n",
        "print('Train: %.3f, Test: %.3f' % (train_acc, test_acc))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "uGqFVswxa8M2",
        "outputId": "f7be97e3-2ec6-404a-899e-cfc7c4a72b4e"
      },
      "execution_count": 24,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Train: 0.667, Test: 0.771\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# plot training history\n",
        "pyplot.plot(history.history['loss'], label='train')\n",
        "pyplot.plot(history.history['val_loss'], label='test')\n",
        "pyplot.legend()\n",
        "pyplot.show()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 265
        },
        "id": "TdHyFsYGa937",
        "outputId": "40519b22-e629-4497-f327-5c7d22c3f8b0"
      },
      "execution_count": 25,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## **Overfit MLP With Early Stopping with Patience**"
      ],
      "metadata": {
        "id": "7sXqMynvbWZ_"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# mlp overfit on the moons dataset with patient early stopping\n",
        "from sklearn.datasets import make_moons\n",
        "from keras.models import Sequential\n",
        "from keras.layers import Dense\n",
        "from keras.callbacks import EarlyStopping\n",
        "from matplotlib import pyplot\n",
        "# generate 2d classification dataset\n",
        "X, y = make_moons(n_samples=100, noise=0.2, random_state=1)\n",
        "# split into train and test\n",
        "n_train = 30\n",
        "trainX, testX = X[:n_train, :], X[n_train:, :]\n",
        "trainy, testy = y[:n_train], y[n_train:]\n",
        "# define model\n",
        "model = Sequential()\n",
        "model.add(Dense(500, input_dim=2, activation='relu'))\n",
        "model.add(Dense(1, activation='sigmoid'))\n",
        "model.compile(loss='binary_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
        "# patient early stopping\n",
        "es = EarlyStopping(monitor='val_loss', mode='min', verbose=1, patience=200)\n",
        "with tf.device(device_name):\n",
        "  # fit model\n",
        "  history = model.fit(trainX, trainy, validation_data=(testX, testy), epochs=4000, verbose=0, callbacks=[es])\n",
        "# evaluate the model\n",
        "_, train_acc = model.evaluate(trainX, trainy, verbose=0)\n",
        "_, test_acc = model.evaluate(testX, testy, verbose=0)\n",
        "print('Train: %.3f, Test: %.3f' % (train_acc, test_acc))\n",
        "# plot training history\n",
        "pyplot.plot(history.history['loss'], label='train')\n",
        "pyplot.plot(history.history['val_loss'], label='test')\n",
        "pyplot.legend()\n",
        "pyplot.show()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 300
        },
        "id": "prd5GsmxbdX9",
        "outputId": "37f9ff2c-7578-43c7-b4bf-843457a2c594"
      },
      "execution_count": 26,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 927: early stopping\n",
            "Train: 1.000, Test: 0.943\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## **Overfit MLP With Early Stopping with Patience and Checkpoints**"
      ],
      "metadata": {
        "id": "NO4rCj12b1k7"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# mlp overfit on the moons dataset with patient early stopping and model checkpointing\n",
        "from sklearn.datasets import make_moons\n",
        "from keras.models import Sequential\n",
        "from keras.layers import Dense\n",
        "from keras.callbacks import EarlyStopping\n",
        "from keras.callbacks import ModelCheckpoint\n",
        "from matplotlib import pyplot\n",
        "from keras.models import load_model\n",
        "# generate 2d classification dataset\n",
        "X, y = make_moons(n_samples=100, noise=0.2, random_state=1)\n",
        "# split into train and test\n",
        "n_train = 30\n",
        "trainX, testX = X[:n_train, :], X[n_train:, :]\n",
        "trainy, testy = y[:n_train], y[n_train:]\n",
        "# define model\n",
        "model = Sequential()\n",
        "model.add(Dense(500, input_dim=2, activation='relu'))\n",
        "model.add(Dense(1, activation='sigmoid'))\n",
        "model.compile(loss='binary_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
        "# simple early stopping\n",
        "es = EarlyStopping(monitor='val_loss', mode='min', verbose=1, patience=200)\n",
        "mc = ModelCheckpoint('best_model.h5', monitor='val_accuracy', mode='max', verbose=1, save_best_only=True)\n",
        "with tf.device(device_name):\n",
        "  # fit model\n",
        "  history = model.fit(trainX, trainy, validation_data=(testX, testy), epochs=4000, verbose=0, callbacks=[es, mc])\n",
        "# load the saved model\n",
        "saved_model = load_model('best_model.h5')\n",
        "# evaluate the model\n",
        "_, train_acc = saved_model.evaluate(trainX, trainy, verbose=0)\n",
        "_, test_acc = saved_model.evaluate(testX, testy, verbose=0)\n",
        "print('Train: %.3f, Test: %.3f' % (train_acc, test_acc))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "TKRTn9J3brrL",
        "outputId": "38c3358f-ee0c-421f-cbb6-36ebf57a08ea"
      },
      "execution_count": 27,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Epoch 1: val_accuracy improved from -inf to 0.44286, saving model to best_model.h5\n",
            "\n",
            "Epoch 2: val_accuracy improved from 0.44286 to 0.50000, saving model to best_model.h5\n",
            "\n",
            "Epoch 3: val_accuracy improved from 0.50000 to 0.58571, saving model to best_model.h5\n",
            "\n",
            "Epoch 4: val_accuracy improved from 0.58571 to 0.68571, saving model to best_model.h5\n",
            "\n",
            "Epoch 5: val_accuracy improved from 0.68571 to 0.71429, saving model to best_model.h5\n",
            "\n",
            "Epoch 6: val_accuracy did not improve from 0.71429\n",
            "\n",
            "Epoch 7: val_accuracy did not improve from 0.71429\n",
            "\n",
            "Epoch 8: val_accuracy did not improve from 0.71429\n",
            "\n",
            "Epoch 9: val_accuracy did not improve from 0.71429\n",
            "\n",
            "Epoch 10: val_accuracy did not improve from 0.71429\n",
            "\n",
            "Epoch 11: val_accuracy did not improve from 0.71429\n",
            "\n",
            "Epoch 12: val_accuracy did not improve from 0.71429\n",
            "\n",
            "Epoch 13: val_accuracy did not improve from 0.71429\n",
            "\n",
            "Epoch 14: val_accuracy did not improve from 0.71429\n",
            "\n",
            "Epoch 15: val_accuracy did not improve from 0.71429\n",
            "\n",
            "Epoch 16: val_accuracy did not improve from 0.71429\n",
            "\n",
            "Epoch 17: val_accuracy did not improve from 0.71429\n",
            "\n",
            "Epoch 18: val_accuracy did not improve from 0.71429\n",
            "\n",
            "Epoch 19: val_accuracy did not improve from 0.71429\n",
            "\n",
            "Epoch 20: val_accuracy did not improve from 0.71429\n",
            "\n",
            "Epoch 21: val_accuracy did not improve from 0.71429\n",
            "\n",
            "Epoch 22: val_accuracy did not improve from 0.71429\n",
            "\n",
            "Epoch 23: val_accuracy did not improve from 0.71429\n",
            "\n",
            "Epoch 24: val_accuracy did not improve from 0.71429\n",
            "\n",
            "Epoch 25: val_accuracy improved from 0.71429 to 0.72857, saving model to best_model.h5\n",
            "\n",
            "Epoch 26: val_accuracy did not improve from 0.72857\n",
            "\n",
            "Epoch 27: val_accuracy did not improve from 0.72857\n",
            "\n",
            "Epoch 28: val_accuracy did not improve from 0.72857\n",
            "\n",
            "Epoch 29: val_accuracy did not improve from 0.72857\n",
            "\n",
            "Epoch 30: val_accuracy did not improve from 0.72857\n",
            "\n",
            "Epoch 31: val_accuracy did not improve from 0.72857\n",
            "\n",
            "Epoch 32: val_accuracy did not improve from 0.72857\n",
            "\n",
            "Epoch 33: val_accuracy did not improve from 0.72857\n",
            "\n",
            "Epoch 34: val_accuracy did not improve from 0.72857\n",
            "\n",
            "Epoch 35: val_accuracy did not improve from 0.72857\n",
            "\n",
            "Epoch 36: val_accuracy did not improve from 0.72857\n",
            "\n",
            "Epoch 37: val_accuracy did not improve from 0.72857\n",
            "\n",
            "Epoch 38: val_accuracy did not improve from 0.72857\n",
            "\n",
            "Epoch 39: val_accuracy did not improve from 0.72857\n",
            "\n",
            "Epoch 40: val_accuracy did not improve from 0.72857\n",
            "\n",
            "Epoch 41: val_accuracy did not improve from 0.72857\n",
            "\n",
            "Epoch 42: val_accuracy did not improve from 0.72857\n",
            "\n",
            "Epoch 43: val_accuracy did not improve from 0.72857\n",
            "\n",
            "Epoch 44: val_accuracy did not improve from 0.72857\n",
            "\n",
            "Epoch 45: val_accuracy did not improve from 0.72857\n",
            "\n",
            "Epoch 46: val_accuracy did not improve from 0.72857\n",
            "\n",
            "Epoch 47: val_accuracy did not improve from 0.72857\n",
            "\n",
            "Epoch 48: val_accuracy did not improve from 0.72857\n",
            "\n",
            "Epoch 49: val_accuracy did not improve from 0.72857\n",
            "\n",
            "Epoch 50: val_accuracy did not improve from 0.72857\n",
            "\n",
            "Epoch 51: val_accuracy did not improve from 0.72857\n",
            "\n",
            "Epoch 52: val_accuracy did not improve from 0.72857\n",
            "\n",
            "Epoch 53: val_accuracy did not improve from 0.72857\n",
            "\n",
            "Epoch 54: val_accuracy did not improve from 0.72857\n",
            "\n",
            "Epoch 55: val_accuracy did not improve from 0.72857\n",
            "\n",
            "Epoch 56: val_accuracy did not improve from 0.72857\n",
            "\n",
            "Epoch 57: val_accuracy did not improve from 0.72857\n",
            "\n",
            "Epoch 58: val_accuracy did not improve from 0.72857\n",
            "\n",
            "Epoch 59: val_accuracy did not improve from 0.72857\n",
            "\n",
            "Epoch 60: val_accuracy did not improve from 0.72857\n",
            "\n",
            "Epoch 61: val_accuracy improved from 0.72857 to 0.74286, saving model to best_model.h5\n",
            "\n",
            "Epoch 62: val_accuracy did not improve from 0.74286\n",
            "\n",
            "Epoch 63: val_accuracy did not improve from 0.74286\n",
            "\n",
            "Epoch 64: val_accuracy did not improve from 0.74286\n",
            "\n",
            "Epoch 65: val_accuracy did not improve from 0.74286\n",
            "\n",
            "Epoch 66: val_accuracy did not improve from 0.74286\n",
            "\n",
            "Epoch 67: val_accuracy did not improve from 0.74286\n",
            "\n",
            "Epoch 68: val_accuracy did not improve from 0.74286\n",
            "\n",
            "Epoch 69: val_accuracy did not improve from 0.74286\n",
            "\n",
            "Epoch 70: val_accuracy did not improve from 0.74286\n",
            "\n",
            "Epoch 71: val_accuracy did not improve from 0.74286\n",
            "\n",
            "Epoch 72: val_accuracy did not improve from 0.74286\n",
            "\n",
            "Epoch 73: val_accuracy did not improve from 0.74286\n",
            "\n",
            "Epoch 74: val_accuracy did not improve from 0.74286\n",
            "\n",
            "Epoch 75: val_accuracy did not improve from 0.74286\n",
            "\n",
            "Epoch 76: val_accuracy did not improve from 0.74286\n",
            "\n",
            "Epoch 77: val_accuracy did not improve from 0.74286\n",
            "\n",
            "Epoch 78: val_accuracy did not improve from 0.74286\n",
            "\n",
            "Epoch 79: val_accuracy did not improve from 0.74286\n",
            "\n",
            "Epoch 80: val_accuracy did not improve from 0.74286\n",
            "\n",
            "Epoch 81: val_accuracy did not improve from 0.74286\n",
            "\n",
            "Epoch 82: val_accuracy did not improve from 0.74286\n",
            "\n",
            "Epoch 83: val_accuracy did not improve from 0.74286\n",
            "\n",
            "Epoch 84: val_accuracy did not improve from 0.74286\n",
            "\n",
            "Epoch 85: val_accuracy did not improve from 0.74286\n",
            "\n",
            "Epoch 86: val_accuracy did not improve from 0.74286\n",
            "\n",
            "Epoch 87: val_accuracy did not improve from 0.74286\n",
            "\n",
            "Epoch 88: val_accuracy did not improve from 0.74286\n",
            "\n",
            "Epoch 89: val_accuracy did not improve from 0.74286\n",
            "\n",
            "Epoch 90: val_accuracy did not improve from 0.74286\n",
            "\n",
            "Epoch 91: val_accuracy did not improve from 0.74286\n",
            "\n",
            "Epoch 92: val_accuracy did not improve from 0.74286\n",
            "\n",
            "Epoch 93: val_accuracy did not improve from 0.74286\n",
            "\n",
            "Epoch 94: val_accuracy did not improve from 0.74286\n",
            "\n",
            "Epoch 95: val_accuracy did not improve from 0.74286\n",
            "\n",
            "Epoch 96: val_accuracy did not improve from 0.74286\n",
            "\n",
            "Epoch 97: val_accuracy did not improve from 0.74286\n",
            "\n",
            "Epoch 98: val_accuracy did not improve from 0.74286\n",
            "\n",
            "Epoch 99: val_accuracy did not improve from 0.74286\n",
            "\n",
            "Epoch 100: val_accuracy did not improve from 0.74286\n",
            "\n",
            "Epoch 101: val_accuracy improved from 0.74286 to 0.75714, saving model to best_model.h5\n",
            "\n",
            "Epoch 102: val_accuracy did not improve from 0.75714\n",
            "\n",
            "Epoch 103: val_accuracy did not improve from 0.75714\n",
            "\n",
            "Epoch 104: val_accuracy did not improve from 0.75714\n",
            "\n",
            "Epoch 105: val_accuracy did not improve from 0.75714\n",
            "\n",
            "Epoch 106: val_accuracy did not improve from 0.75714\n",
            "\n",
            "Epoch 107: val_accuracy did not improve from 0.75714\n",
            "\n",
            "Epoch 108: val_accuracy did not improve from 0.75714\n",
            "\n",
            "Epoch 109: val_accuracy did not improve from 0.75714\n",
            "\n",
            "Epoch 110: val_accuracy did not improve from 0.75714\n",
            "\n",
            "Epoch 111: val_accuracy did not improve from 0.75714\n",
            "\n",
            "Epoch 112: val_accuracy did not improve from 0.75714\n",
            "\n",
            "Epoch 113: val_accuracy did not improve from 0.75714\n",
            "\n",
            "Epoch 114: val_accuracy did not improve from 0.75714\n",
            "\n",
            "Epoch 115: val_accuracy did not improve from 0.75714\n",
            "\n",
            "Epoch 116: val_accuracy improved from 0.75714 to 0.78571, saving model to best_model.h5\n",
            "\n",
            "Epoch 117: val_accuracy did not improve from 0.78571\n",
            "\n",
            "Epoch 118: val_accuracy did not improve from 0.78571\n",
            "\n",
            "Epoch 119: val_accuracy improved from 0.78571 to 0.80000, saving model to best_model.h5\n",
            "\n",
            "Epoch 120: val_accuracy did not improve from 0.80000\n",
            "\n",
            "Epoch 121: val_accuracy did not improve from 0.80000\n",
            "\n",
            "Epoch 122: val_accuracy did not improve from 0.80000\n",
            "\n",
            "Epoch 123: val_accuracy did not improve from 0.80000\n",
            "\n",
            "Epoch 124: val_accuracy did not improve from 0.80000\n",
            "\n",
            "Epoch 125: val_accuracy did not improve from 0.80000\n",
            "\n",
            "Epoch 126: val_accuracy did not improve from 0.80000\n",
            "\n",
            "Epoch 127: val_accuracy did not improve from 0.80000\n",
            "\n",
            "Epoch 128: val_accuracy improved from 0.80000 to 0.81429, saving model to best_model.h5\n",
            "\n",
            "Epoch 129: val_accuracy did not improve from 0.81429\n",
            "\n",
            "Epoch 130: val_accuracy did not improve from 0.81429\n",
            "\n",
            "Epoch 131: val_accuracy did not improve from 0.81429\n",
            "\n",
            "Epoch 132: val_accuracy improved from 0.81429 to 0.82857, saving model to best_model.h5\n",
            "\n",
            "Epoch 133: val_accuracy did not improve from 0.82857\n",
            "\n",
            "Epoch 134: val_accuracy did not improve from 0.82857\n",
            "\n",
            "Epoch 135: val_accuracy did not improve from 0.82857\n",
            "\n",
            "Epoch 136: val_accuracy did not improve from 0.82857\n",
            "\n",
            "Epoch 137: val_accuracy did not improve from 0.82857\n",
            "\n",
            "Epoch 138: val_accuracy did not improve from 0.82857\n",
            "\n",
            "Epoch 139: val_accuracy did not improve from 0.82857\n",
            "\n",
            "Epoch 140: val_accuracy did not improve from 0.82857\n",
            "\n",
            "Epoch 141: val_accuracy did not improve from 0.82857\n",
            "\n",
            "Epoch 142: val_accuracy did not improve from 0.82857\n",
            "\n",
            "Epoch 143: val_accuracy did not improve from 0.82857\n",
            "\n",
            "Epoch 144: val_accuracy did not improve from 0.82857\n",
            "\n",
            "Epoch 145: val_accuracy did not improve from 0.82857\n",
            "\n",
            "Epoch 146: val_accuracy did not improve from 0.82857\n",
            "\n",
            "Epoch 147: val_accuracy did not improve from 0.82857\n",
            "\n",
            "Epoch 148: val_accuracy did not improve from 0.82857\n",
            "\n",
            "Epoch 149: val_accuracy did not improve from 0.82857\n",
            "\n",
            "Epoch 150: val_accuracy did not improve from 0.82857\n",
            "\n",
            "Epoch 151: val_accuracy did not improve from 0.82857\n",
            "\n",
            "Epoch 152: val_accuracy did not improve from 0.82857\n",
            "\n",
            "Epoch 153: val_accuracy did not improve from 0.82857\n",
            "\n",
            "Epoch 154: val_accuracy did not improve from 0.82857\n",
            "\n",
            "Epoch 155: val_accuracy did not improve from 0.82857\n",
            "\n",
            "Epoch 156: val_accuracy did not improve from 0.82857\n",
            "\n",
            "Epoch 157: val_accuracy did not improve from 0.82857\n",
            "\n",
            "Epoch 158: val_accuracy did not improve from 0.82857\n",
            "\n",
            "Epoch 159: val_accuracy did not improve from 0.82857\n",
            "\n",
            "Epoch 160: val_accuracy did not improve from 0.82857\n",
            "\n",
            "Epoch 161: val_accuracy did not improve from 0.82857\n",
            "\n",
            "Epoch 162: val_accuracy did not improve from 0.82857\n",
            "\n",
            "Epoch 163: val_accuracy did not improve from 0.82857\n",
            "\n",
            "Epoch 164: val_accuracy did not improve from 0.82857\n",
            "\n",
            "Epoch 165: val_accuracy did not improve from 0.82857\n",
            "\n",
            "Epoch 166: val_accuracy did not improve from 0.82857\n",
            "\n",
            "Epoch 167: val_accuracy did not improve from 0.82857\n",
            "\n",
            "Epoch 168: val_accuracy did not improve from 0.82857\n",
            "\n",
            "Epoch 169: val_accuracy did not improve from 0.82857\n",
            "\n",
            "Epoch 170: val_accuracy did not improve from 0.82857\n",
            "\n",
            "Epoch 171: val_accuracy did not improve from 0.82857\n",
            "\n",
            "Epoch 172: val_accuracy did not improve from 0.82857\n",
            "\n",
            "Epoch 173: val_accuracy did not improve from 0.82857\n",
            "\n",
            "Epoch 174: val_accuracy did not improve from 0.82857\n",
            "\n",
            "Epoch 175: val_accuracy did not improve from 0.82857\n",
            "\n",
            "Epoch 176: val_accuracy did not improve from 0.82857\n",
            "\n",
            "Epoch 177: val_accuracy did not improve from 0.82857\n",
            "\n",
            "Epoch 178: val_accuracy did not improve from 0.82857\n",
            "\n",
            "Epoch 179: val_accuracy did not improve from 0.82857\n",
            "\n",
            "Epoch 180: val_accuracy did not improve from 0.82857\n",
            "\n",
            "Epoch 181: val_accuracy did not improve from 0.82857\n",
            "\n",
            "Epoch 182: val_accuracy did not improve from 0.82857\n",
            "\n",
            "Epoch 183: val_accuracy did not improve from 0.82857\n",
            "\n",
            "Epoch 184: val_accuracy did not improve from 0.82857\n",
            "\n",
            "Epoch 185: val_accuracy did not improve from 0.82857\n",
            "\n",
            "Epoch 186: val_accuracy did not improve from 0.82857\n",
            "\n",
            "Epoch 187: val_accuracy did not improve from 0.82857\n",
            "\n",
            "Epoch 188: val_accuracy did not improve from 0.82857\n",
            "\n",
            "Epoch 189: val_accuracy did not improve from 0.82857\n",
            "\n",
            "Epoch 190: val_accuracy did not improve from 0.82857\n",
            "\n",
            "Epoch 191: val_accuracy did not improve from 0.82857\n",
            "\n",
            "Epoch 192: val_accuracy did not improve from 0.82857\n",
            "\n",
            "Epoch 193: val_accuracy did not improve from 0.82857\n",
            "\n",
            "Epoch 194: val_accuracy did not improve from 0.82857\n",
            "\n",
            "Epoch 195: val_accuracy did not improve from 0.82857\n",
            "\n",
            "Epoch 196: val_accuracy did not improve from 0.82857\n",
            "\n",
            "Epoch 197: val_accuracy did not improve from 0.82857\n",
            "\n",
            "Epoch 198: val_accuracy did not improve from 0.82857\n",
            "\n",
            "Epoch 199: val_accuracy did not improve from 0.82857\n",
            "\n",
            "Epoch 200: val_accuracy did not improve from 0.82857\n",
            "\n",
            "Epoch 201: val_accuracy did not improve from 0.82857\n",
            "\n",
            "Epoch 202: val_accuracy did not improve from 0.82857\n",
            "\n",
            "Epoch 203: val_accuracy did not improve from 0.82857\n",
            "\n",
            "Epoch 204: val_accuracy did not improve from 0.82857\n",
            "\n",
            "Epoch 205: val_accuracy did not improve from 0.82857\n",
            "\n",
            "Epoch 206: val_accuracy did not improve from 0.82857\n",
            "\n",
            "Epoch 207: val_accuracy did not improve from 0.82857\n",
            "\n",
            "Epoch 208: val_accuracy did not improve from 0.82857\n",
            "\n",
            "Epoch 209: val_accuracy did not improve from 0.82857\n",
            "\n",
            "Epoch 210: val_accuracy did not improve from 0.82857\n",
            "\n",
            "Epoch 211: val_accuracy did not improve from 0.82857\n",
            "\n",
            "Epoch 212: val_accuracy did not improve from 0.82857\n",
            "\n",
            "Epoch 213: val_accuracy did not improve from 0.82857\n",
            "\n",
            "Epoch 214: val_accuracy did not improve from 0.82857\n",
            "\n",
            "Epoch 215: val_accuracy did not improve from 0.82857\n",
            "\n",
            "Epoch 216: val_accuracy did not improve from 0.82857\n",
            "\n",
            "Epoch 217: val_accuracy did not improve from 0.82857\n",
            "\n",
            "Epoch 218: val_accuracy did not improve from 0.82857\n",
            "\n",
            "Epoch 219: val_accuracy did not improve from 0.82857\n",
            "\n",
            "Epoch 220: val_accuracy did not improve from 0.82857\n",
            "\n",
            "Epoch 221: val_accuracy did not improve from 0.82857\n",
            "\n",
            "Epoch 222: val_accuracy did not improve from 0.82857\n",
            "\n",
            "Epoch 223: val_accuracy did not improve from 0.82857\n",
            "\n",
            "Epoch 224: val_accuracy did not improve from 0.82857\n",
            "\n",
            "Epoch 225: val_accuracy did not improve from 0.82857\n",
            "\n",
            "Epoch 226: val_accuracy did not improve from 0.82857\n",
            "\n",
            "Epoch 227: val_accuracy did not improve from 0.82857\n",
            "\n",
            "Epoch 228: val_accuracy did not improve from 0.82857\n",
            "\n",
            "Epoch 229: val_accuracy did not improve from 0.82857\n",
            "\n",
            "Epoch 230: val_accuracy did not improve from 0.82857\n",
            "\n",
            "Epoch 231: val_accuracy did not improve from 0.82857\n",
            "\n",
            "Epoch 232: val_accuracy did not improve from 0.82857\n",
            "\n",
            "Epoch 233: val_accuracy did not improve from 0.82857\n",
            "\n",
            "Epoch 234: val_accuracy did not improve from 0.82857\n",
            "\n",
            "Epoch 235: val_accuracy did not improve from 0.82857\n",
            "\n",
            "Epoch 236: val_accuracy did not improve from 0.82857\n",
            "\n",
            "Epoch 237: val_accuracy did not improve from 0.82857\n",
            "\n",
            "Epoch 238: val_accuracy did not improve from 0.82857\n",
            "\n",
            "Epoch 239: val_accuracy did not improve from 0.82857\n",
            "\n",
            "Epoch 240: val_accuracy did not improve from 0.82857\n",
            "\n",
            "Epoch 241: val_accuracy did not improve from 0.82857\n",
            "\n",
            "Epoch 242: val_accuracy did not improve from 0.82857\n",
            "\n",
            "Epoch 243: val_accuracy did not improve from 0.82857\n",
            "\n",
            "Epoch 244: val_accuracy did not improve from 0.82857\n",
            "\n",
            "Epoch 245: val_accuracy did not improve from 0.82857\n",
            "\n",
            "Epoch 246: val_accuracy did not improve from 0.82857\n",
            "\n",
            "Epoch 247: val_accuracy did not improve from 0.82857\n",
            "\n",
            "Epoch 248: val_accuracy did not improve from 0.82857\n",
            "\n",
            "Epoch 249: val_accuracy did not improve from 0.82857\n",
            "\n",
            "Epoch 250: val_accuracy did not improve from 0.82857\n",
            "\n",
            "Epoch 251: val_accuracy did not improve from 0.82857\n",
            "\n",
            "Epoch 252: val_accuracy did not improve from 0.82857\n",
            "\n",
            "Epoch 253: val_accuracy did not improve from 0.82857\n",
            "\n",
            "Epoch 254: val_accuracy did not improve from 0.82857\n",
            "\n",
            "Epoch 255: val_accuracy did not improve from 0.82857\n",
            "\n",
            "Epoch 256: val_accuracy did not improve from 0.82857\n",
            "\n",
            "Epoch 257: val_accuracy did not improve from 0.82857\n",
            "\n",
            "Epoch 258: val_accuracy did not improve from 0.82857\n",
            "\n",
            "Epoch 259: val_accuracy did not improve from 0.82857\n",
            "\n",
            "Epoch 260: val_accuracy did not improve from 0.82857\n",
            "\n",
            "Epoch 261: val_accuracy did not improve from 0.82857\n",
            "\n",
            "Epoch 262: val_accuracy did not improve from 0.82857\n",
            "\n",
            "Epoch 263: val_accuracy did not improve from 0.82857\n",
            "\n",
            "Epoch 264: val_accuracy did not improve from 0.82857\n",
            "\n",
            "Epoch 265: val_accuracy did not improve from 0.82857\n",
            "\n",
            "Epoch 266: val_accuracy did not improve from 0.82857\n",
            "\n",
            "Epoch 267: val_accuracy did not improve from 0.82857\n",
            "\n",
            "Epoch 268: val_accuracy did not improve from 0.82857\n",
            "\n",
            "Epoch 269: val_accuracy did not improve from 0.82857\n",
            "\n",
            "Epoch 270: val_accuracy did not improve from 0.82857\n",
            "\n",
            "Epoch 271: val_accuracy did not improve from 0.82857\n",
            "\n",
            "Epoch 272: val_accuracy did not improve from 0.82857\n",
            "\n",
            "Epoch 273: val_accuracy did not improve from 0.82857\n",
            "\n",
            "Epoch 274: val_accuracy did not improve from 0.82857\n",
            "\n",
            "Epoch 275: val_accuracy did not improve from 0.82857\n",
            "\n",
            "Epoch 276: val_accuracy did not improve from 0.82857\n",
            "\n",
            "Epoch 277: val_accuracy did not improve from 0.82857\n",
            "\n",
            "Epoch 278: val_accuracy did not improve from 0.82857\n",
            "\n",
            "Epoch 279: val_accuracy did not improve from 0.82857\n",
            "\n",
            "Epoch 280: val_accuracy did not improve from 0.82857\n",
            "\n",
            "Epoch 281: val_accuracy did not improve from 0.82857\n",
            "\n",
            "Epoch 282: val_accuracy did not improve from 0.82857\n",
            "\n",
            "Epoch 283: val_accuracy did not improve from 0.82857\n",
            "\n",
            "Epoch 284: val_accuracy did not improve from 0.82857\n",
            "\n",
            "Epoch 285: val_accuracy did not improve from 0.82857\n",
            "\n",
            "Epoch 286: val_accuracy did not improve from 0.82857\n",
            "\n",
            "Epoch 287: val_accuracy did not improve from 0.82857\n",
            "\n",
            "Epoch 288: val_accuracy did not improve from 0.82857\n",
            "\n",
            "Epoch 289: val_accuracy did not improve from 0.82857\n",
            "\n",
            "Epoch 290: val_accuracy did not improve from 0.82857\n",
            "\n",
            "Epoch 291: val_accuracy did not improve from 0.82857\n",
            "\n",
            "Epoch 292: val_accuracy did not improve from 0.82857\n",
            "\n",
            "Epoch 293: val_accuracy improved from 0.82857 to 0.84286, saving model to best_model.h5\n",
            "\n",
            "Epoch 294: val_accuracy did not improve from 0.84286\n",
            "\n",
            "Epoch 295: val_accuracy did not improve from 0.84286\n",
            "\n",
            "Epoch 296: val_accuracy did not improve from 0.84286\n",
            "\n",
            "Epoch 297: val_accuracy did not improve from 0.84286\n",
            "\n",
            "Epoch 298: val_accuracy did not improve from 0.84286\n",
            "\n",
            "Epoch 299: val_accuracy did not improve from 0.84286\n",
            "\n",
            "Epoch 300: val_accuracy did not improve from 0.84286\n",
            "\n",
            "Epoch 301: val_accuracy did not improve from 0.84286\n",
            "\n",
            "Epoch 302: val_accuracy did not improve from 0.84286\n",
            "\n",
            "Epoch 303: val_accuracy did not improve from 0.84286\n",
            "\n",
            "Epoch 304: val_accuracy did not improve from 0.84286\n",
            "\n",
            "Epoch 305: val_accuracy did not improve from 0.84286\n",
            "\n",
            "Epoch 306: val_accuracy did not improve from 0.84286\n",
            "\n",
            "Epoch 307: val_accuracy did not improve from 0.84286\n",
            "\n",
            "Epoch 308: val_accuracy did not improve from 0.84286\n",
            "\n",
            "Epoch 309: val_accuracy did not improve from 0.84286\n",
            "\n",
            "Epoch 310: val_accuracy did not improve from 0.84286\n",
            "\n",
            "Epoch 311: val_accuracy did not improve from 0.84286\n",
            "\n",
            "Epoch 312: val_accuracy did not improve from 0.84286\n",
            "\n",
            "Epoch 313: val_accuracy did not improve from 0.84286\n",
            "\n",
            "Epoch 314: val_accuracy did not improve from 0.84286\n",
            "\n",
            "Epoch 315: val_accuracy did not improve from 0.84286\n",
            "\n",
            "Epoch 316: val_accuracy did not improve from 0.84286\n",
            "\n",
            "Epoch 317: val_accuracy did not improve from 0.84286\n",
            "\n",
            "Epoch 318: val_accuracy did not improve from 0.84286\n",
            "\n",
            "Epoch 319: val_accuracy did not improve from 0.84286\n",
            "\n",
            "Epoch 320: val_accuracy did not improve from 0.84286\n",
            "\n",
            "Epoch 321: val_accuracy did not improve from 0.84286\n",
            "\n",
            "Epoch 322: val_accuracy did not improve from 0.84286\n",
            "\n",
            "Epoch 323: val_accuracy did not improve from 0.84286\n",
            "\n",
            "Epoch 324: val_accuracy did not improve from 0.84286\n",
            "\n",
            "Epoch 325: val_accuracy did not improve from 0.84286\n",
            "\n",
            "Epoch 326: val_accuracy did not improve from 0.84286\n",
            "\n",
            "Epoch 327: val_accuracy did not improve from 0.84286\n",
            "\n",
            "Epoch 328: val_accuracy did not improve from 0.84286\n",
            "\n",
            "Epoch 329: val_accuracy did not improve from 0.84286\n",
            "\n",
            "Epoch 330: val_accuracy did not improve from 0.84286\n",
            "\n",
            "Epoch 331: val_accuracy did not improve from 0.84286\n",
            "\n",
            "Epoch 332: val_accuracy did not improve from 0.84286\n",
            "\n",
            "Epoch 333: val_accuracy did not improve from 0.84286\n",
            "\n",
            "Epoch 334: val_accuracy did not improve from 0.84286\n",
            "\n",
            "Epoch 335: val_accuracy did not improve from 0.84286\n",
            "\n",
            "Epoch 336: val_accuracy did not improve from 0.84286\n",
            "\n",
            "Epoch 337: val_accuracy did not improve from 0.84286\n",
            "\n",
            "Epoch 338: val_accuracy did not improve from 0.84286\n",
            "\n",
            "Epoch 339: val_accuracy did not improve from 0.84286\n",
            "\n",
            "Epoch 340: val_accuracy did not improve from 0.84286\n",
            "\n",
            "Epoch 341: val_accuracy did not improve from 0.84286\n",
            "\n",
            "Epoch 342: val_accuracy did not improve from 0.84286\n",
            "\n",
            "Epoch 343: val_accuracy did not improve from 0.84286\n",
            "\n",
            "Epoch 344: val_accuracy did not improve from 0.84286\n",
            "\n",
            "Epoch 345: val_accuracy did not improve from 0.84286\n",
            "\n",
            "Epoch 346: val_accuracy did not improve from 0.84286\n",
            "\n",
            "Epoch 347: val_accuracy did not improve from 0.84286\n",
            "\n",
            "Epoch 348: val_accuracy did not improve from 0.84286\n",
            "\n",
            "Epoch 349: val_accuracy did not improve from 0.84286\n",
            "\n",
            "Epoch 350: val_accuracy did not improve from 0.84286\n",
            "\n",
            "Epoch 351: val_accuracy did not improve from 0.84286\n",
            "\n",
            "Epoch 352: val_accuracy did not improve from 0.84286\n",
            "\n",
            "Epoch 353: val_accuracy did not improve from 0.84286\n",
            "\n",
            "Epoch 354: val_accuracy did not improve from 0.84286\n",
            "\n",
            "Epoch 355: val_accuracy did not improve from 0.84286\n",
            "\n",
            "Epoch 356: val_accuracy did not improve from 0.84286\n",
            "\n",
            "Epoch 357: val_accuracy did not improve from 0.84286\n",
            "\n",
            "Epoch 358: val_accuracy did not improve from 0.84286\n",
            "\n",
            "Epoch 359: val_accuracy did not improve from 0.84286\n",
            "\n",
            "Epoch 360: val_accuracy did not improve from 0.84286\n",
            "\n",
            "Epoch 361: val_accuracy did not improve from 0.84286\n",
            "\n",
            "Epoch 362: val_accuracy did not improve from 0.84286\n",
            "\n",
            "Epoch 363: val_accuracy did not improve from 0.84286\n",
            "\n",
            "Epoch 364: val_accuracy did not improve from 0.84286\n",
            "\n",
            "Epoch 365: val_accuracy did not improve from 0.84286\n",
            "\n",
            "Epoch 366: val_accuracy did not improve from 0.84286\n",
            "\n",
            "Epoch 367: val_accuracy did not improve from 0.84286\n",
            "\n",
            "Epoch 368: val_accuracy did not improve from 0.84286\n",
            "\n",
            "Epoch 369: val_accuracy did not improve from 0.84286\n",
            "\n",
            "Epoch 370: val_accuracy did not improve from 0.84286\n",
            "\n",
            "Epoch 371: val_accuracy did not improve from 0.84286\n",
            "\n",
            "Epoch 372: val_accuracy did not improve from 0.84286\n",
            "\n",
            "Epoch 373: val_accuracy did not improve from 0.84286\n",
            "\n",
            "Epoch 374: val_accuracy did not improve from 0.84286\n",
            "\n",
            "Epoch 375: val_accuracy did not improve from 0.84286\n",
            "\n",
            "Epoch 376: val_accuracy did not improve from 0.84286\n",
            "\n",
            "Epoch 377: val_accuracy did not improve from 0.84286\n",
            "\n",
            "Epoch 378: val_accuracy did not improve from 0.84286\n",
            "\n",
            "Epoch 379: val_accuracy did not improve from 0.84286\n",
            "\n",
            "Epoch 380: val_accuracy did not improve from 0.84286\n",
            "\n",
            "Epoch 381: val_accuracy did not improve from 0.84286\n",
            "\n",
            "Epoch 382: val_accuracy did not improve from 0.84286\n",
            "\n",
            "Epoch 383: val_accuracy did not improve from 0.84286\n",
            "\n",
            "Epoch 384: val_accuracy did not improve from 0.84286\n",
            "\n",
            "Epoch 385: val_accuracy did not improve from 0.84286\n",
            "\n",
            "Epoch 386: val_accuracy did not improve from 0.84286\n",
            "\n",
            "Epoch 387: val_accuracy did not improve from 0.84286\n",
            "\n",
            "Epoch 388: val_accuracy did not improve from 0.84286\n",
            "\n",
            "Epoch 389: val_accuracy did not improve from 0.84286\n",
            "\n",
            "Epoch 390: val_accuracy did not improve from 0.84286\n",
            "\n",
            "Epoch 391: val_accuracy did not improve from 0.84286\n",
            "\n",
            "Epoch 392: val_accuracy did not improve from 0.84286\n",
            "\n",
            "Epoch 393: val_accuracy did not improve from 0.84286\n",
            "\n",
            "Epoch 394: val_accuracy did not improve from 0.84286\n",
            "\n",
            "Epoch 395: val_accuracy did not improve from 0.84286\n",
            "\n",
            "Epoch 396: val_accuracy did not improve from 0.84286\n",
            "\n",
            "Epoch 397: val_accuracy did not improve from 0.84286\n",
            "\n",
            "Epoch 398: val_accuracy did not improve from 0.84286\n",
            "\n",
            "Epoch 399: val_accuracy did not improve from 0.84286\n",
            "\n",
            "Epoch 400: val_accuracy did not improve from 0.84286\n",
            "\n",
            "Epoch 401: val_accuracy did not improve from 0.84286\n",
            "\n",
            "Epoch 402: val_accuracy did not improve from 0.84286\n",
            "\n",
            "Epoch 403: val_accuracy did not improve from 0.84286\n",
            "\n",
            "Epoch 404: val_accuracy did not improve from 0.84286\n",
            "\n",
            "Epoch 405: val_accuracy did not improve from 0.84286\n",
            "\n",
            "Epoch 406: val_accuracy did not improve from 0.84286\n",
            "\n",
            "Epoch 407: val_accuracy did not improve from 0.84286\n",
            "\n",
            "Epoch 408: val_accuracy did not improve from 0.84286\n",
            "\n",
            "Epoch 409: val_accuracy did not improve from 0.84286\n",
            "\n",
            "Epoch 410: val_accuracy did not improve from 0.84286\n",
            "\n",
            "Epoch 411: val_accuracy did not improve from 0.84286\n",
            "\n",
            "Epoch 412: val_accuracy did not improve from 0.84286\n",
            "\n",
            "Epoch 413: val_accuracy did not improve from 0.84286\n",
            "\n",
            "Epoch 414: val_accuracy did not improve from 0.84286\n",
            "\n",
            "Epoch 415: val_accuracy did not improve from 0.84286\n",
            "\n",
            "Epoch 416: val_accuracy did not improve from 0.84286\n",
            "\n",
            "Epoch 417: val_accuracy did not improve from 0.84286\n",
            "\n",
            "Epoch 418: val_accuracy did not improve from 0.84286\n",
            "\n",
            "Epoch 419: val_accuracy did not improve from 0.84286\n",
            "\n",
            "Epoch 420: val_accuracy did not improve from 0.84286\n",
            "\n",
            "Epoch 421: val_accuracy did not improve from 0.84286\n",
            "\n",
            "Epoch 422: val_accuracy did not improve from 0.84286\n",
            "\n",
            "Epoch 423: val_accuracy did not improve from 0.84286\n",
            "\n",
            "Epoch 424: val_accuracy did not improve from 0.84286\n",
            "\n",
            "Epoch 425: val_accuracy did not improve from 0.84286\n",
            "\n",
            "Epoch 426: val_accuracy did not improve from 0.84286\n",
            "\n",
            "Epoch 427: val_accuracy did not improve from 0.84286\n",
            "\n",
            "Epoch 428: val_accuracy did not improve from 0.84286\n",
            "\n",
            "Epoch 429: val_accuracy did not improve from 0.84286\n",
            "\n",
            "Epoch 430: val_accuracy did not improve from 0.84286\n",
            "\n",
            "Epoch 431: val_accuracy did not improve from 0.84286\n",
            "\n",
            "Epoch 432: val_accuracy did not improve from 0.84286\n",
            "\n",
            "Epoch 433: val_accuracy did not improve from 0.84286\n",
            "\n",
            "Epoch 434: val_accuracy did not improve from 0.84286\n",
            "\n",
            "Epoch 435: val_accuracy did not improve from 0.84286\n",
            "\n",
            "Epoch 436: val_accuracy did not improve from 0.84286\n",
            "\n",
            "Epoch 437: val_accuracy did not improve from 0.84286\n",
            "\n",
            "Epoch 438: val_accuracy did not improve from 0.84286\n",
            "\n",
            "Epoch 439: val_accuracy did not improve from 0.84286\n",
            "\n",
            "Epoch 440: val_accuracy did not improve from 0.84286\n",
            "\n",
            "Epoch 441: val_accuracy did not improve from 0.84286\n",
            "\n",
            "Epoch 442: val_accuracy did not improve from 0.84286\n",
            "\n",
            "Epoch 443: val_accuracy did not improve from 0.84286\n",
            "\n",
            "Epoch 444: val_accuracy did not improve from 0.84286\n",
            "\n",
            "Epoch 445: val_accuracy did not improve from 0.84286\n",
            "\n",
            "Epoch 446: val_accuracy did not improve from 0.84286\n",
            "\n",
            "Epoch 447: val_accuracy did not improve from 0.84286\n",
            "\n",
            "Epoch 448: val_accuracy did not improve from 0.84286\n",
            "\n",
            "Epoch 449: val_accuracy did not improve from 0.84286\n",
            "\n",
            "Epoch 450: val_accuracy did not improve from 0.84286\n",
            "\n",
            "Epoch 451: val_accuracy did not improve from 0.84286\n",
            "\n",
            "Epoch 452: val_accuracy did not improve from 0.84286\n",
            "\n",
            "Epoch 453: val_accuracy did not improve from 0.84286\n",
            "\n",
            "Epoch 454: val_accuracy did not improve from 0.84286\n",
            "\n",
            "Epoch 455: val_accuracy did not improve from 0.84286\n",
            "\n",
            "Epoch 456: val_accuracy did not improve from 0.84286\n",
            "\n",
            "Epoch 457: val_accuracy did not improve from 0.84286\n",
            "\n",
            "Epoch 458: val_accuracy did not improve from 0.84286\n",
            "\n",
            "Epoch 459: val_accuracy did not improve from 0.84286\n",
            "\n",
            "Epoch 460: val_accuracy did not improve from 0.84286\n",
            "\n",
            "Epoch 461: val_accuracy did not improve from 0.84286\n",
            "\n",
            "Epoch 462: val_accuracy did not improve from 0.84286\n",
            "\n",
            "Epoch 463: val_accuracy did not improve from 0.84286\n",
            "\n",
            "Epoch 464: val_accuracy did not improve from 0.84286\n",
            "\n",
            "Epoch 465: val_accuracy did not improve from 0.84286\n",
            "\n",
            "Epoch 466: val_accuracy did not improve from 0.84286\n",
            "\n",
            "Epoch 467: val_accuracy did not improve from 0.84286\n",
            "\n",
            "Epoch 468: val_accuracy did not improve from 0.84286\n",
            "\n",
            "Epoch 469: val_accuracy did not improve from 0.84286\n",
            "\n",
            "Epoch 470: val_accuracy did not improve from 0.84286\n",
            "\n",
            "Epoch 471: val_accuracy did not improve from 0.84286\n",
            "\n",
            "Epoch 472: val_accuracy did not improve from 0.84286\n",
            "\n",
            "Epoch 473: val_accuracy did not improve from 0.84286\n",
            "\n",
            "Epoch 474: val_accuracy did not improve from 0.84286\n",
            "\n",
            "Epoch 475: val_accuracy did not improve from 0.84286\n",
            "\n",
            "Epoch 476: val_accuracy did not improve from 0.84286\n",
            "\n",
            "Epoch 477: val_accuracy did not improve from 0.84286\n",
            "\n",
            "Epoch 478: val_accuracy did not improve from 0.84286\n",
            "\n",
            "Epoch 479: val_accuracy did not improve from 0.84286\n",
            "\n",
            "Epoch 480: val_accuracy did not improve from 0.84286\n",
            "\n",
            "Epoch 481: val_accuracy did not improve from 0.84286\n",
            "\n",
            "Epoch 482: val_accuracy did not improve from 0.84286\n",
            "\n",
            "Epoch 483: val_accuracy did not improve from 0.84286\n",
            "\n",
            "Epoch 484: val_accuracy did not improve from 0.84286\n",
            "\n",
            "Epoch 485: val_accuracy did not improve from 0.84286\n",
            "\n",
            "Epoch 486: val_accuracy did not improve from 0.84286\n",
            "\n",
            "Epoch 487: val_accuracy did not improve from 0.84286\n",
            "\n",
            "Epoch 488: val_accuracy did not improve from 0.84286\n",
            "\n",
            "Epoch 489: val_accuracy did not improve from 0.84286\n",
            "\n",
            "Epoch 490: val_accuracy did not improve from 0.84286\n",
            "\n",
            "Epoch 491: val_accuracy did not improve from 0.84286\n",
            "\n",
            "Epoch 492: val_accuracy did not improve from 0.84286\n",
            "\n",
            "Epoch 493: val_accuracy did not improve from 0.84286\n",
            "\n",
            "Epoch 494: val_accuracy did not improve from 0.84286\n",
            "\n",
            "Epoch 495: val_accuracy did not improve from 0.84286\n",
            "\n",
            "Epoch 496: val_accuracy did not improve from 0.84286\n",
            "\n",
            "Epoch 497: val_accuracy did not improve from 0.84286\n",
            "\n",
            "Epoch 498: val_accuracy did not improve from 0.84286\n",
            "\n",
            "Epoch 499: val_accuracy did not improve from 0.84286\n",
            "\n",
            "Epoch 500: val_accuracy did not improve from 0.84286\n",
            "\n",
            "Epoch 501: val_accuracy did not improve from 0.84286\n",
            "\n",
            "Epoch 502: val_accuracy did not improve from 0.84286\n",
            "\n",
            "Epoch 503: val_accuracy did not improve from 0.84286\n",
            "\n",
            "Epoch 504: val_accuracy did not improve from 0.84286\n",
            "\n",
            "Epoch 505: val_accuracy did not improve from 0.84286\n",
            "\n",
            "Epoch 506: val_accuracy did not improve from 0.84286\n",
            "\n",
            "Epoch 507: val_accuracy did not improve from 0.84286\n",
            "\n",
            "Epoch 508: val_accuracy did not improve from 0.84286\n",
            "\n",
            "Epoch 509: val_accuracy did not improve from 0.84286\n",
            "\n",
            "Epoch 510: val_accuracy did not improve from 0.84286\n",
            "\n",
            "Epoch 511: val_accuracy did not improve from 0.84286\n",
            "\n",
            "Epoch 512: val_accuracy did not improve from 0.84286\n",
            "\n",
            "Epoch 513: val_accuracy did not improve from 0.84286\n",
            "\n",
            "Epoch 514: val_accuracy did not improve from 0.84286\n",
            "\n",
            "Epoch 515: val_accuracy did not improve from 0.84286\n",
            "\n",
            "Epoch 516: val_accuracy did not improve from 0.84286\n",
            "\n",
            "Epoch 517: val_accuracy did not improve from 0.84286\n",
            "\n",
            "Epoch 518: val_accuracy did not improve from 0.84286\n",
            "\n",
            "Epoch 519: val_accuracy did not improve from 0.84286\n",
            "\n",
            "Epoch 520: val_accuracy did not improve from 0.84286\n",
            "\n",
            "Epoch 521: val_accuracy did not improve from 0.84286\n",
            "\n",
            "Epoch 522: val_accuracy did not improve from 0.84286\n",
            "\n",
            "Epoch 523: val_accuracy did not improve from 0.84286\n",
            "\n",
            "Epoch 524: val_accuracy did not improve from 0.84286\n",
            "\n",
            "Epoch 525: val_accuracy did not improve from 0.84286\n",
            "\n",
            "Epoch 526: val_accuracy did not improve from 0.84286\n",
            "\n",
            "Epoch 527: val_accuracy did not improve from 0.84286\n",
            "\n",
            "Epoch 528: val_accuracy did not improve from 0.84286\n",
            "\n",
            "Epoch 529: val_accuracy did not improve from 0.84286\n",
            "\n",
            "Epoch 530: val_accuracy did not improve from 0.84286\n",
            "\n",
            "Epoch 531: val_accuracy did not improve from 0.84286\n",
            "\n",
            "Epoch 532: val_accuracy did not improve from 0.84286\n",
            "\n",
            "Epoch 533: val_accuracy did not improve from 0.84286\n",
            "\n",
            "Epoch 534: val_accuracy did not improve from 0.84286\n",
            "\n",
            "Epoch 535: val_accuracy did not improve from 0.84286\n",
            "\n",
            "Epoch 536: val_accuracy did not improve from 0.84286\n",
            "\n",
            "Epoch 537: val_accuracy did not improve from 0.84286\n",
            "\n",
            "Epoch 538: val_accuracy did not improve from 0.84286\n",
            "\n",
            "Epoch 539: val_accuracy did not improve from 0.84286\n",
            "\n",
            "Epoch 540: val_accuracy did not improve from 0.84286\n",
            "\n",
            "Epoch 541: val_accuracy did not improve from 0.84286\n",
            "\n",
            "Epoch 542: val_accuracy did not improve from 0.84286\n",
            "\n",
            "Epoch 543: val_accuracy did not improve from 0.84286\n",
            "\n",
            "Epoch 544: val_accuracy did not improve from 0.84286\n",
            "\n",
            "Epoch 545: val_accuracy did not improve from 0.84286\n",
            "\n",
            "Epoch 546: val_accuracy did not improve from 0.84286\n",
            "\n",
            "Epoch 547: val_accuracy did not improve from 0.84286\n",
            "\n",
            "Epoch 548: val_accuracy did not improve from 0.84286\n",
            "\n",
            "Epoch 549: val_accuracy did not improve from 0.84286\n",
            "\n",
            "Epoch 550: val_accuracy improved from 0.84286 to 0.85714, saving model to best_model.h5\n",
            "\n",
            "Epoch 551: val_accuracy did not improve from 0.85714\n",
            "\n",
            "Epoch 552: val_accuracy did not improve from 0.85714\n",
            "\n",
            "Epoch 553: val_accuracy did not improve from 0.85714\n",
            "\n",
            "Epoch 554: val_accuracy did not improve from 0.85714\n",
            "\n",
            "Epoch 555: val_accuracy did not improve from 0.85714\n",
            "\n",
            "Epoch 556: val_accuracy did not improve from 0.85714\n",
            "\n",
            "Epoch 557: val_accuracy did not improve from 0.85714\n",
            "\n",
            "Epoch 558: val_accuracy did not improve from 0.85714\n",
            "\n",
            "Epoch 559: val_accuracy did not improve from 0.85714\n",
            "\n",
            "Epoch 560: val_accuracy did not improve from 0.85714\n",
            "\n",
            "Epoch 561: val_accuracy did not improve from 0.85714\n",
            "\n",
            "Epoch 562: val_accuracy did not improve from 0.85714\n",
            "\n",
            "Epoch 563: val_accuracy did not improve from 0.85714\n",
            "\n",
            "Epoch 564: val_accuracy did not improve from 0.85714\n",
            "\n",
            "Epoch 565: val_accuracy did not improve from 0.85714\n",
            "\n",
            "Epoch 566: val_accuracy did not improve from 0.85714\n",
            "\n",
            "Epoch 567: val_accuracy did not improve from 0.85714\n",
            "\n",
            "Epoch 568: val_accuracy did not improve from 0.85714\n",
            "\n",
            "Epoch 569: val_accuracy did not improve from 0.85714\n",
            "\n",
            "Epoch 570: val_accuracy did not improve from 0.85714\n",
            "\n",
            "Epoch 571: val_accuracy improved from 0.85714 to 0.87143, saving model to best_model.h5\n",
            "\n",
            "Epoch 572: val_accuracy did not improve from 0.87143\n",
            "\n",
            "Epoch 573: val_accuracy did not improve from 0.87143\n",
            "\n",
            "Epoch 574: val_accuracy did not improve from 0.87143\n",
            "\n",
            "Epoch 575: val_accuracy did not improve from 0.87143\n",
            "\n",
            "Epoch 576: val_accuracy did not improve from 0.87143\n",
            "\n",
            "Epoch 577: val_accuracy did not improve from 0.87143\n",
            "\n",
            "Epoch 578: val_accuracy did not improve from 0.87143\n",
            "\n",
            "Epoch 579: val_accuracy did not improve from 0.87143\n",
            "\n",
            "Epoch 580: val_accuracy did not improve from 0.87143\n",
            "\n",
            "Epoch 581: val_accuracy improved from 0.87143 to 0.88571, saving model to best_model.h5\n",
            "\n",
            "Epoch 582: val_accuracy did not improve from 0.88571\n",
            "\n",
            "Epoch 583: val_accuracy did not improve from 0.88571\n",
            "\n",
            "Epoch 584: val_accuracy did not improve from 0.88571\n",
            "\n",
            "Epoch 585: val_accuracy did not improve from 0.88571\n",
            "\n",
            "Epoch 586: val_accuracy did not improve from 0.88571\n",
            "\n",
            "Epoch 587: val_accuracy did not improve from 0.88571\n",
            "\n",
            "Epoch 588: val_accuracy did not improve from 0.88571\n",
            "\n",
            "Epoch 589: val_accuracy did not improve from 0.88571\n",
            "\n",
            "Epoch 590: val_accuracy did not improve from 0.88571\n",
            "\n",
            "Epoch 591: val_accuracy did not improve from 0.88571\n",
            "\n",
            "Epoch 592: val_accuracy did not improve from 0.88571\n",
            "\n",
            "Epoch 593: val_accuracy did not improve from 0.88571\n",
            "\n",
            "Epoch 594: val_accuracy did not improve from 0.88571\n",
            "\n",
            "Epoch 595: val_accuracy did not improve from 0.88571\n",
            "\n",
            "Epoch 596: val_accuracy did not improve from 0.88571\n",
            "\n",
            "Epoch 597: val_accuracy improved from 0.88571 to 0.90000, saving model to best_model.h5\n",
            "\n",
            "Epoch 598: val_accuracy did not improve from 0.90000\n",
            "\n",
            "Epoch 599: val_accuracy did not improve from 0.90000\n",
            "\n",
            "Epoch 600: val_accuracy did not improve from 0.90000\n",
            "\n",
            "Epoch 601: val_accuracy did not improve from 0.90000\n",
            "\n",
            "Epoch 602: val_accuracy did not improve from 0.90000\n",
            "\n",
            "Epoch 603: val_accuracy did not improve from 0.90000\n",
            "\n",
            "Epoch 604: val_accuracy did not improve from 0.90000\n",
            "\n",
            "Epoch 605: val_accuracy did not improve from 0.90000\n",
            "\n",
            "Epoch 606: val_accuracy did not improve from 0.90000\n",
            "\n",
            "Epoch 607: val_accuracy did not improve from 0.90000\n",
            "\n",
            "Epoch 608: val_accuracy did not improve from 0.90000\n",
            "\n",
            "Epoch 609: val_accuracy did not improve from 0.90000\n",
            "\n",
            "Epoch 610: val_accuracy did not improve from 0.90000\n",
            "\n",
            "Epoch 611: val_accuracy did not improve from 0.90000\n",
            "\n",
            "Epoch 612: val_accuracy did not improve from 0.90000\n",
            "\n",
            "Epoch 613: val_accuracy did not improve from 0.90000\n",
            "\n",
            "Epoch 614: val_accuracy did not improve from 0.90000\n",
            "\n",
            "Epoch 615: val_accuracy did not improve from 0.90000\n",
            "\n",
            "Epoch 616: val_accuracy did not improve from 0.90000\n",
            "\n",
            "Epoch 617: val_accuracy did not improve from 0.90000\n",
            "\n",
            "Epoch 618: val_accuracy did not improve from 0.90000\n",
            "\n",
            "Epoch 619: val_accuracy did not improve from 0.90000\n",
            "\n",
            "Epoch 620: val_accuracy did not improve from 0.90000\n",
            "\n",
            "Epoch 621: val_accuracy did not improve from 0.90000\n",
            "\n",
            "Epoch 622: val_accuracy did not improve from 0.90000\n",
            "\n",
            "Epoch 623: val_accuracy did not improve from 0.90000\n",
            "\n",
            "Epoch 624: val_accuracy did not improve from 0.90000\n",
            "\n",
            "Epoch 625: val_accuracy did not improve from 0.90000\n",
            "\n",
            "Epoch 626: val_accuracy did not improve from 0.90000\n",
            "\n",
            "Epoch 627: val_accuracy did not improve from 0.90000\n",
            "\n",
            "Epoch 628: val_accuracy did not improve from 0.90000\n",
            "\n",
            "Epoch 629: val_accuracy did not improve from 0.90000\n",
            "\n",
            "Epoch 630: val_accuracy did not improve from 0.90000\n",
            "\n",
            "Epoch 631: val_accuracy did not improve from 0.90000\n",
            "\n",
            "Epoch 632: val_accuracy did not improve from 0.90000\n",
            "\n",
            "Epoch 633: val_accuracy did not improve from 0.90000\n",
            "\n",
            "Epoch 634: val_accuracy did not improve from 0.90000\n",
            "\n",
            "Epoch 635: val_accuracy did not improve from 0.90000\n",
            "\n",
            "Epoch 636: val_accuracy did not improve from 0.90000\n",
            "\n",
            "Epoch 637: val_accuracy did not improve from 0.90000\n",
            "\n",
            "Epoch 638: val_accuracy did not improve from 0.90000\n",
            "\n",
            "Epoch 639: val_accuracy did not improve from 0.90000\n",
            "\n",
            "Epoch 640: val_accuracy did not improve from 0.90000\n",
            "\n",
            "Epoch 641: val_accuracy did not improve from 0.90000\n",
            "\n",
            "Epoch 642: val_accuracy did not improve from 0.90000\n",
            "\n",
            "Epoch 643: val_accuracy did not improve from 0.90000\n",
            "\n",
            "Epoch 644: val_accuracy did not improve from 0.90000\n",
            "\n",
            "Epoch 645: val_accuracy did not improve from 0.90000\n",
            "\n",
            "Epoch 646: val_accuracy did not improve from 0.90000\n",
            "\n",
            "Epoch 647: val_accuracy did not improve from 0.90000\n",
            "\n",
            "Epoch 648: val_accuracy did not improve from 0.90000\n",
            "\n",
            "Epoch 649: val_accuracy did not improve from 0.90000\n",
            "\n",
            "Epoch 650: val_accuracy did not improve from 0.90000\n",
            "\n",
            "Epoch 651: val_accuracy did not improve from 0.90000\n",
            "\n",
            "Epoch 652: val_accuracy did not improve from 0.90000\n",
            "\n",
            "Epoch 653: val_accuracy did not improve from 0.90000\n",
            "\n",
            "Epoch 654: val_accuracy did not improve from 0.90000\n",
            "\n",
            "Epoch 655: val_accuracy did not improve from 0.90000\n",
            "\n",
            "Epoch 656: val_accuracy did not improve from 0.90000\n",
            "\n",
            "Epoch 657: val_accuracy did not improve from 0.90000\n",
            "\n",
            "Epoch 658: val_accuracy did not improve from 0.90000\n",
            "\n",
            "Epoch 659: val_accuracy did not improve from 0.90000\n",
            "\n",
            "Epoch 660: val_accuracy did not improve from 0.90000\n",
            "\n",
            "Epoch 661: val_accuracy did not improve from 0.90000\n",
            "\n",
            "Epoch 662: val_accuracy did not improve from 0.90000\n",
            "\n",
            "Epoch 663: val_accuracy improved from 0.90000 to 0.91429, saving model to best_model.h5\n",
            "\n",
            "Epoch 664: val_accuracy did not improve from 0.91429\n",
            "\n",
            "Epoch 665: val_accuracy did not improve from 0.91429\n",
            "\n",
            "Epoch 666: val_accuracy did not improve from 0.91429\n",
            "\n",
            "Epoch 667: val_accuracy improved from 0.91429 to 0.92857, saving model to best_model.h5\n",
            "\n",
            "Epoch 668: val_accuracy did not improve from 0.92857\n",
            "\n",
            "Epoch 669: val_accuracy did not improve from 0.92857\n",
            "\n",
            "Epoch 670: val_accuracy did not improve from 0.92857\n",
            "\n",
            "Epoch 671: val_accuracy did not improve from 0.92857\n",
            "\n",
            "Epoch 672: val_accuracy did not improve from 0.92857\n",
            "\n",
            "Epoch 673: val_accuracy did not improve from 0.92857\n",
            "\n",
            "Epoch 674: val_accuracy did not improve from 0.92857\n",
            "\n",
            "Epoch 675: val_accuracy did not improve from 0.92857\n",
            "\n",
            "Epoch 676: val_accuracy did not improve from 0.92857\n",
            "\n",
            "Epoch 677: val_accuracy did not improve from 0.92857\n",
            "\n",
            "Epoch 678: val_accuracy did not improve from 0.92857\n",
            "\n",
            "Epoch 679: val_accuracy did not improve from 0.92857\n",
            "\n",
            "Epoch 680: val_accuracy did not improve from 0.92857\n",
            "\n",
            "Epoch 681: val_accuracy did not improve from 0.92857\n",
            "\n",
            "Epoch 682: val_accuracy did not improve from 0.92857\n",
            "\n",
            "Epoch 683: val_accuracy did not improve from 0.92857\n",
            "\n",
            "Epoch 684: val_accuracy did not improve from 0.92857\n",
            "\n",
            "Epoch 685: val_accuracy did not improve from 0.92857\n",
            "\n",
            "Epoch 686: val_accuracy did not improve from 0.92857\n",
            "\n",
            "Epoch 687: val_accuracy did not improve from 0.92857\n",
            "\n",
            "Epoch 688: val_accuracy did not improve from 0.92857\n",
            "\n",
            "Epoch 689: val_accuracy did not improve from 0.92857\n",
            "\n",
            "Epoch 690: val_accuracy did not improve from 0.92857\n",
            "\n",
            "Epoch 691: val_accuracy did not improve from 0.92857\n",
            "\n",
            "Epoch 692: val_accuracy did not improve from 0.92857\n",
            "\n",
            "Epoch 693: val_accuracy did not improve from 0.92857\n",
            "\n",
            "Epoch 694: val_accuracy did not improve from 0.92857\n",
            "\n",
            "Epoch 695: val_accuracy did not improve from 0.92857\n",
            "\n",
            "Epoch 696: val_accuracy did not improve from 0.92857\n",
            "\n",
            "Epoch 697: val_accuracy did not improve from 0.92857\n",
            "\n",
            "Epoch 698: val_accuracy did not improve from 0.92857\n",
            "\n",
            "Epoch 699: val_accuracy did not improve from 0.92857\n",
            "\n",
            "Epoch 700: val_accuracy did not improve from 0.92857\n",
            "\n",
            "Epoch 701: val_accuracy did not improve from 0.92857\n",
            "\n",
            "Epoch 702: val_accuracy did not improve from 0.92857\n",
            "\n",
            "Epoch 703: val_accuracy did not improve from 0.92857\n",
            "\n",
            "Epoch 704: val_accuracy did not improve from 0.92857\n",
            "\n",
            "Epoch 705: val_accuracy did not improve from 0.92857\n",
            "\n",
            "Epoch 706: val_accuracy did not improve from 0.92857\n",
            "\n",
            "Epoch 707: val_accuracy did not improve from 0.92857\n",
            "\n",
            "Epoch 708: val_accuracy did not improve from 0.92857\n",
            "\n",
            "Epoch 709: val_accuracy did not improve from 0.92857\n",
            "\n",
            "Epoch 710: val_accuracy did not improve from 0.92857\n",
            "\n",
            "Epoch 711: val_accuracy did not improve from 0.92857\n",
            "\n",
            "Epoch 712: val_accuracy did not improve from 0.92857\n",
            "\n",
            "Epoch 713: val_accuracy did not improve from 0.92857\n",
            "\n",
            "Epoch 714: val_accuracy did not improve from 0.92857\n",
            "\n",
            "Epoch 715: val_accuracy did not improve from 0.92857\n",
            "\n",
            "Epoch 716: val_accuracy did not improve from 0.92857\n",
            "\n",
            "Epoch 717: val_accuracy did not improve from 0.92857\n",
            "\n",
            "Epoch 718: val_accuracy did not improve from 0.92857\n",
            "\n",
            "Epoch 719: val_accuracy did not improve from 0.92857\n",
            "\n",
            "Epoch 720: val_accuracy did not improve from 0.92857\n",
            "\n",
            "Epoch 721: val_accuracy did not improve from 0.92857\n",
            "\n",
            "Epoch 722: val_accuracy did not improve from 0.92857\n",
            "\n",
            "Epoch 723: val_accuracy did not improve from 0.92857\n",
            "\n",
            "Epoch 724: val_accuracy did not improve from 0.92857\n",
            "\n",
            "Epoch 725: val_accuracy did not improve from 0.92857\n",
            "\n",
            "Epoch 726: val_accuracy did not improve from 0.92857\n",
            "\n",
            "Epoch 727: val_accuracy did not improve from 0.92857\n",
            "\n",
            "Epoch 728: val_accuracy did not improve from 0.92857\n",
            "\n",
            "Epoch 729: val_accuracy did not improve from 0.92857\n",
            "\n",
            "Epoch 730: val_accuracy did not improve from 0.92857\n",
            "\n",
            "Epoch 731: val_accuracy did not improve from 0.92857\n",
            "\n",
            "Epoch 732: val_accuracy did not improve from 0.92857\n",
            "\n",
            "Epoch 733: val_accuracy did not improve from 0.92857\n",
            "\n",
            "Epoch 734: val_accuracy did not improve from 0.92857\n",
            "\n",
            "Epoch 735: val_accuracy did not improve from 0.92857\n",
            "\n",
            "Epoch 736: val_accuracy did not improve from 0.92857\n",
            "\n",
            "Epoch 737: val_accuracy did not improve from 0.92857\n",
            "\n",
            "Epoch 738: val_accuracy did not improve from 0.92857\n",
            "\n",
            "Epoch 739: val_accuracy did not improve from 0.92857\n",
            "\n",
            "Epoch 740: val_accuracy did not improve from 0.92857\n",
            "\n",
            "Epoch 741: val_accuracy did not improve from 0.92857\n",
            "\n",
            "Epoch 742: val_accuracy did not improve from 0.92857\n",
            "\n",
            "Epoch 743: val_accuracy did not improve from 0.92857\n",
            "\n",
            "Epoch 744: val_accuracy did not improve from 0.92857\n",
            "\n",
            "Epoch 745: val_accuracy did not improve from 0.92857\n",
            "\n",
            "Epoch 746: val_accuracy did not improve from 0.92857\n",
            "\n",
            "Epoch 747: val_accuracy did not improve from 0.92857\n",
            "\n",
            "Epoch 748: val_accuracy did not improve from 0.92857\n",
            "\n",
            "Epoch 749: val_accuracy did not improve from 0.92857\n",
            "\n",
            "Epoch 750: val_accuracy did not improve from 0.92857\n",
            "\n",
            "Epoch 751: val_accuracy did not improve from 0.92857\n",
            "\n",
            "Epoch 752: val_accuracy did not improve from 0.92857\n",
            "\n",
            "Epoch 753: val_accuracy did not improve from 0.92857\n",
            "\n",
            "Epoch 754: val_accuracy did not improve from 0.92857\n",
            "\n",
            "Epoch 755: val_accuracy did not improve from 0.92857\n",
            "\n",
            "Epoch 756: val_accuracy did not improve from 0.92857\n",
            "\n",
            "Epoch 757: val_accuracy did not improve from 0.92857\n",
            "\n",
            "Epoch 758: val_accuracy did not improve from 0.92857\n",
            "\n",
            "Epoch 759: val_accuracy did not improve from 0.92857\n",
            "\n",
            "Epoch 760: val_accuracy did not improve from 0.92857\n",
            "\n",
            "Epoch 761: val_accuracy did not improve from 0.92857\n",
            "\n",
            "Epoch 762: val_accuracy did not improve from 0.92857\n",
            "\n",
            "Epoch 763: val_accuracy did not improve from 0.92857\n",
            "\n",
            "Epoch 764: val_accuracy did not improve from 0.92857\n",
            "\n",
            "Epoch 765: val_accuracy did not improve from 0.92857\n",
            "\n",
            "Epoch 766: val_accuracy did not improve from 0.92857\n",
            "\n",
            "Epoch 767: val_accuracy did not improve from 0.92857\n",
            "\n",
            "Epoch 768: val_accuracy did not improve from 0.92857\n",
            "\n",
            "Epoch 769: val_accuracy did not improve from 0.92857\n",
            "\n",
            "Epoch 770: val_accuracy did not improve from 0.92857\n",
            "\n",
            "Epoch 771: val_accuracy did not improve from 0.92857\n",
            "\n",
            "Epoch 772: val_accuracy did not improve from 0.92857\n",
            "\n",
            "Epoch 773: val_accuracy did not improve from 0.92857\n",
            "\n",
            "Epoch 774: val_accuracy did not improve from 0.92857\n",
            "\n",
            "Epoch 775: val_accuracy did not improve from 0.92857\n",
            "\n",
            "Epoch 776: val_accuracy did not improve from 0.92857\n",
            "\n",
            "Epoch 777: val_accuracy did not improve from 0.92857\n",
            "\n",
            "Epoch 778: val_accuracy did not improve from 0.92857\n",
            "\n",
            "Epoch 779: val_accuracy did not improve from 0.92857\n",
            "\n",
            "Epoch 780: val_accuracy did not improve from 0.92857\n",
            "\n",
            "Epoch 781: val_accuracy did not improve from 0.92857\n",
            "\n",
            "Epoch 782: val_accuracy did not improve from 0.92857\n",
            "\n",
            "Epoch 783: val_accuracy did not improve from 0.92857\n",
            "\n",
            "Epoch 784: val_accuracy did not improve from 0.92857\n",
            "\n",
            "Epoch 785: val_accuracy did not improve from 0.92857\n",
            "\n",
            "Epoch 786: val_accuracy did not improve from 0.92857\n",
            "\n",
            "Epoch 787: val_accuracy did not improve from 0.92857\n",
            "\n",
            "Epoch 788: val_accuracy did not improve from 0.92857\n",
            "\n",
            "Epoch 789: val_accuracy did not improve from 0.92857\n",
            "\n",
            "Epoch 790: val_accuracy did not improve from 0.92857\n",
            "\n",
            "Epoch 791: val_accuracy did not improve from 0.92857\n",
            "\n",
            "Epoch 792: val_accuracy did not improve from 0.92857\n",
            "\n",
            "Epoch 793: val_accuracy did not improve from 0.92857\n",
            "\n",
            "Epoch 794: val_accuracy did not improve from 0.92857\n",
            "\n",
            "Epoch 795: val_accuracy did not improve from 0.92857\n",
            "\n",
            "Epoch 796: val_accuracy did not improve from 0.92857\n",
            "\n",
            "Epoch 797: val_accuracy did not improve from 0.92857\n",
            "\n",
            "Epoch 798: val_accuracy did not improve from 0.92857\n",
            "\n",
            "Epoch 799: val_accuracy did not improve from 0.92857\n",
            "\n",
            "Epoch 800: val_accuracy did not improve from 0.92857\n",
            "\n",
            "Epoch 801: val_accuracy did not improve from 0.92857\n",
            "\n",
            "Epoch 802: val_accuracy did not improve from 0.92857\n",
            "\n",
            "Epoch 803: val_accuracy did not improve from 0.92857\n",
            "\n",
            "Epoch 804: val_accuracy did not improve from 0.92857\n",
            "\n",
            "Epoch 805: val_accuracy did not improve from 0.92857\n",
            "\n",
            "Epoch 806: val_accuracy did not improve from 0.92857\n",
            "\n",
            "Epoch 807: val_accuracy did not improve from 0.92857\n",
            "\n",
            "Epoch 808: val_accuracy did not improve from 0.92857\n",
            "\n",
            "Epoch 809: val_accuracy did not improve from 0.92857\n",
            "\n",
            "Epoch 810: val_accuracy did not improve from 0.92857\n",
            "\n",
            "Epoch 811: val_accuracy did not improve from 0.92857\n",
            "\n",
            "Epoch 812: val_accuracy did not improve from 0.92857\n",
            "\n",
            "Epoch 813: val_accuracy did not improve from 0.92857\n",
            "\n",
            "Epoch 814: val_accuracy did not improve from 0.92857\n",
            "\n",
            "Epoch 815: val_accuracy did not improve from 0.92857\n",
            "\n",
            "Epoch 816: val_accuracy did not improve from 0.92857\n",
            "\n",
            "Epoch 817: val_accuracy did not improve from 0.92857\n",
            "\n",
            "Epoch 818: val_accuracy did not improve from 0.92857\n",
            "\n",
            "Epoch 819: val_accuracy did not improve from 0.92857\n",
            "\n",
            "Epoch 820: val_accuracy did not improve from 0.92857\n",
            "\n",
            "Epoch 821: val_accuracy did not improve from 0.92857\n",
            "\n",
            "Epoch 822: val_accuracy did not improve from 0.92857\n",
            "\n",
            "Epoch 823: val_accuracy did not improve from 0.92857\n",
            "\n",
            "Epoch 824: val_accuracy did not improve from 0.92857\n",
            "\n",
            "Epoch 825: val_accuracy did not improve from 0.92857\n",
            "\n",
            "Epoch 826: val_accuracy did not improve from 0.92857\n",
            "\n",
            "Epoch 827: val_accuracy did not improve from 0.92857\n",
            "\n",
            "Epoch 828: val_accuracy did not improve from 0.92857\n",
            "\n",
            "Epoch 829: val_accuracy did not improve from 0.92857\n",
            "\n",
            "Epoch 830: val_accuracy did not improve from 0.92857\n",
            "\n",
            "Epoch 831: val_accuracy did not improve from 0.92857\n",
            "\n",
            "Epoch 832: val_accuracy did not improve from 0.92857\n",
            "\n",
            "Epoch 833: val_accuracy did not improve from 0.92857\n",
            "\n",
            "Epoch 834: val_accuracy did not improve from 0.92857\n",
            "\n",
            "Epoch 835: val_accuracy did not improve from 0.92857\n",
            "\n",
            "Epoch 836: val_accuracy did not improve from 0.92857\n",
            "\n",
            "Epoch 837: val_accuracy did not improve from 0.92857\n",
            "\n",
            "Epoch 838: val_accuracy did not improve from 0.92857\n",
            "\n",
            "Epoch 839: val_accuracy did not improve from 0.92857\n",
            "\n",
            "Epoch 840: val_accuracy did not improve from 0.92857\n",
            "\n",
            "Epoch 841: val_accuracy did not improve from 0.92857\n",
            "\n",
            "Epoch 842: val_accuracy did not improve from 0.92857\n",
            "\n",
            "Epoch 843: val_accuracy did not improve from 0.92857\n",
            "\n",
            "Epoch 844: val_accuracy did not improve from 0.92857\n",
            "\n",
            "Epoch 845: val_accuracy did not improve from 0.92857\n",
            "\n",
            "Epoch 846: val_accuracy did not improve from 0.92857\n",
            "\n",
            "Epoch 847: val_accuracy did not improve from 0.92857\n",
            "\n",
            "Epoch 848: val_accuracy did not improve from 0.92857\n",
            "\n",
            "Epoch 849: val_accuracy did not improve from 0.92857\n",
            "\n",
            "Epoch 850: val_accuracy did not improve from 0.92857\n",
            "\n",
            "Epoch 851: val_accuracy did not improve from 0.92857\n",
            "\n",
            "Epoch 852: val_accuracy did not improve from 0.92857\n",
            "\n",
            "Epoch 853: val_accuracy did not improve from 0.92857\n",
            "\n",
            "Epoch 854: val_accuracy did not improve from 0.92857\n",
            "\n",
            "Epoch 855: val_accuracy did not improve from 0.92857\n",
            "\n",
            "Epoch 856: val_accuracy did not improve from 0.92857\n",
            "\n",
            "Epoch 857: val_accuracy did not improve from 0.92857\n",
            "\n",
            "Epoch 858: val_accuracy did not improve from 0.92857\n",
            "\n",
            "Epoch 859: val_accuracy did not improve from 0.92857\n",
            "\n",
            "Epoch 860: val_accuracy did not improve from 0.92857\n",
            "\n",
            "Epoch 861: val_accuracy did not improve from 0.92857\n",
            "\n",
            "Epoch 862: val_accuracy did not improve from 0.92857\n",
            "\n",
            "Epoch 863: val_accuracy did not improve from 0.92857\n",
            "\n",
            "Epoch 864: val_accuracy did not improve from 0.92857\n",
            "\n",
            "Epoch 865: val_accuracy did not improve from 0.92857\n",
            "\n",
            "Epoch 866: val_accuracy did not improve from 0.92857\n",
            "\n",
            "Epoch 867: val_accuracy did not improve from 0.92857\n",
            "\n",
            "Epoch 868: val_accuracy did not improve from 0.92857\n",
            "\n",
            "Epoch 869: val_accuracy did not improve from 0.92857\n",
            "\n",
            "Epoch 870: val_accuracy did not improve from 0.92857\n",
            "\n",
            "Epoch 871: val_accuracy did not improve from 0.92857\n",
            "\n",
            "Epoch 872: val_accuracy did not improve from 0.92857\n",
            "\n",
            "Epoch 873: val_accuracy did not improve from 0.92857\n",
            "\n",
            "Epoch 874: val_accuracy did not improve from 0.92857\n",
            "\n",
            "Epoch 875: val_accuracy did not improve from 0.92857\n",
            "\n",
            "Epoch 876: val_accuracy did not improve from 0.92857\n",
            "\n",
            "Epoch 877: val_accuracy did not improve from 0.92857\n",
            "\n",
            "Epoch 878: val_accuracy did not improve from 0.92857\n",
            "\n",
            "Epoch 879: val_accuracy did not improve from 0.92857\n",
            "\n",
            "Epoch 880: val_accuracy did not improve from 0.92857\n",
            "\n",
            "Epoch 881: val_accuracy did not improve from 0.92857\n",
            "\n",
            "Epoch 882: val_accuracy did not improve from 0.92857\n",
            "\n",
            "Epoch 883: val_accuracy did not improve from 0.92857\n",
            "\n",
            "Epoch 884: val_accuracy did not improve from 0.92857\n",
            "\n",
            "Epoch 885: val_accuracy did not improve from 0.92857\n",
            "\n",
            "Epoch 886: val_accuracy did not improve from 0.92857\n",
            "\n",
            "Epoch 887: val_accuracy did not improve from 0.92857\n",
            "\n",
            "Epoch 888: val_accuracy did not improve from 0.92857\n",
            "\n",
            "Epoch 889: val_accuracy did not improve from 0.92857\n",
            "\n",
            "Epoch 890: val_accuracy improved from 0.92857 to 0.94286, saving model to best_model.h5\n",
            "\n",
            "Epoch 891: val_accuracy did not improve from 0.94286\n",
            "\n",
            "Epoch 892: val_accuracy did not improve from 0.94286\n",
            "\n",
            "Epoch 893: val_accuracy did not improve from 0.94286\n",
            "\n",
            "Epoch 894: val_accuracy did not improve from 0.94286\n",
            "\n",
            "Epoch 895: val_accuracy did not improve from 0.94286\n",
            "\n",
            "Epoch 896: val_accuracy did not improve from 0.94286\n",
            "\n",
            "Epoch 897: val_accuracy did not improve from 0.94286\n",
            "\n",
            "Epoch 898: val_accuracy did not improve from 0.94286\n",
            "\n",
            "Epoch 899: val_accuracy did not improve from 0.94286\n",
            "\n",
            "Epoch 900: val_accuracy did not improve from 0.94286\n",
            "\n",
            "Epoch 901: val_accuracy did not improve from 0.94286\n",
            "\n",
            "Epoch 902: val_accuracy did not improve from 0.94286\n",
            "\n",
            "Epoch 903: val_accuracy did not improve from 0.94286\n",
            "\n",
            "Epoch 904: val_accuracy did not improve from 0.94286\n",
            "\n",
            "Epoch 905: val_accuracy did not improve from 0.94286\n",
            "\n",
            "Epoch 906: val_accuracy did not improve from 0.94286\n",
            "\n",
            "Epoch 907: val_accuracy did not improve from 0.94286\n",
            "\n",
            "Epoch 908: val_accuracy did not improve from 0.94286\n",
            "\n",
            "Epoch 909: val_accuracy did not improve from 0.94286\n",
            "\n",
            "Epoch 910: val_accuracy did not improve from 0.94286\n",
            "\n",
            "Epoch 911: val_accuracy did not improve from 0.94286\n",
            "\n",
            "Epoch 912: val_accuracy did not improve from 0.94286\n",
            "\n",
            "Epoch 913: val_accuracy did not improve from 0.94286\n",
            "\n",
            "Epoch 914: val_accuracy did not improve from 0.94286\n",
            "\n",
            "Epoch 915: val_accuracy did not improve from 0.94286\n",
            "\n",
            "Epoch 916: val_accuracy did not improve from 0.94286\n",
            "\n",
            "Epoch 917: val_accuracy did not improve from 0.94286\n",
            "\n",
            "Epoch 918: val_accuracy did not improve from 0.94286\n",
            "\n",
            "Epoch 919: val_accuracy did not improve from 0.94286\n",
            "\n",
            "Epoch 920: val_accuracy did not improve from 0.94286\n",
            "\n",
            "Epoch 921: val_accuracy did not improve from 0.94286\n",
            "\n",
            "Epoch 922: val_accuracy did not improve from 0.94286\n",
            "\n",
            "Epoch 923: val_accuracy did not improve from 0.94286\n",
            "\n",
            "Epoch 924: val_accuracy did not improve from 0.94286\n",
            "\n",
            "Epoch 925: val_accuracy did not improve from 0.94286\n",
            "\n",
            "Epoch 926: val_accuracy did not improve from 0.94286\n",
            "\n",
            "Epoch 927: val_accuracy did not improve from 0.94286\n",
            "\n",
            "Epoch 928: val_accuracy did not improve from 0.94286\n",
            "\n",
            "Epoch 929: val_accuracy did not improve from 0.94286\n",
            "\n",
            "Epoch 930: val_accuracy did not improve from 0.94286\n",
            "\n",
            "Epoch 931: val_accuracy did not improve from 0.94286\n",
            "\n",
            "Epoch 932: val_accuracy did not improve from 0.94286\n",
            "\n",
            "Epoch 933: val_accuracy did not improve from 0.94286\n",
            "\n",
            "Epoch 934: val_accuracy did not improve from 0.94286\n",
            "\n",
            "Epoch 935: val_accuracy did not improve from 0.94286\n",
            "\n",
            "Epoch 936: val_accuracy did not improve from 0.94286\n",
            "\n",
            "Epoch 937: val_accuracy did not improve from 0.94286\n",
            "\n",
            "Epoch 938: val_accuracy did not improve from 0.94286\n",
            "\n",
            "Epoch 939: val_accuracy did not improve from 0.94286\n",
            "\n",
            "Epoch 940: val_accuracy did not improve from 0.94286\n",
            "\n",
            "Epoch 941: val_accuracy did not improve from 0.94286\n",
            "\n",
            "Epoch 942: val_accuracy did not improve from 0.94286\n",
            "\n",
            "Epoch 943: val_accuracy did not improve from 0.94286\n",
            "\n",
            "Epoch 944: val_accuracy did not improve from 0.94286\n",
            "\n",
            "Epoch 945: val_accuracy did not improve from 0.94286\n",
            "\n",
            "Epoch 946: val_accuracy did not improve from 0.94286\n",
            "\n",
            "Epoch 947: val_accuracy did not improve from 0.94286\n",
            "\n",
            "Epoch 948: val_accuracy did not improve from 0.94286\n",
            "\n",
            "Epoch 949: val_accuracy did not improve from 0.94286\n",
            "\n",
            "Epoch 950: val_accuracy did not improve from 0.94286\n",
            "\n",
            "Epoch 951: val_accuracy did not improve from 0.94286\n",
            "\n",
            "Epoch 952: val_accuracy did not improve from 0.94286\n",
            "\n",
            "Epoch 953: val_accuracy did not improve from 0.94286\n",
            "\n",
            "Epoch 954: val_accuracy did not improve from 0.94286\n",
            "\n",
            "Epoch 955: val_accuracy did not improve from 0.94286\n",
            "\n",
            "Epoch 956: val_accuracy did not improve from 0.94286\n",
            "\n",
            "Epoch 957: val_accuracy did not improve from 0.94286\n",
            "\n",
            "Epoch 958: val_accuracy did not improve from 0.94286\n",
            "\n",
            "Epoch 959: val_accuracy did not improve from 0.94286\n",
            "\n",
            "Epoch 960: val_accuracy did not improve from 0.94286\n",
            "\n",
            "Epoch 961: val_accuracy did not improve from 0.94286\n",
            "\n",
            "Epoch 962: val_accuracy did not improve from 0.94286\n",
            "\n",
            "Epoch 963: val_accuracy did not improve from 0.94286\n",
            "\n",
            "Epoch 964: val_accuracy did not improve from 0.94286\n",
            "\n",
            "Epoch 965: val_accuracy did not improve from 0.94286\n",
            "\n",
            "Epoch 966: val_accuracy did not improve from 0.94286\n",
            "\n",
            "Epoch 967: val_accuracy did not improve from 0.94286\n",
            "\n",
            "Epoch 968: val_accuracy did not improve from 0.94286\n",
            "\n",
            "Epoch 969: val_accuracy did not improve from 0.94286\n",
            "\n",
            "Epoch 970: val_accuracy did not improve from 0.94286\n",
            "\n",
            "Epoch 971: val_accuracy did not improve from 0.94286\n",
            "\n",
            "Epoch 972: val_accuracy did not improve from 0.94286\n",
            "\n",
            "Epoch 973: val_accuracy did not improve from 0.94286\n",
            "\n",
            "Epoch 974: val_accuracy did not improve from 0.94286\n",
            "\n",
            "Epoch 975: val_accuracy did not improve from 0.94286\n",
            "\n",
            "Epoch 976: val_accuracy did not improve from 0.94286\n",
            "\n",
            "Epoch 977: val_accuracy did not improve from 0.94286\n",
            "\n",
            "Epoch 978: val_accuracy did not improve from 0.94286\n",
            "\n",
            "Epoch 979: val_accuracy did not improve from 0.94286\n",
            "\n",
            "Epoch 980: val_accuracy did not improve from 0.94286\n",
            "\n",
            "Epoch 981: val_accuracy did not improve from 0.94286\n",
            "\n",
            "Epoch 982: val_accuracy did not improve from 0.94286\n",
            "\n",
            "Epoch 983: val_accuracy did not improve from 0.94286\n",
            "\n",
            "Epoch 984: val_accuracy did not improve from 0.94286\n",
            "\n",
            "Epoch 985: val_accuracy did not improve from 0.94286\n",
            "\n",
            "Epoch 986: val_accuracy did not improve from 0.94286\n",
            "\n",
            "Epoch 987: val_accuracy did not improve from 0.94286\n",
            "\n",
            "Epoch 988: val_accuracy did not improve from 0.94286\n",
            "\n",
            "Epoch 989: val_accuracy did not improve from 0.94286\n",
            "\n",
            "Epoch 990: val_accuracy did not improve from 0.94286\n",
            "\n",
            "Epoch 991: val_accuracy did not improve from 0.94286\n",
            "\n",
            "Epoch 992: val_accuracy did not improve from 0.94286\n",
            "\n",
            "Epoch 993: val_accuracy did not improve from 0.94286\n",
            "\n",
            "Epoch 994: val_accuracy did not improve from 0.94286\n",
            "\n",
            "Epoch 995: val_accuracy did not improve from 0.94286\n",
            "\n",
            "Epoch 996: val_accuracy did not improve from 0.94286\n",
            "\n",
            "Epoch 997: val_accuracy did not improve from 0.94286\n",
            "\n",
            "Epoch 998: val_accuracy did not improve from 0.94286\n",
            "\n",
            "Epoch 999: val_accuracy did not improve from 0.94286\n",
            "\n",
            "Epoch 1000: val_accuracy did not improve from 0.94286\n",
            "\n",
            "Epoch 1001: val_accuracy did not improve from 0.94286\n",
            "\n",
            "Epoch 1002: val_accuracy did not improve from 0.94286\n",
            "\n",
            "Epoch 1003: val_accuracy did not improve from 0.94286\n",
            "\n",
            "Epoch 1004: val_accuracy did not improve from 0.94286\n",
            "\n",
            "Epoch 1005: val_accuracy did not improve from 0.94286\n",
            "\n",
            "Epoch 1006: val_accuracy did not improve from 0.94286\n",
            "\n",
            "Epoch 1007: val_accuracy did not improve from 0.94286\n",
            "\n",
            "Epoch 1008: val_accuracy did not improve from 0.94286\n",
            "\n",
            "Epoch 1009: val_accuracy did not improve from 0.94286\n",
            "\n",
            "Epoch 1010: val_accuracy did not improve from 0.94286\n",
            "\n",
            "Epoch 1011: val_accuracy did not improve from 0.94286\n",
            "\n",
            "Epoch 1012: val_accuracy did not improve from 0.94286\n",
            "\n",
            "Epoch 1013: val_accuracy did not improve from 0.94286\n",
            "\n",
            "Epoch 1014: val_accuracy did not improve from 0.94286\n",
            "\n",
            "Epoch 1015: val_accuracy did not improve from 0.94286\n",
            "\n",
            "Epoch 1016: val_accuracy did not improve from 0.94286\n",
            "\n",
            "Epoch 1017: val_accuracy did not improve from 0.94286\n",
            "\n",
            "Epoch 1018: val_accuracy did not improve from 0.94286\n",
            "\n",
            "Epoch 1019: val_accuracy did not improve from 0.94286\n",
            "\n",
            "Epoch 1020: val_accuracy did not improve from 0.94286\n",
            "\n",
            "Epoch 1021: val_accuracy did not improve from 0.94286\n",
            "\n",
            "Epoch 1022: val_accuracy did not improve from 0.94286\n",
            "\n",
            "Epoch 1023: val_accuracy did not improve from 0.94286\n",
            "\n",
            "Epoch 1024: val_accuracy did not improve from 0.94286\n",
            "\n",
            "Epoch 1025: val_accuracy did not improve from 0.94286\n",
            "\n",
            "Epoch 1026: val_accuracy did not improve from 0.94286\n",
            "\n",
            "Epoch 1027: val_accuracy did not improve from 0.94286\n",
            "\n",
            "Epoch 1028: val_accuracy did not improve from 0.94286\n",
            "\n",
            "Epoch 1029: val_accuracy did not improve from 0.94286\n",
            "\n",
            "Epoch 1030: val_accuracy did not improve from 0.94286\n",
            "\n",
            "Epoch 1031: val_accuracy did not improve from 0.94286\n",
            "\n",
            "Epoch 1032: val_accuracy did not improve from 0.94286\n",
            "\n",
            "Epoch 1033: val_accuracy did not improve from 0.94286\n",
            "\n",
            "Epoch 1034: val_accuracy did not improve from 0.94286\n",
            "\n",
            "Epoch 1035: val_accuracy did not improve from 0.94286\n",
            "\n",
            "Epoch 1036: val_accuracy did not improve from 0.94286\n",
            "\n",
            "Epoch 1037: val_accuracy did not improve from 0.94286\n",
            "\n",
            "Epoch 1038: val_accuracy did not improve from 0.94286\n",
            "\n",
            "Epoch 1039: val_accuracy did not improve from 0.94286\n",
            "\n",
            "Epoch 1040: val_accuracy did not improve from 0.94286\n",
            "\n",
            "Epoch 1041: val_accuracy did not improve from 0.94286\n",
            "\n",
            "Epoch 1042: val_accuracy did not improve from 0.94286\n",
            "\n",
            "Epoch 1043: val_accuracy did not improve from 0.94286\n",
            "\n",
            "Epoch 1044: val_accuracy did not improve from 0.94286\n",
            "\n",
            "Epoch 1045: val_accuracy did not improve from 0.94286\n",
            "\n",
            "Epoch 1046: val_accuracy did not improve from 0.94286\n",
            "\n",
            "Epoch 1047: val_accuracy did not improve from 0.94286\n",
            "\n",
            "Epoch 1048: val_accuracy did not improve from 0.94286\n",
            "\n",
            "Epoch 1049: val_accuracy did not improve from 0.94286\n",
            "Epoch 1049: early stopping\n",
            "Train: 1.000, Test: 0.943\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "nHZDR7aFejF3"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}